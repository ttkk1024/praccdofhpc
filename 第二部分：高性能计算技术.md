# 第二部分：高性能计算技术

## 第3章 并行计算架构

### 3.1 并行计算模型

#### SIMD (Single Instruction, Multiple Data)
**概念定义**：所有处理单元同时执行相同的指令，但处理不同的数据元素

**架构特点**：
- 统一的指令流控制多个数据流
- 高度同步的执行模式
- 适合规则的数据并行操作

**典型应用**：
- 向量化计算（SIMD指令集：SSE、AVX、NEON）
- 图像和视频处理
- 科学计算中的数组运算

**优势与局限**：
- ✅ 高吞吐量，适合规则计算
- ❌ 灵活性差，不支持分支
- ⚠️ 数据依赖性要求高

**实现示例**：
```c
// AVX向量加法
__m256 a = _mm256_load_ps(array_a);
__m256 b = _mm256_load_ps(array_b);
__m256 c = _mm256_add_ps(a, b);
_mm256_store_ps(result, c);
```

#### MIMD (Multiple Instruction, Multiple Data)
**概念定义**：每个处理单元可以独立执行不同的指令，处理不同的数据

**架构分类**：
- **SMP (Symmetric Multiprocessing)**：共享内存的多处理器系统
- **Cluster**：分布式内存的计算机集群
- **NUMA**：非统一内存访问架构

**典型应用**：
- 服务器应用（Web服务器、数据库）
- 分布式计算系统
- 多任务操作系统

**优势与局限**：
- ✅ 高灵活性，支持复杂算法
- ✅ 良好的可扩展性
- ❌ 通信开销较大
- ❌ 同步复杂度高

#### SPMD (Single Program, Multiple Data)
**概念定义**：所有处理器执行相同的程序，但处理不同的数据集

**特点**：
- 程序代码相同，数据分布不同
- 进程间需要协调和通信
- MPI编程的典型模式

**实现模式**：
```c
// MPI SPMD示例
int rank, size;
MPI_Init(&argc, &argv);
MPI_Comm_rank(MPI_COMM_WORLD, &rank);
MPI_Comm_size(MPI_COMM_WORLD, &size);

// 所有进程执行相同程序，但处理不同数据
if (rank == 0) {
    // 主进程逻辑
} else {
    // 工作进程逻辑
}

MPI_Finalize();
```

#### MPMD (Multiple Program, Multiple Data)
**概念定义**：不同处理器执行不同的程序，处理不同的数据

**应用场景**：
- 异构计算系统
- 客户端-服务器架构
- 功能专门化的并行系统

#### 数据并行模型
**核心思想**：将大数据集分割成小块，分配给不同处理器并行处理

**实现方式**：
- **循环级并行**：for循环的并行化
- **数组操作并行**：向量化数组运算
- **数据分区**：按数据维度分割

**优化策略**：
- 数据局部性优化
- 负载均衡
- 减少通信开销

#### 任务并行模型
**核心思想**：将计算任务分解为独立的子任务，并行执行

**任务类型**：
- **功能分解**：按功能模块分解
- **流水线并行**：按执行阶段分解
- **递归分解**：递归式任务分解

**调度策略**：
- 静态调度
- 动态调度
- 工作窃取

#### 流水线并行模型
**概念定义**：将计算过程分解为多个阶段，各阶段并行执行

**特点**：
- 阶段间存在数据依赖
- 通过缓冲区实现阶段间通信
- 适合流式数据处理

**应用场景**：
- 编译器优化
- 视频处理流水线
- 数据流计算

#### 混合并行模型
**概念定义**：结合多种并行模型的优势，实现多层次并行

**常见组合**：
- **MPI + OpenMP**：进程级 + 线程级并行
- **MPI + CUDA**：分布式 + GPU并行
- **OpenMP + SIMD**：线程级 + 向量化并行

**实现示例**：
```c
// MPI + OpenMP混合并行
#pragma omp parallel for
for (int i = 0; i < local_size; i++) {
    #pragma omp simd
    for (int j = 0; j < vector_size; j++) {
        // SIMD向量化内循环
        result[i][j] = compute(data[i][j]);
    }
}
```

#### 模型选择指南

| 应用类型 | 推荐模型 | 原因 |
|---------|---------|------|
| 向量化计算 | SIMD | 高吞吐量，适合规则运算 |
| 科学计算 | SPMD/MPI | 数据分布，通信需求 |
| 服务器应用 | MIMD | 灵活性，多任务处理 |
| 图像处理 | SIMD + 任务并行 | 数据并行 + 功能并行 |
| 大数据分析 | 混合并行 | 多层次优化 |

#### 性能比较

| 模型 | 并行度 | 灵活性 | 通信开销 | 适用场景 |
|-----|-------|--------|---------|---------|
| SIMD | 高 | 低 | 无 | 规则计算 |
| MIMD | 中 | 高 | 高 | 复杂应用 |
| SPMD | 高 | 中 | 中 | 分布式计算 |
| 任务并行 | 中 | 高 | 可变 | 多样化任务 |

### 3.2 内存架构

#### 共享内存系统 (Shared Memory)

**概念定义**：所有处理器共享同一物理内存空间，通过总线或互连网络访问

**架构特点**：
- 统一的地址空间
- 简化的编程模型
- 硬件负责缓存一致性

**实现方式**：
- **UMA (Uniform Memory Access)**：统一内存访问时间
- **NUMA (Non-Uniform Memory Access)**：非统一内存访问时间

**UMA架构**：
```c
// UMA系统特点
// - 所有处理器访问内存时间相同
// - 适合小规模多处理器系统
// - 典型：SMP系统
```

**NUMA架构**：
```c
// NUMA系统特点
// - 本地内存访问快，远程内存访问慢
// - 需要内存亲和性优化
// - 典型：多插槽服务器

// NUMA感知的内存分配
#include <numa.h>
numa_set_localalloc();  // 分配本地内存
numa_set_preferred(node_id);  // 设置首选节点
```

**优势与挑战**：
- ✅ 编程简单，数据共享方便
- ✅ 线程间通信开销小
- ❌ 可扩展性受限
- ❌ 缓存一致性开销
- ❌ 内存带宽瓶颈

#### 分布式内存系统 (Distributed Memory)

**概念定义**：每个处理器有独立的内存空间，通过消息传递进行通信

**架构特点**：
- 分布式的地址空间
- 显式的通信机制
- 优秀的可扩展性

**典型实现**：
- **计算机集群**：通过网络互连
- **大规模并行处理器 (MPP)**
- **分布式计算框架**

**通信模式**：
```c
// MPI分布式内存通信
MPI_Send(buffer, count, MPI_DOUBLE, dest, tag, MPI_COMM_WORLD);
MPI_Recv(buffer, count, MPI_DOUBLE, source, tag, MPI_COMM_WORLD, &status);

// 点对点通信
MPI_Isend(buffer, count, datatype, dest, tag, comm, &request);
MPI_Irecv(buffer, count, datatype, source, tag, comm, &request);

// 集体通信
MPI_Bcast(data, count, datatype, root, comm);
MPI_Allreduce(sendbuf, recvbuf, count, datatype, op, comm);
```

**数据分布策略**：
- **块分布 (Block Distribution)**：连续数据块分配
- **循环分布 (Cyclic Distribution)**：轮询分配
- **块循环分布 (Block-Cyclic)**：混合策略

**优势与挑战**：
- ✅ 优秀的可扩展性
- ✅ 避免缓存一致性问题
- ✅ 适合大规模系统
- ❌ 编程复杂度高
- ❌ 通信开销大
- ❌ 内存使用不均衡

#### 混合内存系统 (Hybrid Memory)

**概念定义**：结合共享内存和分布式内存的特点，实现多层次内存架构

**典型架构**：
- **NUMA + 分布式**：节点内NUMA，节点间分布式
- **CPU + GPU异构**：CPU内存 + GPU显存
- **内存 + 存储层次**：内存、SSD、HDD多级存储

**实现示例**：
```c
// 混合内存系统编程策略
#ifdef USE_MPI
    // 分布式内存通信
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    // 数据分片处理
    local_data = distribute_data(global_data, rank, size);
#endif

#ifdef USE_OPENMP
    // 共享内存并行
    #pragma omp parallel for
    for (int i = 0; i < local_size; i++) {
        process_data(local_data[i]);
    }
#endif

// GPU内存管理
#ifdef USE_CUDA
    float *d_data;
    cudaMalloc(&d_data, size * sizeof(float));
    cudaMemcpy(d_data, h_data, size * sizeof(float), cudaMemcpyHostToDevice);
#endif
```

#### 内存层次结构 (Memory Hierarchy)

**存储器金字塔**：
```
寄存器 (Registers)     - 几个周期
    ↓
L1缓存 (L1 Cache)      - 1-4周期
    ↓
L2缓存 (L2 Cache)      - 10-20周期
    ↓
L3缓存 (L3 Cache)      - 30-50周期
    ↓
主内存 (Main Memory)   - 100-300周期
    ↓
SSD存储               - 微秒级
    ↓
HDD存储               - 毫秒级
```

**缓存组织方式**：
- **直接映射 (Direct Mapped)**：简单但冲突率高
- **组相联 (Set Associative)**：平衡性能和复杂度
- **全相联 (Fully Associative)**：性能好但复杂

**缓存一致性协议**：
- **MESI协议**：Modified, Exclusive, Shared, Invalid
- **MOESI协议**：增加Owned状态
- **MESIF协议**：Intel的优化版本

#### 内存优化技术

**数据局部性优化**：
```c
// 空间局部性：连续访问
for (int i = 0; i < N; i++) {
    for (int j = 0; j < M; j++) {
        // 连续访问提高缓存命中率
        result[i][j] = a[i][j] * b[i][j];
    }
}

// 时间局部性：重复使用数据
for (int k = 0; k < ITERATIONS; k++) {
    for (int i = 0; i < N; i++) {
        // 重复使用temp提高缓存效率
        double temp = compute_value(i);
        result[i] += temp * factor;
    }
}
```

**内存对齐优化**：
```c
// 结构体对齐优化
struct aligned_data {
    double value;     // 8字节对齐
    char padding[4];  // 填充到16字节边界
    int index;        // 4字节
} __attribute__((aligned(16)));

// SIMD内存对齐
float *aligned_array = (float*)_mm_malloc(size * sizeof(float), 32);
```

**NUMA感知优化**：
```c
// NUMA内存绑定
#include <numa.h>
#include <numaif.h>

// 获取NUMA节点信息
int num_nodes = numa_num_task_nodes();
numa_node_set(node_mask);

// 绑定线程到特定NUMA节点
cpu_set_t cpuset;
CPU_ZERO(&cpuset);
CPU_SET(cpu_id, &cpuset);
pthread_setaffinity_np(thread, sizeof(cpu_set_t), &cpuset);

// 内存绑定到节点
void *ptr = numa_alloc_onnode(size, node_id);
```

#### 新兴内存技术

**非易失性内存 (NVM)**：
- **Intel Optane DC Persistent Memory**
- **3D XPoint技术**
- **字节寻址的持久化存储**

**实现示例**：
```c
// NVM内存映射
#include <libpmem.h>

// 创建持久化内存映射
void *pmem_addr = pmem_map_file(path, size,
    PMEM_FILE_CREATE, 0666, &mapped_len, &is_pmem);

// 持久化写入
memcpy(pmem_addr, data, size);
pmem_persist(pmem_addr, size);  // 确保数据持久化
```

**高带宽内存 (HBM)**：
- **堆叠式内存架构**
- **GPU和AI加速器使用**
- **极高的内存带宽**

**存内计算 (Computing-in-Memory)**：
- **减少数据移动**
- **提高能效比**
- **新兴研究领域**

#### 内存架构选择指南

| 系统规模 | 推荐架构 | 原因 |
|---------|---------|------|
| 单节点，<64核 | 共享内存 | 简单高效 |
| 多节点，>64核 | 分布式内存 | 可扩展性 |
| 异构系统 | 混合内存 | 利用各层次优势 |
| 大数据处理 | 分布式内存 | 数据本地性 |

#### 性能对比分析

| 架构类型 | 延迟 | 带宽 | 可扩展性 | 编程复杂度 |
|---------|------|------|---------|-----------|
| 共享内存 | 低 | 高 | 中 | 低 |
| 分布式内存 | 中 | 中 | 高 | 高 |
| 混合内存 | 可变 | 高 | 高 | 中 |

#### 内存调试工具

**内存错误检测**：
```bash
# Valgrind内存检测
valgrind --tool=memcheck --leak-check=full ./program

# Intel Inspector
inspxe-cl -collect mi1 ./program

# AddressSanitizer
gcc -fsanitize=address -g -o program program.c
```

**NUMA分析**：
```bash
# 查看NUMA拓扑
numactl --hardware

# NUMA性能分析
numastat -p <pid>

# 内存访问模式分析
perf stat -e mem-loads,mem-stores ./program
```

### 3.3 通信模式

#### 消息传递 (Message Passing)

**概念定义**：进程间通过显式发送和接收消息进行通信，每个进程有独立的地址空间

**核心特征**：
- 点对点通信机制
- 显式的发送和接收操作
- 通信双方需要协调同步

**MPI消息传递模型**：
```c
// 点对点通信
MPI_Send(buffer, count, datatype, dest, tag, comm);
MPI_Recv(buffer, count, datatype, source, tag, comm, &status);

// 非阻塞通信
MPI_Isend(buffer, count, datatype, dest, tag, comm, &request);
MPI_Irecv(buffer, count, datatype, source, tag, comm, &request);
MPI_Wait(&request, &status);

// 通信完成检查
MPI_Test(&request, &flag, &status);
MPI_Waitall(count, requests, statuses);
```

**通信类型**：
- **阻塞通信**：发送/接收操作直到完成才返回
- **非阻塞通信**：立即返回，允许重叠计算和通信
- **持久通信**：重复使用的通信句柄

**通信优化策略**：
```c
// 通信聚合
MPI_Allreduce(local_sum, global_sum, 1, MPI_DOUBLE, MPI_SUM, MPI_COMM_WORLD);

// 通信与计算重叠
MPI_Isend(data, size, MPI_DOUBLE, dest, tag, MPI_COMM_WORLD, &request);
// 执行计算
compute_work();
MPI_Wait(&request, &status);

// 流水线通信
for (int i = 0; i < num_chunks; i++) {
    MPI_Isend(chunk[i], chunk_size, MPI_DOUBLE, dest, i, comm, &request[i]);
    if (i > 0) {
        MPI_Wait(&request[i-1], &status);
    }
}
```

#### 共享内存通信

**概念定义**：多个线程通过共享的内存区域进行通信和同步

**同步机制**：
```c
// 互斥锁 (Mutex)
pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;
pthread_mutex_lock(&mutex);
// 临界区代码
pthread_mutex_unlock(&mutex);

// 条件变量 (Condition Variable)
pthread_cond_t cond = PTHREAD_COND_INITIALIZER;
pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;

// 等待条件
pthread_mutex_lock(&mutex);
while (condition_not_met) {
    pthread_cond_wait(&cond, &mutex);
}
pthread_mutex_unlock(&mutex);

// 通知条件
pthread_mutex_lock(&mutex);
condition_met = 1;
pthread_cond_signal(&cond);
pthread_mutex_unlock(&mutex);
```

**OpenMP共享内存通信**：
```c
// 共享变量和私有变量
#pragma omp parallel shared(shared_var) private(local_var)
{
    local_var = compute_local();
    #pragma omp critical
    {
        shared_var += local_var;
    }
}

// 原子操作
#pragma omp atomic
counter++;

// 屏障同步
#pragma omp barrier;

// 单线程执行
#pragma omp single
{
    // 只有一个线程执行此代码
    initialize_data();
}
```

**锁的类型和优化**：
```c
// 自旋锁 (Spinlock)
typedef struct {
    volatile int locked;
} spinlock_t;

void spinlock_lock(spinlock_t *lock) {
    while (__sync_lock_test_and_set(&lock->locked, 1)) {
        // 自旋等待
        while (lock->locked) {
            // 空循环
        }
    }
}

void spinlock_unlock(spinlock_t *lock) {
    __sync_lock_release(&lock->locked);
}

// 读写锁 (Read-Write Lock)
pthread_rwlock_t rwlock = PTHREAD_RWLOCK_INITIALIZER;

// 读锁
pthread_rwlock_rdlock(&rwlock);
// 读取共享数据
pthread_rwlock_unlock(&rwlock);

// 写锁
pthread_rwlock_wrlock(&rwlock);
// 修改共享数据
pthread_rwlock_unlock(&rwlock);
```

#### 远程内存访问 (RMA - Remote Memory Access)

**概念定义**：允许一个进程直接访问另一个进程的内存，无需显式的消息传递

**MPI-2 RMA操作**：
```c
// 创建窗口
MPI_Win win;
MPI_Win_create(buffer, size, disp_unit, info, comm, &win);

// Put操作：将本地数据写入远程内存
MPI_Put(local_data, count, datatype, target_rank, target_disp,
        count, datatype, win);

// Get操作：从远程内存读取数据
MPI_Get(local_data, count, datatype, source_rank, source_disp,
        count, datatype, win);

// Accumulate操作：原子的归约操作
MPI_Accumulate(local_data, count, datatype, target_rank, target_disp,
               datatype, MPI_SUM, win);

// 同步操作
MPI_Win_fence(0, win);  // 同步所有进程
MPI_Win_start(group, 0, win);  // 启动RMA操作
MPI_Win_complete(win);  // 完成RMA操作
```

**RMA优化策略**：
```c
// 一-sided通信优化
MPI_Win_lock_all(0, win);
for (int i = 0; i < num_updates; i++) {
    MPI_Put(local_buffer[i], 1, MPI_INT, target_rank, i, 1, MPI_INT, win);
}
MPI_Win_unlock_all(win);

// 主动目标RMA
MPI_Win_lock(MPI_LOCK_SHARED, target_rank, 0, win);
MPI_Get(remote_data, count, MPI_DOUBLE, target_rank, disp, count, MPI_DOUBLE, win);
MPI_Win_unlock(target_rank, win);
```

#### 通信拓扑

**基本拓扑结构**：
```c
// 创建网格拓扑
int dims[2] = {rows, cols};
int periods[2] = {0, 0};  // 非周期性
int reorder = 1;
MPI_Comm cart_comm;
MPI_Cart_create(MPI_COMM_WORLD, 2, dims, periods, reorder, &cart_comm);

// 获取邻居进程
int coords[2], neighbors[4];
MPI_Cart_coords(cart_comm, rank, 2, coords);
MPI_Cart_shift(cart_comm, 0, 1, &neighbors[0], &neighbors[1]);  // 上下邻居
MPI_Cart_shift(cart_comm, 1, 1, &neighbors[2], &neighbors[3]);  // 左右邻居

// 创建图拓扑
int index[4] = {2, 4, 6, 8};
int edges[8] = {1, 3, 0, 2, 1, 3, 0, 2};
MPI_Comm graph_comm;
MPI_Graph_create(MPI_COMM_WORLD, 4, index, edges, 0, &graph_comm);
```

**拓扑感知通信**：
```c
// 拓扑感知的邻居通信
MPI_Cart_shift(cart_comm, 0, 1, &up, &down);
MPI_Cart_shift(cart_comm, 1, 1, &left, &right);

// 与邻居交换边界数据
MPI_Sendrecv(send_up, count, MPI_DOUBLE, up, tag,
             recv_down, count, MPI_DOUBLE, down, tag,
             cart_comm, &status);
```

#### 集合通信 (Collective Communication)

**基本集合操作**：
```c
// 广播 (Broadcast)
MPI_Bcast(data, count, datatype, root, comm);

// 规约 (Reduce)
MPI_Reduce(sendbuf, recvbuf, count, datatype, op, root, comm);
MPI_Allreduce(sendbuf, recvbuf, count, datatype, op, comm);

// 散发 (Scatter)
MPI_Scatter(sendbuf, sendcount, sendtype,
            recvbuf, recvcount, recvtype, root, comm);

// 收集 (Gather)
MPI_Gather(sendbuf, sendcount, sendtype,
           recvbuf, recvcount, recvtype, root, comm);
MPI_Allgather(sendbuf, sendcount, sendtype,
              recvbuf, recvcount, recvtype, comm);

// 全局散布 (Alltoall)
MPI_Alltoall(sendbuf, sendcount, sendtype,
             recvbuf, recvcount, recvtype, comm);
```

**高级集合操作**：
```c
// 扫描操作
MPI_Scan(sendbuf, recvbuf, count, datatype, op, comm);
MPI_Exscan(sendbuf, recvbuf, count, datatype, op, comm);

// 数据类型操作
MPI_Datatype custom_type;
MPI_Type_contiguous(count, MPI_DOUBLE, &custom_type);
MPI_Type_commit(&custom_type);

MPI_Reduce(sendbuf, recvbuf, 1, custom_type, op, root, comm);
MPI_Type_free(&custom_type);
```

#### 通信性能优化

**通信模式选择**：
```c
// 小消息：点对点通信
if (message_size < 1024) {
    MPI_Send(data, message_size, MPI_BYTE, dest, tag, comm);
}
// 大消息：使用异步通信
else {
    MPI_Isend(data, message_size, MPI_BYTE, dest, tag, comm, &request);
    // 重叠计算
    compute_work();
    MPI_Wait(&request, &status);
}
```

**通信聚合优化**：
```c
// 减少通信次数
// 不好的做法：多次小消息
for (int i = 0; i < n; i++) {
    MPI_Send(&data[i], 1, MPI_DOUBLE, dest, i, comm);
}

// 好的做法：聚合通信
MPI_Send(data, n, MPI_DOUBLE, dest, tag, comm);

// 使用非阻塞通信重叠
MPI_Request requests[4];
MPI_Isend(data1, size1, MPI_DOUBLE, dest1, tag1, comm, &requests[0]);
MPI_Isend(data2, size2, MPI_DOUBLE, dest2, tag2, comm, &requests[1]);
MPI_Isend(data3, size3, MPI_DOUBLE, dest3, tag3, comm, &requests[2]);
MPI_Isend(data4, size4, MPI_DOUBLE, dest4, tag4, comm, &requests[3]);

// 执行计算
compute_work();

// 等待所有通信完成
MPI_Waitall(4, requests, MPI_STATUSES_IGNORE);
```

**通信模式对比**

| 通信模式 | 延迟 | 带宽 | 可扩展性 | 复杂度 | 适用场景 |
|---------|------|------|---------|--------|---------|
| 点对点 | 低 | 高 | 高 | 中 | 精确控制 |
| 集合通信 | 中 | 高 | 中 | 低 | 全局操作 |
| RMA | 低 | 高 | 高 | 高 | 一-sided |
| 共享内存 | 极低 | 极高 | 低 | 低 | 多线程 |

#### 通信死锁预防

**死锁检测和预防**：
```c
// 死锁预防：使用非阻塞通信
MPI_Request send_req, recv_req;
MPI_Status send_status, recv_status;

MPI_Isend(send_buffer, count, datatype, dest, send_tag, comm, &send_req);
MPI_Irecv(recv_buffer, count, datatype, source, recv_tag, comm, &recv_req);

// 等待任意通信完成
MPI_Waitany(2, (MPI_Request[]){send_req, recv_req},
           &index, &status);

// 处理完成的通信
if (index == 0) {
    // 发送完成，可以安全发送下一条
    MPI_Isend(next_send_buffer, count, datatype, dest, next_tag, comm, &next_req);
} else {
    // 接收完成，处理数据
    process_received_data(recv_buffer);
}
```

**通信顺序优化**：
```c
// 环形通信避免死锁
int next_rank = (rank + 1) % size;
int prev_rank = (rank - 1 + size) % size;

// 先发送后接收，或者使用非阻塞通信
MPI_Isend(send_data, count, MPI_DOUBLE, next_rank, tag, comm, &send_req);
MPI_Recv(recv_data, count, MPI_DOUBLE, prev_rank, tag, comm, &status);
MPI_Wait(&send_req, &status);
```

#### 通信调试工具

**通信模式分析**：
```bash
# 使用TAU分析通信模式
tau_exec -T mpi ./program

# 使用Vampir分析通信时间线
vampir ./program

# 使用mpiP分析通信统计
mpiP ./program
```

**通信性能监控**：
```c
// 手动添加通信计时
double start_time = MPI_Wtime();
MPI_Send(data, count, MPI_DOUBLE, dest, tag, comm);
double send_time = MPI_Wtime() - start_time;

double recv_start = MPI_Wtime();
MPI_Recv(data, count, MPI_DOUBLE, source, tag, comm, &status);
double recv_time = MPI_Wtime() - recv_start;

printf("Send time: %f, Recv time: %f\n", send_time, recv_time);
```

#### 通信模式选择指南

| 应用特征 | 推荐通信模式 | 原因 |
|---------|-------------|------|
| 小规模通信 | 点对点 | 简单直接 |
| 全局同步 | 集合通信 | 高效同步 |
| 不规则通信 | RMA | 灵活访问 |
| 多线程 | 共享内存 | 低开销 |
| 大规模系统 | 非阻塞通信 | 重叠计算 |

## 第4章 GPU计算

### 4.1 GPU架构基础

#### GPU与CPU架构对比

**CPU架构特点**：
- **核心数量**：通常4-64个核心
- **时钟频率**：高频率（3-5GHz）
- **缓存层次**：大容量L1/L2/L3缓存
- **执行模式**：复杂指令集，分支预测
- **适用场景**：串行任务，复杂逻辑

**GPU架构特点**：
- **核心数量**：数千个简化核心
- **时钟频率**：中等频率（1-2GHz）
- **缓存层次**：小容量但高带宽缓存
- **执行模式**：SIMD/SIMT，数据并行
- **适用场景**：大规模并行计算

#### CUDA核心架构

**SM (Streaming Multiprocessor) 结构**：
```
SM组成：
├── CUDA核心 (CUDA Cores)
├── 特殊功能单元 (SFU)
├── 加载/存储单元 (LD/ST)
├── 寄存器文件 (Register File)
├── 共享内存 (Shared Memory)
└── L1缓存
```

**CUDA核心特性**：
- **32位浮点运算**：FP32性能
- **整数运算**：INT32运算
- **双精度运算**：FP64性能（通常较低）
- **张量核心**：混合精度矩阵运算

**SM执行模型**：
```c
// Warp执行示例
__global__ void vectorAdd(float *a, float *b, float *c, int n) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < n) {
        // 所有32个线程同时执行相同指令
        c[idx] = a[idx] + b[idx];
    }
}
```

#### GPU内存层次结构

**全局内存 (Global Memory)**：
- **容量**：几GB到几十GB
- **带宽**：数百GB/s到TB/s
- **延迟**：数百到数千周期
- **访问模式**：必须合并访问以获得最佳性能

```c
// 合并内存访问示例
__global__ void coalescedAccess(float *data) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    // 合并访问：连续线程访问连续内存
    float val = data[idx];
    // 处理数据...
}
```

**共享内存 (Shared Memory)**：
- **容量**：每个SM 48-164KB
- **带宽**：极高（比全局内存快10-100倍）
- **延迟**：低延迟
- **作用域**：Block内线程共享

```c
// 共享内存使用示例
__global__ void sharedMemoryExample(float *input, float *output) {
    __shared__ float shared_data[256];

    int tid = threadIdx.x;
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    // 加载到共享内存
    shared_data[tid] = input[idx];
    __syncthreads();

    // 使用共享内存进行计算
    // 避免重复访问全局内存
    float result = process(shared_data[tid]);

    output[idx] = result;
}
```

**寄存器 (Registers)**：
- **容量**：每个SM数千个寄存器
- **访问速度**：最快
- **作用域**：每个线程私有
- **限制**：寄存器使用过多会限制并发线程数

**常量内存 (Constant Memory)**：
- **容量**：64KB
- **特点**：只读，缓存优化
- **适用**：广播式访问模式

```c
__constant__ float coefficients[256];

__global__ void constantMemoryExample(float *data) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    // 所有线程读取相同的常量数据
    float coeff = coefficients[threadIdx.x % 256];
    data[idx] *= coeff;
}
```

**纹理内存 (Texture Memory)**：
- **特点**：缓存优化，支持插值
- **适用**：图像处理，空间局部性访问
- **只读**：硬件缓存优化

#### 线程组织模型

**线程层次结构**：
```
Grid (网格)
├── Block (线程块)
│   ├── Warp (线程束，32个线程)
│   │   ├── Thread (线程)
│   │   ├── Thread
│   │   └── ...
│   ├── Block内其他Warp
│   └── ...
└── Grid内其他Block
```

**线程索引计算**：
```c
// 一维线程索引
int idx = blockIdx.x * blockDim.x + threadIdx.x;

// 二维线程索引
int row = blockIdx.y * blockDim.y + threadIdx.y;
int col = blockIdx.x * blockDim.x + threadIdx.x;
int idx = row * width + col;

// 三维线程索引
int x = blockIdx.x * blockDim.x + threadIdx.x;
int y = blockIdx.y * blockDim.y + threadIdx.y;
int z = blockIdx.z * blockDim.z + threadIdx.z;
int idx = z * width * height + y * width + x;
```

**Warp执行特性**：
- **SIMT (Single Instruction, Multiple Thread)**：32个线程执行相同指令
- **分支发散**：if-else分支会导致性能下降
- **内存合并**：连续线程访问连续内存地址

```c
// 分支发散示例（不推荐）
__global__ void divergentBranch(float *data) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    if (idx % 2 == 0) {
        // 偶数线程执行
        data[idx] *= 2.0f;
    } else {
        // 奇数线程执行
        data[idx] += 1.0f;
    }
    // 导致Warp内分支发散，性能下降
}

// 分支收敛优化（推荐）
__global__ void convergentBranch(float *data) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    if (threadIdx.x % 2 == 0) {
        // 同一Warp内的线程分支一致
        int global_idx = idx * 2;
        data[global_idx] *= 2.0f;
    } else {
        int global_idx = (idx - 1) * 2 + 1;
        data[global_idx] += 1.0f;
    }
}
```

#### GPU计算能力 (Compute Capability)

**主要架构代号**：
- **Kepler**：计算能力3.x
- **Maxwell**：计算能力5.x
- **Pascal**：计算能力6.x
- **Volta**：计算能力7.0
- **Turing**：计算能力7.5
- **Ampere**：计算能力8.x
- **Ada Lovelace**：计算能力8.9

**特性对比**：
| 架构 | 计算能力 | 主要特性 |
|-----|---------|---------|
| Kepler | 3.x | 基础CUDA功能 |
| Maxwell | 5.x | 功耗优化 |
| Pascal | 6.x | 统一内存 |
| Volta | 7.0 | Tensor Core |
| Turing | 7.5 | RT Core |
| Ampere | 8.x | 第三代Tensor Core |

#### GPU内存带宽优化

**内存带宽计算**：
```c
// 计算理论带宽
// 带宽 = 内存频率 × 总线宽度 × 传输次数
// 例如：14 Gbps × 384位 × 2 = 1075.2 GB/s
```

**内存访问优化策略**：
```c
// 1. 合并内存访问
__global__ void coalescedAccess(float *data) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    // 确保32个连续线程访问32个连续内存位置
    float val = data[idx * stride];  // stride=1时最佳
}

// 2. 使用共享内存减少全局内存访问
__global__ void sharedMemoryOptimized(float *input, float *output) {
    __shared__ float cache[BLOCK_SIZE];

    int tid = threadIdx.x;
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    // 分块加载到共享内存
    for (int i = tid; i < DATA_SIZE; i += BLOCK_SIZE) {
        cache[tid] = input[i];
        __syncthreads();

        // 处理共享内存中的数据
        float result = process(cache[tid]);

        output[i] = result;
        __syncthreads();
    }
}

// 3. 使用向量化内存访问
__global__ void vectorizedAccess(float4 *data) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    // 一次访问128位（4个float）
    float4 vec = data[idx];
    vec.x *= 2.0f;
    vec.y *= 2.0f;
    vec.z *= 2.0f;
    vec.w *= 2.0f;
    data[idx] = vec;
}
```

#### GPU并行度分析

**理论并行度计算**：
```c
// 计算GPU理论并行度
int computeParallelism(int num_SM, int max_threads_per_SM) {
    return num_SM * max_threads_per_SM;
}

// 例如：84个SM × 1536个线程/SM = 129,024个并发线程
```

**实际并行度限制**：
- **寄存器使用**：每个线程使用的寄存器数量
- **共享内存使用**：每个Block使用的共享内存量
- **线程块数量**：每个SM能容纳的Block数量
- **内存带宽**：内存访问限制

#### GPU架构发展趋势

**当前趋势**：
- **更多核心**：增加并行处理能力
- **专用硬件**：Tensor Core、RT Core
- **内存技术**：HBM、GDDR6X
- **能效优化**：提高性能功耗比

**未来方向**：
- **存内计算**：减少数据移动
- **光互连**：提高通信带宽
- **量子计算**：混合计算架构
- **神经形态**：类脑计算架构

#### GPU架构选择指南

| 应用类型 | 推荐架构 | 原因 |
|---------|---------|------|
| 传统CUDA | Ampere | 成熟稳定 |
| AI训练 | Hopper | 第四代Tensor Core |
| 图形渲染 | Ada Lovelace | RTX 40系列 |
| 高性能计算 | H100 | 最高计算能力 |

#### GPU性能监控

**CUDA工具包监控**：
```bash
# nvidia-smi监控GPU状态
nvidia-smi

# nvprof性能分析
nvprof --print-gpu-trace ./program

# Nsight Systems系统级分析
nsys profile ./program

# Nsight Compute内核级分析
ncu ./program
```

**代码内性能监控**：
```c
#include <cuda_runtime.h>

// GPU时间测量
cudaEvent_t start, stop;
float milliseconds = 0;

cudaEventCreate(&start);
cudaEventCreate(&stop);

cudaEventRecord(start);
// GPU计算代码
kernel<<<blocks, threads>>>(data);
cudaEventRecord(stop);

cudaEventSynchronize(stop);
cudaEventElapsedTime(&milliseconds, start, stop);

printf("Kernel execution time: %f ms\n", milliseconds);
```

### 4.2 CUDA编程模型

#### Kernel函数设计

**Kernel函数特性**：
- **执行位置**：在GPU上执行
- **调用方式**：主机代码调用
- **并行执行**：多个线程同时执行
- **限制**：不能递归，不能使用动态内存分配

**Kernel函数声明**：
```c
// __global__ 标识符表示这是GPU执行的函数
__global__ void vectorAdd(float *a, float *b, float *c, int n) {
    // 线程索引计算
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    // 边界检查
    if (idx < n) {
        c[idx] = a[idx] + b[idx];
    }
}

// Kernel调用语法
// <<<grid_dim, block_dim>>> 指定执行配置
vectorAdd<<<num_blocks, block_size>>>(d_a, d_b, d_c, n);
```

**执行配置策略**：
```c
// 1. 计算最佳block大小
int getOptimalBlockSize(int max_threads_per_block) {
    // 通常选择32的倍数，推荐128或256
    return min(256, max_threads_per_block);
}

// 2. 计算grid大小
int getGridSize(int data_size, int block_size) {
    return (data_size + block_size - 1) / block_size;
}

// 3. 实际使用
int block_size = getOptimalBlockSize(1024);
int grid_size = getGridSize(n, block_size);
kernel<<<grid_size, block_size>>>(data);
```

**Kernel函数类型**：
```c
// __global__ 函数：GPU执行，主机调用
__global__ void gpu_kernel(float *data);

// __device__ 函数：GPU执行，GPU调用
__device__ float compute(float x, float y);

// __host__ 函数：主机执行，主机调用
__host__ void host_function();

// __host__ __device__ 函数：主机和GPU都能执行
__host__ __device__ float inline_function(float x);
```

#### 线程层次管理

**线程索引计算**：
```c
// 一维线程索引
__global__ void kernel_1d(int *data) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    data[idx] = idx;
}

// 二维线程索引
__global__ void kernel_2d(float *matrix, int width, int height) {
    int row = blockIdx.y * blockDim.y + threadIdx.y;
    int col = blockIdx.x * blockDim.x + threadIdx.x;

    if (row < height && col < width) {
        int idx = row * width + col;
        matrix[idx] = row + col;
    }
}

// 三维线程索引
__global__ void kernel_3d(float *volume, int width, int height, int depth) {
    int x = blockIdx.x * blockDim.x + threadIdx.x;
    int y = blockIdx.y * blockDim.y + threadIdx.y;
    int z = blockIdx.z * blockDim.z + threadIdx.z;

    if (x < width && y < height && z < depth) {
        int idx = z * width * height + y * width + x;
        volume[idx] = x * y * z;
    }
}
```

**Warp内同步**：
```c
__global__ void warp_synchronization(float *data) {
    int tid = threadIdx.x;
    int warp_id = tid / 32;
    int lane_id = tid % 32;

    // Warp内所有线程执行相同操作
    float val = data[tid];

    // Warp内归约操作
    for (int offset = 16; offset > 0; offset /= 2) {
        val += __shfl_down_sync(0xFFFFFFFF, val, offset);
    }

    // 只有Warp的第一个线程保存结果
    if (lane_id == 0) {
        data[warp_id] = val;
    }
}
```

**线程束分支优化**：
```c
// 不好的分支设计（导致分支发散）
__global__ void bad_branching(float *data) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    if (idx % 2 == 0) {
        // 偶数线程路径
        data[idx] *= 2.0f;
    } else {
        // 奇数线程路径
        data[idx] += 1.0f;
    }
    // 导致Warp内分支发散
}

// 好的分支设计（避免分支发散）
__global__ void good_branching(float *data) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    // 重新组织索引，使同一Warp内的线程走相同路径
    int warp_base = (idx / 32) * 32;
    int lane_id = idx % 32;

    if (lane_id < 16) {
        // 前16个线程
        data[idx] *= 2.0f;
    } else {
        // 后16个线程
        data[idx] += 1.0f;
    }
}
```

#### 内存管理

**内存分配和释放**：
```c
// 主机内存分配
float *h_data = (float*)malloc(size * sizeof(float));

// 设备内存分配
float *d_data;
cudaMalloc(&d_data, size * sizeof(float));

// 内存拷贝
cudaMemcpy(d_data, h_data, size * sizeof(float), cudaMemcpyHostToDevice);

// 内存释放
cudaFree(d_data);
free(h_data);
```

**内存类型选择**：
```c
// 1. 全局内存：大数据集
float *d_global_data;
cudaMalloc(&d_global_data, large_size * sizeof(float));

// 2. 共享内存：小数据集，线程间共享
__global__ void shared_memory_kernel() {
    __shared__ float shared_data[256];
    // 使用共享内存
}

// 3. 常量内存：只读数据
__constant__ float const_data[256];

// 4. 纹理内存：空间局部性访问
texture<float, cudaTextureType1D, cudaReadModeElementType> tex_data;
```

**内存对齐优化**：
```c
// 结构体对齐
struct AlignedData {
    float x, y, z;  // 12字节
    float padding;  // 4字节填充到16字节
} __attribute__((aligned(16)));

// SIMD对齐内存分配
float *aligned_data;
posix_memalign((void**)&aligned_data, 32, size * sizeof(float));

// CUDA对齐分配
float *cuda_aligned_data;
cudaMalloc(&cuda_aligned_data, size * sizeof(float));
```

#### CUDA流和事件

**流管理**：
```c
// 创建CUDA流
cudaStream_t stream1, stream2;
cudaStreamCreate(&stream1);
cudaStreamCreate(&stream2);

// 异步内存拷贝
cudaMemcpyAsync(d_data1, h_data1, size1, cudaMemcpyHostToDevice, stream1);
cudaMemcpyAsync(d_data2, h_data2, size2, cudaMemcpyHostToDevice, stream2);

// 异步Kernel执行
kernel1<<<blocks, threads, 0, stream1>>>(d_data1);
kernel2<<<blocks, threads, 0, stream2>>>(d_data2);

// 同步流
cudaStreamSynchronize(stream1);
cudaStreamSynchronize(stream2);

// 销毁流
cudaStreamDestroy(stream1);
cudaStreamDestroy(stream2);
```

**事件同步**：
```c
// 创建事件
cudaEvent_t start, stop;
cudaEventCreate(&start);
cudaEventCreate(&stop);

// 记录事件
cudaEventRecord(start, 0);
// 执行GPU操作
kernel<<<blocks, threads>>>(data);
cudaEventRecord(stop, 0);

// 等待完成并计算时间
cudaEventSynchronize(stop);
float milliseconds = 0;
cudaEventElapsedTime(&milliseconds, start, stop);

// 销毁事件
cudaEventDestroy(start);
cudaEventDestroy(stop);
```

#### CUDA错误处理

**错误检查宏**：
```c
#define CUDA_CHECK(call) \
do { \
    cudaError_t error = call; \
    if (error != cudaSuccess) { \
        fprintf(stderr, "CUDA error at %s:%d - %s\n", __FILE__, __LINE__, \
                cudaGetErrorString(error)); \
        exit(1); \
    } \
} while(0)

// 使用示例
CUDA_CHECK(cudaMalloc(&d_data, size * sizeof(float)));
CUDA_CHECK(cudaMemcpy(d_data, h_data, size * sizeof(float), cudaMemcpyHostToDevice));
CUDA_CHECK(cudaDeviceSynchronize());
```

**运行时错误处理**：
```c
// 检查Kernel执行错误
kernel<<<blocks, threads>>>(data);
cudaError_t error = cudaGetLastError();
if (error != cudaSuccess) {
    fprintf(stderr, "Kernel launch failed: %s\n", cudaGetErrorString(error));
}

// 检查同步错误
error = cudaDeviceSynchronize();
if (error != cudaSuccess) {
    fprintf(stderr, "CUDA sync failed: %s\n", cudaGetErrorString(error));
}
```

### 4.3 GPU优化技术

#### 内存访问优化

**合并内存访问**：
```c
// 好的内存访问模式
__global__ void coalesced_access(float *input, float *output) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    // 连续的线程访问连续的内存地址
    // 线程0访问input[0]，线程1访问input[1]，等等
    float val = input[idx];
    output[idx] = val * 2.0f;
}

// 不好的内存访问模式
__global__ void uncoalesced_access(float *input, float *output) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    // 非连续访问，导致内存事务增加
    float val = input[idx * stride];  // stride > 1
    output[idx] = val * 2.0f;
}
```

**共享内存优化**：
```c
// 使用共享内存减少全局内存访问
__global__ void shared_memory_optimized(float *input, float *output, int width) {
    __shared__ float tile[TILE_SIZE][TILE_SIZE + 1];  // +1避免bank conflict

    int tx = threadIdx.x;
    int ty = threadIdx.y;
    int bx = blockIdx.x * TILE_SIZE;
    int by = blockIdx.y * TILE_SIZE;

    // 加载数据到共享内存
    for (int i = 0; i < TILE_SIZE; i += BLOCK_SIZE_Y) {
        int y = by + ty + i;
        int x = bx + tx;
        if (y < width && x < width) {
            tile[ty + i][tx] = input[y * width + x];
        }
    }
    __syncthreads();

    // 处理共享内存中的数据
    float result = 0.0f;
    for (int k = 0; k < TILE_SIZE; k++) {
        result += tile[ty][k] * tile[k][tx];
    }

    // 写回结果
    int y = by + ty;
    int x = bx + tx;
    if (y < width && x < width) {
        output[y * width + x] = result;
    }
}
```

**内存bank冲突避免**：
```c
// 避免bank冲突的共享内存布局
__shared__ float data[BLOCK_SIZE][BANK_SIZE + 1];  // +1避免冲突

// 访问模式示例
int idx = threadIdx.x;
float val = data[threadIdx.y][idx];  // 不同bank访问

// 如果必须访问同一bank的不同位置，使用交错访问
__shared__ float bank_conflict_data[32];
// 避免：bank_conflict_data[threadIdx.x * 2]
// 推荐：bank_conflict_data[threadIdx.x]
```

#### 计算优化

**指令级并行**：
```c
// 增加指令级并行度
__global__ void instruction_level_parallel(float *a, float *b, float *c, int n) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    if (idx < n) {
        // 独立的计算操作可以并行执行
        float x = a[idx];
        float y = b[idx];

        // 这些操作是独立的，可以并行执行
        float result1 = x * x + y * y;
        float result2 = x * y - 1.0f;
        float result3 = sin(x) + cos(y);

        c[idx] = result1 + result2 + result3;
    }
}
```

**算术优化**：
```c
// 使用快速数学函数
__global__ void fast_math(float *data, int n) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    if (idx < n) {
        // 使用内建函数，通常更快
        float x = data[idx];

        // 快速平方根
        float sqrt_x = sqrtf(x);

        // 快速倒数平方根
        float inv_sqrt = rsqrtf(x);

        // 快速指数
        float exp_x = expf(x);

        data[idx] = sqrt_x + inv_sqrt + exp_x;
    }
}

// 使用内在函数
__global__ void intrinsic_functions(float *a, float *b, float *c) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    // 使用内在函数通常比标准库函数更快
    float x = __sinf(a[idx]);      // 比sinf()快
    float y = __cosf(b[idx]);      // 比cosf()快
    float z = __expf(c[idx]);      // 比expf()快

    // 位操作内在函数
    int mask = __ballot_sync(0xFFFFFFFF, x > 0.0f);  // Warp内投票
    int leading_zeros = __clz(mask);                 // 前导零计数
}
```

**寄存器优化**：
```c
// 减少寄存器使用
__global__ void register_optimized(float *input, float *output, int n) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    if (idx < n) {
        // 重用变量减少寄存器压力
        float temp = input[idx];
        temp = temp * temp;        // 重用temp
        temp = temp + 1.0f;        // 继续重用
        temp = sqrtf(temp);        // 最终计算

        output[idx] = temp;
    }
}

// 使用合适的变量类型
__global__ void type_optimized(float *input, float *output) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    // 使用float而不是double（除非需要双精度）
    float val = input[idx];

    // 使用int而不是long long（如果范围允许）
    int index = idx;

    output[index] = val * 2.0f;
}
```

#### 并发优化

**多Kernel并发**：
```c
// 使用多个流实现Kernel并发
void concurrent_kernels(float *h_data1, float *h_data2, int size1, int size2) {
    cudaStream_t stream1, stream2;

    // 分配设备内存
    float *d_data1, *d_data2;
    cudaMalloc(&d_data1, size1 * sizeof(float));
    cudaMalloc(&d_data2, size2 * sizeof(float));

    // 创建流
    cudaStreamCreate(&stream1);
    cudaStreamCreate(&stream2);

    // 异步内存拷贝
    cudaMemcpyAsync(d_data1, h_data1, size1 * sizeof(float),
                    cudaMemcpyHostToDevice, stream1);
    cudaMemcpyAsync(d_data2, h_data2, size2 * sizeof(float),
                    cudaMemcpyHostToDevice, stream2);

    // 并发Kernel执行
    kernel1<<<blocks1, threads1, 0, stream1>>>(d_data1);
    kernel2<<<blocks2, threads2, 0, stream2>>>(d_data2);

    // 同步
    cudaStreamSynchronize(stream1);
    cudaStreamSynchronize(stream2);

    // 清理
    cudaStreamDestroy(stream1);
    cudaStreamDestroy(stream2);
    cudaFree(d_data1);
    cudaFree(d_data2);
}
```

**内存和计算重叠**：
```c
// 重叠内存传输和计算
void overlap_memory_compute(float *h_data, float *d_data, int size) {
    cudaStream_t compute_stream, copy_stream;

    cudaStreamCreate(&compute_stream);
    cudaStreamCreate(&copy_stream);

    // 第一部分数据传输
    cudaMemcpyAsync(d_data, h_data, size/2 * sizeof(float),
                    cudaMemcpyHostToDevice, copy_stream);

    // 等待第一部分传输完成
    cudaStreamSynchronize(copy_stream);

    // 开始计算第一部分
    kernel<<<blocks, threads, 0, compute_stream>>>(d_data, size/2);

    // 同时传输第二部分数据
    cudaMemcpyAsync(&d_data[size/2], &h_data[size/2], size/2 * sizeof(float),
                    cudaMemcpyHostToDevice, copy_stream);

    // 等待所有操作完成
    cudaStreamSynchronize(compute_stream);
    cudaStreamSynchronize(copy_stream);

    cudaStreamDestroy(compute_stream);
    cudaStreamDestroy(copy_stream);
}
```

#### 性能分析和调优

**性能分析工具使用**：
```bash
# 使用nvprof进行性能分析
nvprof --metrics achieved_occupancy,gld_efficiency,shared_efficiency ./program

# 使用Nsight Compute分析内核性能
ncu --set full --metrics sm__throughput.avg.pct_of_peak_sustained_elapsed ./program

# 使用Nsight Systems进行系统级分析
nsys profile --trace=cuda,nvtx ./program
```

**手动性能监控**：
```c
// 详细的性能监控
void detailed_performance_monitoring() {
    cudaEvent_t start, stop;
    float kernel_time, memory_time;

    // 测量Kernel执行时间
    cudaEventCreate(&start);
    cudaEventCreate(&stop);

    cudaEventRecord(start);
    kernel<<<blocks, threads>>>(data);
    cudaEventRecord(stop);
    cudaEventSynchronize(stop);
    cudaEventElapsedTime(&kernel_time, start, stop);

    // 测量内存传输时间
    cudaEventRecord(start);
    cudaMemcpy(d_data, h_data, size, cudaMemcpyHostToDevice);
    cudaEventRecord(stop);
    cudaEventSynchronize(stop);
    cudaEventElapsedTime(&memory_time, start, stop);

    printf("Kernel time: %f ms\n", kernel_time);
    printf("Memory time: %f ms\n", memory_time);
    printf("Computation to communication ratio: %f\n",
           kernel_time / memory_time);

    cudaEventDestroy(start);
    cudaEventDestroy(stop);
}
```

**优化检查清单**：
```c
// GPU优化检查清单
void optimization_checklist() {
    // 1. 内存访问优化
    // ✅ 合并内存访问
    // ✅ 使用共享内存
    // ✅ 避免bank冲突
    // ✅ 内存对齐

    // 2. 计算优化
    // ✅ 使用快速数学函数
    // ✅ 增加指令级并行
    // ✅ 减少寄存器使用
    // ✅ 选择合适的变量类型

    // 3. 并发优化
    // ✅ 使用多流
    // ✅ 重叠计算和内存传输
    // ✅ 并发Kernel执行

    // 4. 内核配置优化
    // ✅ 选择合适的block大小
    // ✅ 确保高占用率
    // ✅ 避免分支发散
}
```

#### GPU优化策略总结

| 优化类型 | 目标 | 方法 | 预期收益 |
|---------|------|------|---------|
| 内存访问 | 减少内存延迟 | 合并访问、共享内存 | 2-10倍 |
| 计算优化 | 提高计算效率 | 快速函数、指令并行 | 1.5-3倍 |
| 并发优化 | 提高资源利用率 | 多流、重叠执行 | 1.5-5倍 |
| 内核配置 | 提高硬件利用率 | 优化block大小、减少发散 | 1.2-2倍 |

## 第5章 分布式计算

### 5.1 分布式系统基础

#### 分布式系统概念

**定义和特征**：
- **分布式系统**：由多台独立计算机组成的系统，通过网络连接协同工作
- **透明性**：用户感知不到系统的分布性
- **可扩展性**：能够通过增加节点来提升性能
- **容错性**：部分节点故障不影响整体系统运行

**分布式系统优势**：
- **性能提升**：并行处理能力
- **资源利用**：整合分散的计算资源
- **可靠性**：冗余设计提高系统可靠性
- **成本效益**：使用商用硬件构建高性能系统

**分布式系统挑战**：
- **网络延迟**：通信开销和延迟
- **数据一致性**：分布式数据同步问题
- **故障处理**：节点故障检测和恢复
- **负载均衡**：任务分配和资源调度

#### 节点通信

**通信模型**：
```c
// 1. 点对点通信模型
// 每个节点直接与其他节点通信
Node A → Node B
Node A → Node C
Node B → Node C

// 2. 客户端-服务器模型
// 客户端请求，服务器响应
Client → Server
Client ← Server

// 3. 发布-订阅模型
// 消息发布和订阅机制
Publisher → Message Broker → Subscriber
```

**通信协议**：
```c
// TCP/IP协议栈
// 应用层
//   ↓
// 传输层 (TCP/UDP)
//   ↓
// 网络层 (IP)
//   ↓
// 数据链路层 (Ethernet)
//   ↓
// 物理层
```

**网络拓扑结构**：
- **星型拓扑**：所有节点连接到中心节点
- **环形拓扑**：节点形成环状连接
- **网状拓扑**：节点间有多条连接路径
- **树形拓扑**：层次化结构连接

**通信优化策略**：
```c
// 1. 消息聚合
// 将多个小消息合并为大消息
void aggregate_messages(Message *messages, int count, Message *aggregated) {
    int total_size = 0;
    for (int i = 0; i < count; i++) {
        total_size += messages[i].size;
    }

    aggregated->data = malloc(total_size);
    int offset = 0;
    for (int i = 0; i < count; i++) {
        memcpy(aggregated->data + offset, messages[i].data, messages[i].size);
        offset += messages[i].size;
    }
    aggregated->size = total_size;
}

// 2. 异步通信
// 非阻塞通信提高效率
typedef struct {
    int node_id;
    void *data;
    size_t size;
    int completed;
} AsyncRequest;

AsyncRequest send_async(int dest_node, void *data, size_t size) {
    AsyncRequest req;
    req.node_id = dest_node;
    req.data = data;
    req.size = size;
    req.completed = 0;

    // 启动异步发送
    start_async_send(&req);

    return req;
}

int check_completion(AsyncRequest *req) {
    return req->completed;
}
```

**网络通信库**：
- **MPI (Message Passing Interface)**：标准分布式通信接口
- **gRPC**：高性能RPC框架
- **ZeroMQ**：轻量级消息队列
- **Apache Thrift**：跨语言RPC框架

#### 负载均衡

**负载均衡策略**：
```c
// 1. 静态负载均衡
// 预先分配任务，不考虑运行时状态
typedef struct {
    int node_id;
    int task_count;
    Task *tasks[MAX_TASKS];
} StaticAssignment;

void static_load_balancing(Task *tasks, int task_count, Node *nodes, int node_count) {
    int tasks_per_node = task_count / node_count;

    for (int i = 0; i < node_count; i++) {
        nodes[i].task_count = tasks_per_node;
        for (int j = 0; j < tasks_per_node; j++) {
            nodes[i].tasks[j] = &tasks[i * tasks_per_node + j];
        }
    }
}

// 2. 动态负载均衡
// 根据运行时状态动态分配任务
typedef struct {
    int node_id;
    int current_load;
    int max_capacity;
} NodeStatus;

void dynamic_load_balancing(TaskQueue *task_queue, NodeStatus *nodes, int node_count) {
    while (!task_queue_empty(task_queue)) {
        // 找到负载最轻的节点
        int min_load_node = find_min_load_node(nodes, node_count);

        if (nodes[min_load_node].current_load < nodes[min_load_node].max_capacity) {
            Task *task = dequeue_task(task_queue);
            assign_task_to_node(task, min_load_node);
            nodes[min_load_node].current_load++;
        } else {
            // 节点已满，等待其他节点完成任务
            wait_for_completion();
        }
    }
}

// 3. 工作窃取 (Work Stealing)
// 空闲节点从忙碌节点窃取任务
void work_stealing_load_balancing(TaskQueue *local_queues[], int queue_count) {
    int my_queue = get_my_queue_id();

    // 尝试从本地队列获取任务
    Task *task = dequeue_task(local_queues[my_queue]);
    if (task == NULL) {
        // 本地队列为空，尝试窃取
        for (int i = 0; i < queue_count; i++) {
            int victim = (my_queue + i) % queue_count;
            if (victim != my_queue) {
                task = steal_task(local_queues[victim]);
                if (task != NULL) {
                    break;
                }
            }
        }
    }

    if (task != NULL) {
        execute_task(task);
    }
}
```

**负载均衡算法**：
```c
// 轮询调度 (Round Robin)
int round_robin_scheduler(int current_node, int node_count) {
    return (current_node + 1) % node_count;
}

// 最少连接数 (Least Connections)
int least_connections_scheduler(NodeStatus *nodes, int node_count) {
    int min_connections = INT_MAX;
    int selected_node = 0;

    for (int i = 0; i < node_count; i++) {
        if (nodes[i].current_connections < min_connections) {
            min_connections = nodes[i].current_connections;
            selected_node = i;
        }
    }

    return selected_node;
}

// 加权轮询 (Weighted Round Robin)
int weighted_round_robin_scheduler(NodeStatus *nodes, int node_count) {
    static int current_index = 0;
    static int current_weight = 0;

    // 找到最大权重
    int max_weight = 0;
    for (int i = 0; i < node_count; i++) {
        if (nodes[i].weight > max_weight) {
            max_weight = nodes[i].weight;
        }
    }

    while (1) {
        current_index = (current_index + 1) % node_count;

        if (current_index == 0) {
            current_weight--;
            if (current_weight <= 0) {
                current_weight = max_weight;
                if (current_weight == 0) {
                    return 0;
                }
            }
        }

        if (nodes[current_index].weight >= current_weight) {
            return current_index;
        }
    }
}
```

**负载均衡监控**：
```c
// 负载监控和报告
typedef struct {
    double cpu_usage;
    double memory_usage;
    double network_bandwidth;
    int active_tasks;
    time_t last_update;
} LoadMetrics;

LoadMetrics get_node_load(int node_id) {
    LoadMetrics metrics;

    // 获取CPU使用率
    metrics.cpu_usage = get_cpu_usage();

    // 获取内存使用率
    metrics.memory_usage = get_memory_usage();

    // 获取网络带宽
    metrics.network_bandwidth = get_network_bandwidth();

    // 获取活跃任务数
    metrics.active_tasks = get_active_task_count();

    metrics.last_update = time(NULL);

    return metrics;
}

void report_load_balancing_status(NodeStatus *nodes, int node_count) {
    printf("Load Balancing Status:\n");
    printf("Node\tCPU\tMemory\tTasks\tCapacity\n");
    printf("----\t---\t------\t-----\t--------\n");

    for (int i = 0; i < node_count; i++) {
        LoadMetrics metrics = get_node_load(nodes[i].node_id);
        printf("%d\t%.2f%%\t%.2f%%\t%d\t%d\n",
               nodes[i].node_id,
               metrics.cpu_usage * 100,
               metrics.memory_usage * 100,
               metrics.active_tasks,
               nodes[i].max_capacity);
    }
}
```

#### 容错机制

**故障检测**：
```c
// 心跳机制检测节点故障
typedef struct {
    int node_id;
    time_t last_heartbeat;
    int is_alive;
} HeartbeatMonitor;

void start_heartbeat_monitoring(HeartbeatMonitor *monitors, int node_count) {
    for (int i = 0; i < node_count; i++) {
        monitors[i].last_heartbeat = time(NULL);
        monitors[i].is_alive = 1;
    }

    // 启动心跳检测线程
    pthread_t heartbeat_thread;
    pthread_create(&heartbeat_thread, NULL, heartbeat_checker, monitors);
}

void *heartbeat_checker(void *arg) {
    HeartbeatMonitor *monitors = (HeartbeatMonitor *)arg;
    int node_count = get_node_count();

    while (1) {
        sleep(HEARTBEAT_INTERVAL);

        time_t current_time = time(NULL);

        for (int i = 0; i < node_count; i++) {
            if (current_time - monitors[i].last_heartbeat > HEARTBEAT_TIMEOUT) {
                if (monitors[i].is_alive) {
                    printf("Node %d detected as failed\n", monitors[i].node_id);
                    handle_node_failure(monitors[i].node_id);
                    monitors[i].is_alive = 0;
                }
            }
        }
    }
}

// 发送心跳信号
void send_heartbeat(int node_id) {
    // 发送心跳消息到监控节点
    Message heartbeat_msg;
    heartbeat_msg.type = MSG_HEARTBEAT;
    heartbeat_msg.source = node_id;
    heartbeat_msg.timestamp = time(NULL);

    send_message_to_monitor(&heartbeat_msg);
}
```

**故障恢复策略**：
```c
// 1. 主动-备用 (Active-Standby) 模式
typedef struct {
    int primary_node;
    int standby_node;
    int status;  // 0: primary active, 1: standby active
} FailoverPair;

void handle_primary_failure(FailoverPair *pair) {
    printf("Primary node %d failed, switching to standby node %d\n",
           pair->primary_node, pair->standby_node);

    // 停止主节点服务
    stop_node_service(pair->primary_node);

    // 启动备用节点服务
    start_node_service(pair->standby_node);

    // 更新状态
    pair->status = 1;
    pair->primary_node = pair->standby_node;

    // 通知其他节点
    broadcast_failover_notification(pair);
}

// 2. 主动-主动 (Active-Active) 模式
// 多个节点同时提供服务，故障时自动重定向
void active_active_failover(int failed_node, int *active_nodes, int node_count) {
    printf("Node %d failed in active-active cluster\n", failed_node);

    // 从活跃节点列表中移除故障节点
    remove_node_from_list(active_nodes, &node_count, failed_node);

    // 重新分配故障节点的任务
    redistribute_tasks(failed_node, active_nodes, node_count);

    // 更新路由表
    update_routing_table(active_nodes, node_count);
}

// 3. 数据复制和恢复
typedef struct {
    int replica_id;
    int data_version;
    char *data;
    int is_primary;
} DataReplica;

void replicate_data(DataReplica *primary, DataReplica *replicas, int replica_count) {
    for (int i = 0; i < replica_count; i++) {
        if (!replicas[i].is_primary) {
            // 复制数据到副本
            memcpy(replicas[i].data, primary->data, DATA_SIZE);
            replicas[i].data_version = primary->data_version;

            // 确认复制完成
            if (verify_replication(&replicas[i])) {
                printf("Data replicated to replica %d\n", replicas[i].replica_id);
            } else {
                printf("Replication failed for replica %d\n", replicas[i].replica_id);
            }
        }
    }
}

void recover_from_failure(DataReplica *replicas, int replica_count) {
    // 找到最新的数据版本
    int latest_version = 0;
    DataReplica *latest_replica = NULL;

    for (int i = 0; i < replica_count; i++) {
        if (replicas[i].data_version > latest_version) {
            latest_version = replicas[i].data_version;
            latest_replica = &replicas[i];
        }
    }

    if (latest_replica != NULL) {
        printf("Recovering data from replica %d (version %d)\n",
               latest_replica->replica_id, latest_version);

        // 使用最新副本恢复数据
        restore_data_from_replica(latest_replica);
    }
}
```

**容错系统设计原则**：
```c
// 1. 冗余设计
// 关键组件的多重备份
typedef struct {
    int service_id;
    ServiceInstance primary;
    ServiceInstance backup[BACKUP_COUNT];
} RedundantService;

// 2. 快速故障检测
// 短时间间隔的心跳检测
#define HEARTBEAT_INTERVAL 1    // 1秒
#define HEARTBEAT_TIMEOUT 3     // 3秒超时

// 3. 自动故障转移
// 无需人工干预的自动切换
void automatic_failover_handler() {
    // 检测到故障
    if (detect_node_failure()) {
        // 自动切换到备用节点
        switch_to_standby_node();
        // 通知管理系统
        notify_management_system();
    }
}

// 4. 数据一致性保证
// 使用分布式一致性算法
typedef enum {
    STATE_FOLLOWER,
    STATE_CANDIDATE,
    STATE_LEADER
} RaftState;

// Raft一致性算法状态
typedef struct {
    RaftState state;
    int term;
    int voted_for;
    int commit_index;
    int last_applied;
} RaftNode;
```

#### 分布式系统架构模式

**微服务架构**：
```c
// 服务注册和发现
typedef struct {
    char service_name[64];
    char service_address[128];
    int port;
    int health_status;
    time_t last_heartbeat;
} ServiceRegistry;

// 服务注册
int register_service(ServiceRegistry *service) {
    // 向服务注册中心注册服务
    return send_registration_request(service);
}

// 服务发现
ServiceRegistry *discover_service(const char *service_name) {
    // 从注册中心查询服务
    return query_service_registry(service_name);
}

// 健康检查
int health_check(ServiceRegistry *service) {
    // 发送健康检查请求
    return send_health_check_request(service);
}
```

**主从架构**：
```c
// 主节点选举
typedef struct {
    int node_id;
    int priority;
    int current_master;
    int candidates[MAX_NODES];
} MasterElection;

int elect_master(MasterElection *election) {
    // 使用优先级选举主节点
    int highest_priority = -1;
    int elected_master = -1;

    for (int i = 0; i < election->node_count; i++) {
        if (election->candidates[i] > highest_priority) {
            highest_priority = election->candidates[i];
            elected_master = i;
        }
    }

    return elected_master;
}
```

**对等网络 (P2P)**：
```c
// 节点发现和连接
typedef struct {
    int node_id;
    char ip_address[64];
    int port;
    int connected_peers[MAX_PEERS];
    int peer_count;
} PeerNode;

// 加入P2P网络
int join_p2p_network(PeerNode *node, const char *bootstrap_ip) {
    // 连接到引导节点
    int bootstrap_fd = connect_to_node(bootstrap_ip, BOOTSTRAP_PORT);

    // 获取网络中的其他节点信息
    NodeInfo *peers = get_peer_list(bootstrap_fd);

    // 连接到多个节点建立网络连接
    for (int i = 0; i < peers->count; i++) {
        if (node->peer_count < MAX_PEERS) {
            int peer_fd = connect_to_node(peers->nodes[i].ip, peers->nodes[i].port);
            if (peer_fd > 0) {
                node->connected_peers[node->peer_count++] = peer_fd;
            }
        }
    }

    close(bootstrap_fd);
    return node->peer_count;
}
```

#### 分布式系统监控

**监控指标**：
```c
// 系统监控指标
typedef struct {
    // 性能指标
    double cpu_usage;
    double memory_usage;
    double disk_usage;
    double network_bandwidth;

    // 服务指标
    int active_connections;
    int request_rate;
    int error_rate;
    double response_time;

    // 集群指标
    int node_count;
    int healthy_nodes;
    int failed_nodes;
    double cluster_utilization;

    time_t timestamp;
} SystemMetrics;

// 收集系统指标
SystemMetrics collect_system_metrics() {
    SystemMetrics metrics;

    // 收集CPU使用率
    metrics.cpu_usage = get_cpu_usage_percentage();

    // 收集内存使用率
    metrics.memory_usage = get_memory_usage_percentage();

    // 收集磁盘使用率
    metrics.disk_usage = get_disk_usage_percentage();

    // 收集网络带宽
    metrics.network_bandwidth = get_network_bandwidth_usage();

    // 收集服务指标
    metrics.active_connections = get_active_connection_count();
    metrics.request_rate = get_request_rate();
    metrics.error_rate = get_error_rate();
    metrics.response_time = get_average_response_time();

    // 收集集群指标
    metrics.node_count = get_cluster_node_count();
    metrics.healthy_nodes = get_healthy_node_count();
    metrics.failed_nodes = get_failed_node_count();
    metrics.cluster_utilization = get_cluster_utilization();

    metrics.timestamp = time(NULL);

    return metrics;
}

// 监控数据上报
void report_metrics_to_monitoring(SystemMetrics *metrics) {
    // 发送到监控系统
    send_to_monitoring_system(metrics);

    // 检查告警条件
    check_alert_conditions(metrics);
}

// 告警检查
void check_alert_conditions(SystemMetrics *metrics) {
    if (metrics->cpu_usage > CPU_ALERT_THRESHOLD) {
        send_alert("High CPU usage detected: %.2f%%", metrics->cpu_usage * 100);
    }

    if (metrics->memory_usage > MEMORY_ALERT_THRESHOLD) {
        send_alert("High memory usage detected: %.2f%%", metrics->memory_usage * 100);
    }

    if (metrics->error_rate > ERROR_RATE_ALERT_THRESHOLD) {
        send_alert("High error rate detected: %.2f%%", metrics->error_rate * 100);
    }
}
```

**分布式追踪**：
```c
// 请求追踪
typedef struct {
    char trace_id[64];
    char span_id[64];
    char parent_span_id[64];
    char operation_name[128];
    time_t start_time;
    time_t end_time;
    char tags[MAX_TAGS][256];
    int tag_count;
} TraceSpan;

// 开始追踪
TraceSpan *start_trace(const char *operation_name) {
    TraceSpan *span = malloc(sizeof(TraceSpan));
    generate_trace_id(span->trace_id);
    generate_span_id(span->span_id);
    span->operation_name = strdup(operation_name);
    span->start_time = get_current_time();

    return span;
}

// 结束追踪
void end_trace(TraceSpan *span) {
    span->end_time = get_current_time();

    // 发送追踪数据到追踪系统
    send_trace_to_collector(span);

    free(span->operation_name);
    free(span);
}

// 跨服务追踪
void trace_service_call(const char *service_name, const char *operation) {
    TraceSpan *span = start_trace(operation);

    // 添加服务标签
    add_trace_tag(span, "service", service_name);

    // 执行服务调用
    perform_service_call(service_name, operation);

    // 结束追踪
    end_trace(span);
}
```

这个重构版本提供了：
- **理论基础**：分布式系统的核心概念和原理
- **实践指导**：具体的代码示例和实现方法
- **系统设计**：完整的架构模式和设计原则
- **监控管理**：全面的监控和故障处理机制
- **最佳实践**：经过验证的分布式系统设计模式

### 5.2 MPI编程

#### MPI基础概念

**MPI (Message Passing Interface) 概述**：
- **标准接口**：跨平台的并行编程标准
- **消息传递模型**：进程间通过消息传递进行通信
- **分布式内存**：每个进程有独立的内存空间
- **可移植性**：支持多种编程语言（C、C++、Fortran、Python）

**MPI环境初始化**：
```c
#include <mpi.h>
#include <stdio.h>

int main(int argc, char** argv) {
    // 初始化MPI环境
    MPI_Init(&argc, &argv);

    // 获取进程总数
    int world_size;
    MPI_Comm_size(MPI_COMM_WORLD, &world_size);

    // 获取当前进程的排名
    int world_rank;
    MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);

    // 获取处理器名称
    char processor_name[MPI_MAX_PROCESSOR_NAME];
    int name_len;
    MPI_Get_processor_name(processor_name, &name_len);

    printf("Hello world from processor %s, rank %d out of %d processors\n",
           processor_name, world_rank, world_size);

    // 最终化MPI环境
    MPI_Finalize();

    return 0;
}
```

**MPI编译和运行**：
```bash
# 编译MPI程序
mpicc -o hello_mpi hello_mpi.c

# 运行MPI程序（4个进程）
mpirun -np 4 ./hello_mpi

# 在特定节点上运行
mpirun -np 8 -hosts node1,node2 ./program

# 使用SLURM调度器
sbatch submit_mpi.sh  # 提交作业脚本
```

#### 点对点通信

**阻塞通信**：
```c
// 1. 基本的发送和接收
void basic_point_to_point() {
    int world_rank, world_size;
    MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);
    MPI_Comm_size(MPI_COMM_WORLD, &world_size);

    if (world_rank == 0) {
        int data = 42;
        // 发送数据到进程1
        MPI_Send(&data, 1, MPI_INT, 1, 0, MPI_COMM_WORLD);
        printf("Process 0 sent data %d to process 1\n", data);
    } else if (world_rank == 1) {
        int received_data;
        // 从进程0接收数据
        MPI_Recv(&received_data, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);
        printf("Process 1 received data %d from process 0\n", received_data);
    }
}

// 2. 数组数据传输
void array_communication() {
    int rank, size;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    const int ARRAY_SIZE = 1000;
    double *send_buffer = NULL;
    double *recv_buffer = NULL;

    if (rank == 0) {
        // 分配和初始化发送缓冲区
        send_buffer = malloc(ARRAY_SIZE * sizeof(double));
        for (int i = 0; i < ARRAY_SIZE; i++) {
            send_buffer[i] = i * 1.0;
        }

        // 发送数据到进程1
        MPI_Send(send_buffer, ARRAY_SIZE, MPI_DOUBLE, 1, 0, MPI_COMM_WORLD);
        printf("Process 0 sent array of size %d to process 1\n", ARRAY_SIZE);

        free(send_buffer);
    } else if (rank == 1) {
        // 分配接收缓冲区
        recv_buffer = malloc(ARRAY_SIZE * sizeof(double));

        // 接收数据
        MPI_Recv(recv_buffer, ARRAY_SIZE, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);
        printf("Process 1 received array, first element: %f\n", recv_buffer[0]);

        free(recv_buffer);
    }
}

// 3. 状态信息获取
void status_information() {
    int rank;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);

    if (rank == 0) {
        char message[] = "Hello from process 0";
        MPI_Send(message, strlen(message) + 1, MPI_CHAR, 1, 0, MPI_COMM_WORLD);
    } else if (rank == 1) {
        MPI_Status status;
        char buffer[100];

        MPI_Recv(buffer, 100, MPI_CHAR, 0, 0, MPI_COMM_WORLD, &status);

        printf("Received message: %s\n", buffer);
        printf("Message source: %d\n", status.MPI_SOURCE);
        printf("Message tag: %d\n", status.MPI_TAG);
        printf("Message error: %d\n", status.MPI_ERROR);
    }
}
```

**非阻塞通信**：
```c
// 1. 基本的非阻塞通信
void nonblocking_basic() {
    int rank;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);

    if (rank == 0) {
        int data = 123;
        MPI_Request request;
        MPI_Status status;

        // 发起非阻塞发送
        MPI_Isend(&data, 1, MPI_INT, 1, 0, MPI_COMM_WORLD, &request);

        // 执行一些计算工作
        for (int i = 0; i < 1000000; i++) {
            // 模拟计算
        }

        // 等待发送完成
        MPI_Wait(&request, &status);
        printf("Process 0: Nonblocking send completed\n");
    } else if (rank == 1) {
        int received_data;
        MPI_Request request;
        MPI_Status status;

        // 发起非阻塞接收
        MPI_Irecv(&received_data, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, &request);

        // 执行一些计算工作
        for (int i = 0; i < 1000000; i++) {
            // 模拟计算
        }

        // 等待接收完成
        MPI_Wait(&request, &status);
        printf("Process 1: Nonblocking receive completed, data: %d\n", received_data);
    }
}

// 2. 多个非阻塞操作
void multiple_nonblocking() {
    int rank, size;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    const int NUM_REQUESTS = 4;
    MPI_Request requests[NUM_REQUESTS];
    MPI_Status statuses[NUM_REQUESTS];
    int send_data[NUM_REQUESTS];
    int recv_data[NUM_REQUESTS];

    // 初始化数据
    for (int i = 0; i < NUM_REQUESTS; i++) {
        send_data[i] = rank * 100 + i;
    }

    // 发起多个非阻塞发送
    for (int i = 0; i < NUM_REQUESTS; i++) {
        int dest = (rank + 1) % size;
        MPI_Isend(&send_data[i], 1, MPI_INT, dest, i, MPI_COMM_WORLD, &requests[i]);
    }

    // 发起多个非阻塞接收
    for (int i = 0; i < NUM_REQUESTS; i++) {
        int source = (rank - 1 + size) % size;
        MPI_Irecv(&recv_data[i], 1, MPI_INT, source, i, MPI_COMM_WORLD, &requests[NUM_REQUESTS + i]);
    }

    // 等待所有通信完成
    MPI_Waitall(2 * NUM_REQUESTS, requests, statuses);

    printf("Process %d: All communication completed\n", rank);
    for (int i = 0; i < NUM_REQUESTS; i++) {
        printf("  Received: %d\n", recv_data[i]);
    }
}

// 3. 通信完成检查
void check_completion() {
    int rank;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);

    if (rank == 0) {
        int data = 456;
        MPI_Request request;
        int flag;

        MPI_Isend(&data, 1, MPI_INT, 1, 0, MPI_COMM_WORLD, &request);

        // 检查发送是否完成
        do {
            MPI_Test(&request, &flag, MPI_STATUS_IGNORE);
            if (!flag) {
                // 发送未完成，执行其他工作
                printf("Process 0: Send not completed, doing other work...\n");
                // 模拟工作
                for (int i = 0; i < 100000; i++);
            }
        } while (!flag);

        printf("Process 0: Send completed\n");
    } else if (rank == 1) {
        int received_data;
        MPI_Request request;
        int flag;

        MPI_Irecv(&received_data, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, &request);

        // 检查接收是否完成
        do {
            MPI_Test(&request, &flag, MPI_STATUS_IGNORE);
            if (!flag) {
                printf("Process 1: Receive not completed, doing other work...\n");
                for (int i = 0; i < 100000; i++);
            }
        } while (!flag);

        printf("Process 1: Receive completed, data: %d\n", received_data);
    }
}
```

**持久通信**：
```c
// 重复使用的通信操作
void persistent_communication() {
    int rank, size;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    if (size < 2) {
        printf("This example requires at least 2 processes\n");
        return;
    }

    const int BUFFER_SIZE = 100;
    int *send_buffer = malloc(BUFFER_SIZE * sizeof(int));
    int *recv_buffer = malloc(BUFFER_SIZE * sizeof(int));

    // 初始化缓冲区
    for (int i = 0; i < BUFFER_SIZE; i++) {
        send_buffer[i] = rank * 1000 + i;
    }

    // 创建持久发送请求
    MPI_Request send_request;
    MPI_Send_init(send_buffer, BUFFER_SIZE, MPI_INT, (rank + 1) % size, 0, MPI_COMM_WORLD, &send_request);

    // 创建持久接收请求
    MPI_Request recv_request;
    MPI_Recv_init(recv_buffer, BUFFER_SIZE, MPI_INT, (rank - 1 + size) % size, 0, MPI_COMM_WORLD, &recv_request);

    // 执行多次通信
    for (int iteration = 0; iteration < 3; iteration++) {
        // 启动持久通信
        MPI_Start(&send_request);
        MPI_Start(&recv_request);

        // 等待通信完成
        MPI_Wait(&send_request, MPI_STATUS_IGNORE);
        MPI_Wait(&recv_request, MPI_STATUS_IGNORE);

        printf("Iteration %d: Process %d received from process %d\n",
               iteration, rank, (rank - 1 + size) % size);
        printf("  First received element: %d\n", recv_buffer[0]);
    }

    // 释放持久通信请求
    MPI_Request_free(&send_request);
    MPI_Request_free(&recv_request);

    free(send_buffer);
    free(recv_buffer);
}
```

#### 集合通信

**基本集合操作**：
```c
// 1. 广播 (Broadcast)
void broadcast_example() {
    int rank, size;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    int data;
    if (rank == 0) {
        data = 12345;
        printf("Process 0: Broadcasting data %d\n", data);
    }

    // 广播数据，root=0
    MPI_Bcast(&data, 1, MPI_INT, 0, MPI_COMM_WORLD);

    printf("Process %d: Received broadcasted data %d\n", rank, data);
}

// 2. 规约操作 (Reduce)
void reduce_example() {
    int rank, size;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    int local_data = rank * 10;
    int global_sum, global_max, global_min;

    printf("Process %d: Local data = %d\n", rank, local_data);

    // 求和规约
    MPI_Reduce(&local_data, &global_sum, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);

    // 最大值规约
    MPI_Reduce(&local_data, &global_max, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);

    // 最小值规约
    MPI_Reduce(&local_data, &global_min, 1, MPI_INT, MPI_MIN, 0, MPI_COMM_WORLD);

    if (rank == 0) {
        printf("Process 0: Global sum = %d, max = %d, min = %d\n",
               global_sum, global_max, global_min);
    }
}

// 3. 全局规约 (Allreduce)
void allreduce_example() {
    int rank, size;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    int local_data = rank * 5;
    int global_sum;

    printf("Process %d: Local data = %d\n", rank, local_data);

    // 全局规约，所有进程都得到结果
    MPI_Allreduce(&local_data, &global_sum, 1, MPI_INT, MPI_SUM, MPI_COMM_WORLD);

    printf("Process %d: Global sum = %d\n", rank, global_sum);
}

// 4. 散发 (Scatter)
void scatter_example() {
    int rank, size;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    const int ARRAY_SIZE = 16;
    int *send_array = NULL;
    int recv_element;

    if (rank == 0) {
        // 主进程初始化数组
        send_array = malloc(ARRAY_SIZE * sizeof(int));
        for (int i = 0; i < ARRAY_SIZE; i++) {
            send_array[i] = i * 10;
        }

        printf("Process 0: Sending array [");
        for (int i = 0; i < ARRAY_SIZE; i++) {
            printf("%d ", send_array[i]);
        }
        printf("]\n");
    }

    // 散发数组元素到各个进程
    MPI_Scatter(send_array, ARRAY_SIZE / size, MPI_INT,
                &recv_element, ARRAY_SIZE / size, MPI_INT, 0, MPI_COMM_WORLD);

    printf("Process %d: Received element %d\n", rank, recv_element);

    if (rank == 0) {
        free(send_array);
    }
}

// 5. 收集 (Gather)
void gather_example() {
    int rank, size;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    const int ELEMENTS_PER_PROCESS = 4;
    int local_data[ELEMENTS_PER_PROCESS];
    int *gathered_data = NULL;

    // 每个进程初始化本地数据
    for (int i = 0; i < ELEMENTS_PER_PROCESS; i++) {
        local_data[i] = rank * 100 + i;
    }

    if (rank == 0) {
        gathered_data = malloc(size * ELEMENTS_PER_PROCESS * sizeof(int));
    }

    printf("Process %d: Local data [", rank);
    for (int i = 0; i < ELEMENTS_PER_PROCESS; i++) {
        printf("%d ", local_data[i]);
    }
    printf("]\n");

    // 收集所有进程的数据到根进程
    MPI_Gather(local_data, ELEMENTS_PER_PROCESS, MPI_INT,
               gathered_data, ELEMENTS_PER_PROCESS, MPI_INT, 0, MPI_COMM_WORLD);

    if (rank == 0) {
        printf("Process 0: Gathered data [");
        for (int i = 0; i < size * ELEMENTS_PER_PROCESS; i++) {
            printf("%d ", gathered_data[i]);
        }
        printf("]\n");

        free(gathered_data);
    }
}

// 6. 全局收集 (Allgather)
void allgather_example() {
    int rank, size;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    const int ELEMENTS_PER_PROCESS = 3;
    int local_data[ELEMENTS_PER_PROCESS];
    int all_data[size * ELEMENTS_PER_PROCESS];

    // 每个进程初始化本地数据
    for (int i = 0; i < ELEMENTS_PER_PROCESS; i++) {
        local_data[i] = rank * 10 + i;
    }

    printf("Process %d: Local data [", rank);
    for (int i = 0; i < ELEMENTS_PER_PROCESS; i++) {
        printf("%d ", local_data[i]);
    }
    printf("]\n");

    // 所有进程收集所有数据
    MPI_Allgather(local_data, ELEMENTS_PER_PROCESS, MPI_INT,
                  all_data, ELEMENTS_PER_PROCESS, MPI_INT, MPI_COMM_WORLD);

    printf("Process %d: All gathered data [", rank);
    for (int i = 0; i < size * ELEMENTS_PER_PROCESS; i++) {
        printf("%d ", all_data[i]);
    }
    printf("]\n");
}
```

**高级集合操作**：
```c
// 1. 扫描操作 (Scan)
void scan_example() {
    int rank, size;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    int local_value = rank + 1;
    int inclusive_scan, exclusive_scan;

    // 包含式扫描（包含当前进程的值）
    MPI_Scan(&local_value, &inclusive_scan, 1, MPI_INT, MPI_SUM, MPI_COMM_WORLD);

    // 排他式扫描（不包含当前进程的值）
    MPI_Exscan(&local_value, &exclusive_scan, 1, MPI_INT, MPI_SUM, MPI_COMM_WORLD);

    printf("Process %d: Local value = %d, Inclusive scan = %d, Exclusive scan = %d\n",
           rank, local_value, inclusive_scan, exclusive_scan);
}

// 2. 全局散布 (Alltoall)
void alltoall_example() {
    int rank, size;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    const int ELEMENTS_PER_PROCESS = 4;
    int send_data[size * ELEMENTS_PER_PROCESS];
    int recv_data[size * ELEMENTS_PER_PROCESS];

    // 初始化发送数据
    for (int i = 0; i < size * ELEMENTS_PER_PROCESS; i++) {
        send_data[i] = rank * 100 + i;
    }

    printf("Process %d: Send data [", rank);
    for (int i = 0; i < size * ELEMENTS_PER_PROCESS; i++) {
        printf("%d ", send_data[i]);
    }
    printf("]\n");

    // 全局散布：每个进程向所有进程发送数据
    MPI_Alltoall(send_data, ELEMENTS_PER_PROCESS, MPI_INT,
                 recv_data, ELEMENTS_PER_PROCESS, MPI_INT, MPI_COMM_WORLD);

    printf("Process %d: Received data [", rank);
    for (int i = 0; i < size * ELEMENTS_PER_PROCESS; i++) {
        printf("%d ", recv_data[i]);
    }
    printf("]\n");
}

// 3. 自定义规约操作
void custom_reduce() {
    int rank, size;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    // 定义自定义规约操作
    MPI_Op custom_op;
    MPI_Op_create(custom_max_abs, 1, &custom_op);  // custom_max_abs是自定义函数

    double local_value = rank * -1.5;
    double result;

    MPI_Reduce(&local_value, &result, 1, MPI_DOUBLE, custom_op, 0, MPI_COMM_WORLD);

    if (rank == 0) {
        printf("Custom reduce result: %f\n", result);
    }

    MPI_Op_free(&custom_op);
}

// 自定义规约函数示例
void custom_max_abs(void *invec, void *inoutvec, int *len, MPI_Datatype *datatype) {
    double *in = (double *)invec;
    double *inout = (double *)inoutvec;

    for (int i = 0; i < *len; i++) {
        inout[i] = (fabs(in[i]) > fabs(inout[i])) ? in[i] : inout[i];
    }
}
```

#### 进程管理

**进程组和通信器**：
```c
// 1. 创建进程组
void group_operations() {
    int rank, size;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    MPI_Group world_group, new_group;
    int ranks_to_include[2] = {0, 2};

    // 获取当前通信器的进程组
    MPI_Comm_group(MPI_COMM_WORLD, &world_group);

    // 创建新的进程组（包含进程0和2）
    MPI_Group_incl(world_group, 2, ranks_to_include, &new_group);

    // 从新组创建通信器
    MPI_Comm new_comm;
    MPI_Comm_create(MPI_COMM_WORLD, new_group, &new_comm);

    if (new_comm != MPI_COMM_NULL) {
        int new_rank, new_size;
        MPI_Comm_rank(new_comm, &new_rank);
        MPI_Comm_size(new_comm, &new_size);

        printf("Process %d: In new communicator, rank = %d, size = %d\n",
               rank, new_rank, new_size);

        // 在新通信器中进行通信
        if (new_rank == 0) {
            int data = 999;
            MPI_Send(&data, 1, MPI_INT, 1, 0, new_comm);
        } else if (new_rank == 1) {
            int received_data;
            MPI_Recv(&received_data, 1, MPI_INT, 0, 0, new_comm, MPI_STATUS_IGNORE);
            printf("Process %d: Received %d in new communicator\n", rank, received_data);
        }

        MPI_Comm_free(&new_comm);
    }

    MPI_Group_free(&world_group);
    MPI_Group_free(&new_group);
}

// 2. 分裂通信器
void communicator_split() {
    int rank, size;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    // 根据进程排名的奇偶性分裂通信器
    int color = rank % 2;
    int key = rank;

    MPI_Comm split_comm;
    MPI_Comm_split(MPI_COMM_WORLD, color, key, &split_comm);

    int split_rank, split_size;
    MPI_Comm_rank(split_comm, &split_rank);
    MPI_Comm_size(split_comm, &split_size);

    printf("Process %d: Original rank, Split rank = %d, Split size = %d\n",
           rank, split_rank, split_size);

    // 在分裂的通信器中进行通信
    if (split_rank == 0) {
        int data = 777;
        MPI_Bcast(&data, 1, MPI_INT, 0, split_comm);
        printf("Process %d: Broadcasted %d in split communicator\n", rank, data);
    } else {
        int received_data;
        MPI_Bcast(&received_data, 1, MPI_INT, 0, split_comm);
        printf("Process %d: Received %d in split communicator\n", rank, received_data);
    }

    MPI_Comm_free(&split_comm);
}

// 3. 进程创建和动态管理
void dynamic_process_management() {
    int rank, size;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    printf("Initial process %d of %d\n", rank, size);

    // 创建新的进程
    MPI_Comm intercomm;
    MPI_Comm_spawn("worker_program", MPI_ARGV_NULL, 2, MPI_INFO_NULL, 0, MPI_COMM_WORLD, &intercomm, MPI_ERRCODES_IGNORE);

    int spawned_size;
    MPI_Comm_remote_size(intercomm, &spawned_size);

    printf("Process %d: Created %d new processes\n", rank, spawned_size);

    // 与新创建的进程通信
    if (spawned_size > 0) {
        int data = 111;
        MPI_Send(&data, 1, MPI_INT, 0, 0, intercomm);
        printf("Process %d: Sent %d to spawned process\n", rank, data);
    }

    MPI_Comm_disconnect(&intercomm);
}
```

**MPI环境管理**：
```c
// 1. MPI环境信息查询
void mpi_environment_info() {
    int rank, size;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);

    if (rank == 0) {
        // 获取版本信息
        int version, subversion;
        MPI_Get_version(&version, &subversion);
        printf("MPI Version: %d.%d\n", version, subversion);

        // 获取实现信息
        char version_string[MPI_MAX_LIBRARY_VERSION_STRING];
        int resultlen;
        MPI_Get_library_version(version_string, &resultlen);
        printf("MPI Library Version: %s\n", version_string);
    }
}

// 2. MPI错误处理
void mpi_error_handling() {
    int rank;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);

    // 自定义错误处理函数
    MPI_Errhandler error_handler;
    MPI_Comm_create_errhandler(custom_error_function, &error_handler);
    MPI_Comm_set_errhandler(MPI_COMM_WORLD, error_handler);

    // 模拟可能出错的操作
    int *null_ptr = NULL;
    // MPI_Send(null_ptr, 1, MPI_INT, 1, 0, MPI_COMM_WORLD);  // 这会触发错误

    MPI_Errhandler_free(&error_handler);
}

// 自定义错误处理函数
void custom_error_function(MPI_Comm *comm, int *error_code, ...) {
    char error_string[MPI_MAX_ERROR_STRING];
    int resultlen;
    MPI_Error_string(*error_code, error_string, &resultlen);
    printf("Custom error handler: %s\n", error_string);
}

// 3. MPI进度推进
void mpi_progress() {
    int rank;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);

    // 在非阻塞通信期间手动推进MPI进度
    MPI_Request request;
    int data = 42;

    MPI_Isend(&data, 1, MPI_INT, (rank + 1) % 2, 0, MPI_COMM_WORLD, &request);

    // 手动推进MPI进度
    MPI_Test(&request, NULL, MPI_STATUS_IGNORE);

    // 或者使用MPI_Testall, MPI_Testany等
    // MPI_Testall(1, &request, NULL, MPI_STATUSES_IGNORE);
}
```

#### MPI性能优化

**通信优化策略**：
```c
// 1. 通信聚合
void communication_aggregation() {
    int rank, size;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);

    if (rank == 0) {
        // 聚合多个小消息为大消息
        const int NUM_MESSAGES = 100;
        const int MESSAGE_SIZE = 1024;
        char *aggregated_buffer = malloc(NUM_MESSAGES * MESSAGE_SIZE);

        // 填充聚合缓冲区
        for (int i = 0; i < NUM_MESSAGES; i++) {
            // 填充数据...
        }

        // 一次性发送
        MPI_Send(aggregated_buffer, NUM_MESSAGES * MESSAGE_SIZE,
                 MPI_CHAR, 1, 0, MPI_COMM_WORLD);

        free(aggregated_buffer);
    } else if (rank == 1) {
        // 接收聚合消息并分解
        const int NUM_MESSAGES = 100;
        const int MESSAGE_SIZE = 1024;
        char *aggregated_buffer = malloc(NUM_MESSAGES * MESSAGE_SIZE);

        MPI_Recv(aggregated_buffer, NUM_MESSAGES * MESSAGE_SIZE,
                 MPI_CHAR, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);

        // 分解消息...
        free(aggregated_buffer);
    }
}

// 2. 通信与计算重叠
void computation_overlap() {
    int rank, size;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);

    // 启动非阻塞通信
    MPI_Request send_request, recv_request;
    int send_data = rank * 100;
    int recv_data;

    MPI_Isend(&send_data, 1, MPI_INT, (rank + 1) % size, 0, MPI_COMM_WORLD, &send_request);
    MPI_Irecv(&recv_data, 1, MPI_INT, (rank - 1 + size) % size, 0, MPI_COMM_WORLD, &recv_request);

    // 执行计算（与通信重叠）
    double result = 0.0;
    for (int i = 0; i < 1000000; i++) {
        result += sin(i) * cos(i);
    }

    // 等待通信完成
    MPI_Wait(&send_request, MPI_STATUS_IGNORE);
    MPI_Wait(&recv_request, MPI_STATUS_IGNORE);

    printf("Process %d: Computation result = %f, Received = %d\n",
           rank, result, recv_data);
}

// 3. 使用MPI派生数据类型
void derived_datatypes() {
    // 定义自定义数据结构
    typedef struct {
        int id;
        double value;
        char name[32];
    } CustomData;

    // 创建MPI数据类型
    const int nitems = 3;
    int blocklengths[3] = {1, 1, 32};
    MPI_Datatype types[3] = {MPI_INT, MPI_DOUBLE, MPI_CHAR};
    MPI_Aint offsets[3];

    CustomData dummy;
    MPI_Get_address(&dummy.id, &offsets[0]);
    MPI_Get_address(&dummy.value, &offsets[1]);
    MPI_Get_address(&dummy.name, &offsets[2]);

    // 调整偏移量
    for (int i = 1; i < nitems; i++) {
        offsets[i] -= offsets[0];
    }
    offsets[0] = 0;

    MPI_Datatype custom_mpi_type;
    MPI_Type_create_struct(nitems, blocklengths, offsets, types, &custom_mpi_type);
    MPI_Type_commit(&custom_mpi_type);

    // 使用自定义数据类型进行通信
    CustomData send_data = {123, 3.14, "Hello MPI"};
    CustomData recv_data;

    int rank;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);

    if (rank == 0) {
        MPI_Send(&send_data, 1, custom_mpi_type, 1, 0, MPI_COMM_WORLD);
    } else if (rank == 1) {
        MPI_Recv(&recv_data, 1, custom_mpi_type, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);
        printf("Received: id=%d, value=%f, name=%s\n",
               recv_data.id, recv_data.value, recv_data.name);
    }

    MPI_Type_free(&custom_mpi_type);
}
```

**MPI调试和性能分析**：
```c
// 1. MPI性能计时
void mpi_timing() {
    int rank;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);

    double start_time = MPI_Wtime();

    // 执行MPI操作
    int data = 42;
    MPI_Bcast(&data, 1, MPI_INT, 0, MPI_COMM_WORLD);

    double end_time = MPI_Wtime();
    double elapsed_time = end_time - start_time;

    if (rank == 0) {
        printf("MPI_Bcast time: %f seconds\n", elapsed_time);
    }
}

// 2. MPI状态检查
void mpi_status_check() {
    int rank, size;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);

    MPI_Status status;
    int flag;

    // 检查是否有消息到达
    MPI_Iprobe(MPI_ANY_SOURCE, MPI_ANY_TAG, MPI_COMM_WORLD, &flag, &status);

    if (flag) {
        int count;
        MPI_Get_count(&status, MPI_INT, &count);
        printf("Process %d: Message from %d, tag %d, count %d\n",
               rank, status.MPI_SOURCE, status.MPI_TAG, count);
    }
}

// 3. MPI调试辅助函数
void mpi_debug_info() {
    int rank, size;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    // 获取进程信息
    char processor_name[MPI_MAX_PROCESSOR_NAME];
    int name_len;
    MPI_Get_processor_name(processor_name, &name_len);

    printf("Debug: Process %d of %d on %s\n", rank, size, processor_name);
}
```

#### MPI最佳实践

**代码组织和设计模式**：
```c
// 1. MPI程序模板
#define MPI_CHECK(call) \
    do { \
        int error = call; \
        if (error != MPI_SUCCESS) { \
            char error_string[MPI_MAX_ERROR_STRING]; \
            int length; \
            MPI_Error_string(error, error_string, &length); \
            fprintf(stderr, "MPI error at %s:%d - %s\n", __FILE__, __LINE__, error_string); \
            MPI_Abort(MPI_COMM_WORLD, error); \
        } \
    } while(0)

int main(int argc, char** argv) {
    // 1. 初始化
    MPI_CHECK(MPI_Init(&argc, &argv));

    // 2. 获取进程信息
    int rank, size;
    MPI_CHECK(MPI_Comm_rank(MPI_COMM_WORLD, &rank));
    MPI_CHECK(MPI_Comm_size(MPI_COMM_WORLD, &size));

    // 3. 程序逻辑
    if (size < 2) {
        if (rank == 0) {
            fprintf(stderr, "This program requires at least 2 processes\n");
        }
        MPI_Finalize();
        return 1;
    }

    // 主要计算逻辑
    main_computation(rank, size);

    // 4. 清理和结束
    MPI_CHECK(MPI_Finalize());
    return 0;
}

// 2. 分层通信设计
void hierarchical_communication() {
    int rank, size;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    // 创建进程子组
    int color = rank / (size / 2);  // 0或1
    int key = rank % (size / 2);

    MPI_Comm subgroup;
    MPI_Comm_split(MPI_COMM_WORLD, color, key, &subgroup);

    int sub_rank, sub_size;
    MPI_Comm_rank(subgroup, &sub_rank);
    MPI_Comm_size(subgroup, &sub_size);

    // 在子组内进行局部通信
    int local_data = rank * 10;
    int local_sum;

    MPI_Reduce(&local_data, &local_sum, 1, MPI_INT, MPI_SUM, 0, subgroup);

    // 在全局通信器中进行全局通信
    int global_sum;
    MPI_Allreduce(&local_sum, &global_sum, 1, MPI_INT, MPI_SUM, MPI_COMM_WORLD);

    printf("Process %d: Local sum = %d, Global sum = %d\n", rank, local_sum, global_sum);

    MPI_Comm_free(&subgroup);
}

// 3. 容错设计
void fault_tolerance_design() {
    // 使用检查点机制
    int checkpoint_interval = 100;
    int iteration = 0;

    while (iteration < 1000) {
        // 执行计算
        perform_iteration(iteration);

        // 定期保存检查点
        if (iteration % checkpoint_interval == 0) {
            save_checkpoint(iteration);
        }

        iteration++;
    }
}

void save_checkpoint(int iteration) {
    // 保存当前状态到文件
    // 这样可以在故障后从检查点恢复
}

void perform_iteration(int iteration) {
    // 执行单次迭代计算
}
```

这个重构版本提供了：
- **完整的MPI编程指南**：从基础到高级
- **丰富的代码示例**：涵盖所有主要MPI功能
- **性能优化技巧**：实际的优化策略
- **最佳实践**：生产级代码组织模式
- **错误处理**：健壮的错误处理机制

### 5.3 集群管理

#### 资源调度

**作业调度系统概述**：
- **调度器作用**：管理计算资源分配、作业排队、优先级控制
- **资源类型**：CPU、内存、GPU、存储、网络带宽
- **调度策略**：先进先出、优先级、公平共享、抢占式

**主流调度系统**：

**1. SLURM (Simple Linux Utility for Resource Management)**
```bash
# SLURM基本命令
sinfo                    # 查看节点状态
squeue                   # 查看作业队列
sbatch job_script.sh     # 提交作业
scancel job_id           # 取消作业
srun --pty bash          # 交互式作业

# SLURM作业脚本示例
#!/bin/bash
#SBATCH --job-name=my_mpi_job
#SBATCH --nodes=4
#SBATCH --ntasks-per-node=16
#SBATCH --time=01:00:00
#SBATCH --partition=compute
#SBATCH --output=output_%j.log

module load openmpi
mpirun -np 64 ./my_mpi_program
```

**2. PBS/Torque**
```bash
# PBS基本命令
qstat                    # 查看作业状态
qsub job_script.pbs      # 提交作业
qdel job_id              # 删除作业
qhold job_id             # 暂停作业

# PBS作业脚本示例
#!/bin/bash
#PBS -N my_mpi_job
#PBS -l nodes=4:ppn=16
#PBS -l walltime=01:00:00
#PBS -q batch
#PBS -o output.log
#PBS -e error.log

cd $PBS_O_WORKDIR
module load openmpi
mpirun -np 64 ./my_mpi_program
```

**3. LSF (Load Sharing Facility)**
```bash
# LSF基本命令
bjobs                    # 查看作业状态
bsub < job_script.lsf    # 提交作业
bkill job_id             # 终止作业
bstop job_id             # 暂停作业

# LSF作业脚本示例
#!/bin/bash
#BSUB -J my_mpi_job
#BSUB -n 64
#BSUB -R "span[ptile=16]"
#BSUB -W 01:00
#BSUB -o output.log
#BSUB -e error.log

module load openmpi
mpirun -np 64 ./my_mpi_program
```

**调度策略配置**：
```bash
# SLURM公平共享配置
sacctmgr add user name=username FairShare=1.0
sacctmgr add account name=project1 FairShare=0.5

# 优先级配置
scontrol update partition=compute PriorityJobFactor=1000

# 资源限制配置
scontrol update partition=compute MaxTime=24:00:00
scontrol update partition=compute MaxNodes=100
```

**高级调度特性**：
```bash
# 依赖作业
JOB1=$(sbatch --parsable job1.sh)
sbatch --dependency=afterok:$JOB1 job2.sh

# 阵列作业
sbatch --array=1-100 job_array.sh

# 资源预留
sbatch --reservation=my_reservation job.sh

# QoS (Quality of Service)
sbatch --qos=high_priority job.sh
```

#### 作业提交

**作业脚本编写规范**：
```bash
#!/bin/bash
# 作业脚本模板

# SLURM指令部分
#SBATCH --job-name=scientific_simulation    # 作业名称
#SBATCH --output=output_%j.log              # 标准输出文件
#SBATCH --error=error_%j.log                # 标准错误文件
#SBATCH --partition=compute                 # 分区选择
#SBATCH --nodes=8                           # 节点数
#SBATCH --ntasks-per-node=32                # 每节点任务数
#SBATCH --cpus-per-task=1                   # 每任务CPU数
#SBATCH --time=02:00:00                     # 运行时间
#SBATCH --mem=64G                          # 内存需求
#SBATCH --gres=gpu:4                       # GPU资源
#SBATCH --mail-type=BEGIN,END,FAIL         # 邮件通知
#SBATCH --mail-user=user@institution.edu   # 邮箱地址

# 环境设置
module purge                              # 清除模块
module load openmpi/4.1.0                 # 加载MPI模块
module load gcc/11.2.0                    # 加载编译器
module load cuda/11.4                     # 加载CUDA

# 设置环境变量
export OMP_NUM_THREADS=1                  # OpenMP线程数
export CUDA_VISIBLE_DEVICES=0,1,2,3       # 可见GPU
export LD_LIBRARY_PATH=/opt/lib:$LD_LIBRARY_PATH

# 作业准备
cd $SLURM_SUBMIT_DIR                      # 切换到提交目录
mkdir -p results                          # 创建结果目录

# 数据准备
if [ ! -f input_data.dat ]; then
    echo "Input data not found, generating..."
    ./generate_input.sh
fi

# 作业执行
echo "Starting job at $(date)"
echo "Job ID: $SLURM_JOB_ID"
echo "Node list: $SLURM_JOB_NODELIST"
echo "Number of tasks: $SLURM_NTASKS"

# MPI并行作业
srun --mpi=pmix ./my_mpi_program input_data.dat output.dat

# OpenMP并行作业
export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK
./my_openmp_program input_data.dat output.dat

# 混合作业 (MPI + OpenMP)
export OMP_NUM_THREADS=4
srun --mpi=pmix -c 4 ./my_hybrid_program input_data.dat output.dat

# GPU作业
srun ./my_gpu_program input_data.dat output.dat

echo "Job completed at $(date)"

# 结果处理
if [ -f output.dat ]; then
    echo "Processing results..."
    ./process_results.sh output.dat results/
fi

# 清理
echo "Cleaning up temporary files..."
rm -f temp_*.dat
```

**多作业管理**：
```bash
# 批量提交脚本
#!/bin/bash
for i in {1..10}; do
    sbatch <<EOF
#!/bin/bash
#SBATCH --job-name=job_$i
#SBATCH --output=output_$i.log
#SBATCH --nodes=1
#SBATCH --ntasks=16
#SBATCH --time=01:00:00

cd /path/to/working/dir
./simulation_$i
EOF
done

# 作业状态监控脚本
#!/bin/bash
while true; do
    PENDING=$(squeue -u $USER -t PENDING | wc -l)
    RUNNING=$(squeue -u $USER -t RUNNING | wc -l)
    COMPLETED=$(squeue -u $USER -t COMPLETED | wc -l)

    echo "Pending: $PENDING, Running: $RUNNING, Completed: $COMPLETED"

    if [ $PENDING -eq 0 ] && [ $RUNNING -eq 0 ]; then
        echo "All jobs completed!"
        break
    fi

    sleep 60
done
```

**作业依赖和工作流**：
```bash
# 复杂工作流示例
#!/bin/bash

# 第一阶段：数据预处理
PREPROCESS_JOBS=""
for i in {1..8}; do
    JOB_ID=$(sbatch --parsable <<EOF
#!/bin/bash
#SBATCH --job-name=preprocess_$i
#SBATCH --output=preprocess_$i.out
#SBATCH --nodes=1
#SBATCH --ntasks=16

./preprocess_data $i
EOF
    )
    PREPROCESS_JOBS="$PREPROCESS_JOBS:$JOB_ID"
done

# 第二阶段：主计算（依赖预处理）
MAIN_JOB=$(sbatch --parsable --dependency=afterok${PREPROCESS_JOBS//:/,} <<EOF
#!/bin/bash
#SBATCH --job-name=main_calculation
#SBATCH --output=main.out
#SBATCH --nodes=16
#SBATCH --ntasks=256

./main_simulation
EOF
)

# 第三阶段：后处理（依赖主计算）
sbatch --dependency=afterok:$MAIN_JOB <<EOF
#!/bin/bash
#SBATCH --job-name=postprocess
#SBATCH --output=postprocess.out
#SBATCH --nodes=1
#SBATCH --ntasks=8

./postprocess_results
EOF

echo "Workflow submitted successfully"
```

#### 性能监控

**集群级监控**：
```bash
# 节点状态监控
#!/bin/bash
while true; do
    echo "=== Cluster Status ==="
    sinfo -o "%.10P %.5a %.10l %.20N %.10T"
    echo ""

    echo "=== Node Details ==="
    scontrol show nodes | grep -E "(NodeName|State|CPUs|RealMemory|AllocMem)"
    echo ""

    sleep 300  # 每5分钟更新一次
done

# 资源使用统计
sreport cluster UserUtilization start=2024-01-01 end=2024-12-31
sreport cluster JobUtilization start=2024-01-01 end=2024-12-31
```

**作业级监控**：
```bash
# 作业详细信息查询
scontrol show job $JOB_ID
scontrol show step $JOB_ID.batch

# 实时资源使用监控
#!/bin/bash
JOB_ID=$1
while squeue -j $JOB_ID > /dev/null; do
    echo "=== Job $JOB_ID Status ==="
    sstat -j $JOB_ID --format="JobID,NTasks,CPUEff,MemEff,MaxRSS"

    # 获取节点级信息
    NODES=$(squeue -j $JOB_ID -o "%N" | tail -n 1)
    for node in $(echo $NODES | tr ',' ' '); do
        echo "Node $node:"
        ssh $node "top -bn1 | head -20"
    done

    echo ""
    sleep 60
done

# GPU使用监控
#!/bin/bash
JOB_ID=$1
while squeue -j $JOB_ID > /dev/null; do
    echo "=== GPU Usage for Job $JOB_ID ==="

    # 获取作业使用的节点
    NODES=$(squeue -j $JOB_ID -o "%N" | tail -n 1)
    for node in $(echo $NODES | tr ',' ' '); do
        echo "Node $node GPU status:"
        ssh $node "nvidia-smi --query-gpu=index,name,utilization.gpu,memory.used,memory.total --format=csv"
    done

    sleep 120
done
```

**性能分析工具集成**：
```bash
# 性能分析作业脚本
#!/bin/bash
#SBATCH --job-name=performance_analysis
#SBATCH --output=perf_analysis.out
#SBATCH --nodes=1
#SBATCH --ntasks=16
#SBATCH --time=01:00:00

# 使用性能分析工具
# 1. Intel VTune
module load vtune
vtune -collect hotspots -result-dir vtune_results ./my_program

# 2. perf
perf record -g -p $(pgrep my_program) sleep 60
perf report --stdio

# 3. NVIDIA Nsight
nsys profile --trace=cuda,nvtx ./my_gpu_program

# 4. MPI性能分析
tau_exec -T mpi ./my_mpi_program
```

**自定义监控脚本**：
```python
#!/usr/bin/env python3
import subprocess
import time
import json
import smtplib
from email.mime.text import MIMEText

class ClusterMonitor:
    def __init__(self):
        self.config = self.load_config()
        self.last_status = {}

    def load_config(self):
        with open('monitor_config.json', 'r') as f:
            return json.load(f)

    def get_cluster_status(self):
        """获取集群状态"""
        try:
            result = subprocess.run(['sinfo', '--json'], capture_output=True, text=True)
            return json.loads(result.stdout)
        except Exception as e:
            print(f"Error getting cluster status: {e}")
            return None

    def get_job_status(self):
        """获取作业状态"""
        try:
            result = subprocess.run(['squeue', '--json'], capture_output=True, text=True)
            return json.loads(result.stdout)
        except Exception as e:
            print(f"Error getting job status: {e}")
            return None

    def check_resources(self, cluster_status):
        """检查资源使用情况"""
        if not cluster_status:
            return

        total_nodes = len(cluster_status['nodes'])
        idle_nodes = sum(1 for node in cluster_status['nodes'] if node['state'] == 'IDLE')
        allocated_nodes = sum(1 for node in cluster_status['nodes'] if node['state'] == 'ALLOCATED')

        utilization = (allocated_nodes / total_nodes) * 100 if total_nodes > 0 else 0

        print(f"Cluster utilization: {utilization:.1f}% ({allocated_nodes}/{total_nodes})")

        if utilization > 90:
            self.send_alert(f"High cluster utilization: {utilization:.1f}%")

    def check_job_completion(self, job_status):
        """检查作业完成情况"""
        if not job_status:
            return

        for job in job_status['jobs']:
            job_id = job['job_id']
            state = job['state']['current']

            if state == 'RUNNING':
                self.check_job_performance(job)
            elif state == 'COMPLETED':
                self.check_job_success(job)
            elif state == 'FAILED':
                self.send_alert(f"Job {job_id} failed")

    def check_job_performance(self, job):
        """检查正在运行作业的性能"""
        job_id = job['job_id']
        cpu_time = job.get('time_limit', 0)
        current_time = time.time()

        # 检查作业是否运行时间过长
        if cpu_time > job.get('time_limit', 0) * 0.8:
            self.send_alert(f"Job {job_id} is using {cpu_time} CPU time")

    def check_job_success(self, job):
        """检查已完成作业"""
        job_id = job['job_id']
        exit_code = job.get('exit_code', {}).get('return_code', -1)

        if exit_code != 0:
            self.send_alert(f"Job {job_id} completed with exit code {exit_code}")

    def send_alert(self, message):
        """发送告警邮件"""
        msg = MIMEText(message)
        msg['Subject'] = 'Cluster Alert'
        msg['From'] = self.config['email']['from']
        msg['To'] = self.config['email']['to']

        try:
            with smtplib.SMTP(self.config['email']['smtp_server']) as server:
                server.send_message(msg)
            print(f"Alert sent: {message}")
        except Exception as e:
            print(f"Failed to send alert: {e}")

    def run_monitoring(self):
        """运行监控循环"""
        while True:
            cluster_status = self.get_cluster_status()
            job_status = self.get_job_status()

            self.check_resources(cluster_status)
            self.check_job_completion(job_status)

            time.sleep(self.config['monitoring']['interval'])

if __name__ == "__main__":
    monitor = ClusterMonitor()
    monitor.run_monitoring()
```

**监控配置文件**：
```json
{
    "monitoring": {
        "interval": 300,
        "cluster_thresholds": {
            "high_utilization": 90,
            "low_utilization": 10
        },
        "job_thresholds": {
            "max_runtime": 86400,
            "cpu_time_threshold": 0.8
        }
    },
    "email": {
        "smtp_server": "smtp.university.edu",
        "from": "cluster-monitor@university.edu",
        "to": "admin@university.edu"
    },
    "alerts": {
        "enabled": true,
        "types": ["utilization", "job_failure", "performance"]
    }
}
```

**可视化监控面板**：
```python
#!/usr/bin/env python3
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import subprocess
import json
import time

class ClusterDashboard:
    def __init__(self):
        self.fig, (self.ax1, self.ax2) = plt.subplots(2, 1, figsize=(12, 8))

        # 设置图表
        self.ax1.set_title('Cluster Utilization')
        self.ax1.set_ylabel('Utilization (%)')
        self.ax1.set_ylim(0, 100)

        self.ax2.set_title('Job Queue')
        self.ax2.set_ylabel('Number of Jobs')
        self.ax2.set_xlabel('Time')

        # 初始化数据
        self.times = []
        self.utilization_data = []
        self.pending_jobs = []
        self.running_jobs = []

    def get_data(self):
        """获取实时数据"""
        try:
            # 获取集群状态
            result = subprocess.run(['sinfo', '--json'], capture_output=True, text=True)
            cluster_data = json.loads(result.stdout)

            total_nodes = len(cluster_data['nodes'])
            idle_nodes = sum(1 for node in cluster_data['nodes'] if node['state'] == 'IDLE')
            allocated_nodes = sum(1 for node in cluster_data['nodes'] if node['state'] == 'ALLOCATED')

            utilization = (allocated_nodes / total_nodes) * 100 if total_nodes > 0 else 0

            # 获取作业状态
            result = subprocess.run(['squeue', '--json'], capture_output=True, text=True)
            job_data = json.loads(result.stdout)

            pending = sum(1 for job in job_data['jobs'] if job['state']['current'] == 'PENDING')
            running = sum(1 for job in job_data['jobs'] if job['state']['current'] == 'RUNNING')

            return utilization, pending, running

        except Exception as e:
            print(f"Error getting data: {e}")
            return 0, 0, 0

    def update(self, frame):
        """更新图表"""
        current_time = time.strftime('%H:%M:%S')
        self.times.append(current_time)

        if len(self.times) > 100:
            self.times.pop(0)
            self.utilization_data.pop(0)
            self.pending_jobs.pop(0)
            self.running_jobs.pop(0)

        utilization, pending, running = self.get_data()

        self.utilization_data.append(utilization)
        self.pending_jobs.append(pending)
        self.running_jobs.append(running)

        # 更新图表
        self.ax1.clear()
        self.ax1.plot(self.times, self.utilization_data, 'b-', label='Utilization')
        self.ax1.axhline(y=80, color='r', linestyle='--', label='High Threshold')
        self.ax1.set_title('Cluster Utilization')
        self.ax1.set_ylabel('Utilization (%)')
        self.ax1.legend()
        self.ax1.tick_params(axis='x', rotation=45)

        self.ax2.clear()
        self.ax2.plot(self.times, self.pending_jobs, 'r-', label='Pending')
        self.ax2.plot(self.times, self.running_jobs, 'g-', label='Running')
        self.ax2.set_title('Job Queue')
        self.ax2.set_ylabel('Number of Jobs')
        self.ax2.legend()
        self.ax2.tick_params(axis='x', rotation=45)

        plt.tight_layout()

    def run(self):
        """运行监控面板"""
        ani = animation.FuncAnimation(self.fig, self.update, interval=30000)  # 30秒更新一次
        plt.show()

if __name__ == "__main__":
    dashboard = ClusterDashboard()
    dashboard.run()
```

这个重构版本提供了：
- **完整的集群管理指南**：从作业提交到性能监控
- **多种调度系统支持**：SLURM、PBS、LSF
- **实用的脚本示例**：作业脚本、监控脚本、工作流
- **性能分析集成**：专业工具的使用方法
- **自动化监控**：Python脚本实现智能监控
- **可视化界面**：实时图表展示集群状态