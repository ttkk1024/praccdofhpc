# 第十二章：CUDA/GPU计算

## 12.1 GPU计算基础

### 12.1.1 GPU架构概述

**GPU与CPU的差异**

| 特性 | CPU | GPU |
|------|-----|-----|
| 核心数量 | 少量（4-64个） | 大量（数千个） |
| 时钟频率 | 高（3-5GHz） | 较低（1-2GHz） |
| 内存带宽 | 中等 | 极高 |
| 并行度 | 低 | 极高 |
| 适用场景 | 复杂逻辑、串行任务 | 大规模并行计算 |

**GPU核心架构特点**：

- **SIMT架构**：单指令多线程（Single Instruction Multiple Thread）
- **CUDA核心**：NVIDIA GPU中的基本计算单元
- **流多处理器（SM）**：包含多个CUDA核心的处理单元
- **内存层次**：全局内存、共享内存、寄存器、常量内存

### 12.1.2 CUDA编程模型

**CUDA核心概念**：

1. **Host（主机）**：CPU及其内存
2. **Device（设备）**：GPU及其内存
3. **Kernel（内核函数）**：在GPU上执行的函数
4. **线程层次结构**：
   - Grid（网格）
   - Block（块）
   - Thread（线程）

**内存空间**：
- **全局内存**：所有线程可访问，容量大但延迟高
- **共享内存**：同块内线程共享，容量小但速度快
- **寄存器**：每个线程私有，速度最快
- **常量内存**：只读，有缓存优化

## 12.2 CUDA编程基础

### 12.2.1 基本语法

```cuda
// Kernel函数定义
__global__ void vectorAdd(float *a, float *b, float *c, int n) {
    // 获取线程索引
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    // 边界检查
    if (idx < n) {
        c[idx] = a[idx] + b[idx];
    }
}

// 主机代码
int main() {
    int n = 1000000;
    size_t size = n * sizeof(float);

    // 1. 分配主机内存
    float *h_a = (float*)malloc(size);
    float *h_b = (float*)malloc(size);
    float *h_c = (float*)malloc(size);

    // 2. 初始化数据
    for (int i = 0; i < n; i++) {
        h_a[i] = i;
        h_b[i] = i * 2;
    }

    // 3. 分配设备内存
    float *d_a, *d_b, *d_c;
    cudaMalloc(&d_a, size);
    cudaMalloc(&d_b, size);
    cudaMalloc(&d_c, size);

    // 4. 主机到设备内存拷贝
    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);
    cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);

    // 5. 配置执行参数
    int threadsPerBlock = 256;
    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;

    // 6. 启动Kernel
    vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, d_c, n);

    // 7. 设备到主机内存拷贝
    cudaMemcpy(h_c, d_c, size, cudaMemcpyDeviceToHost);

    // 8. 释放内存
    free(h_a); free(h_b); free(h_c);
    cudaFree(d_a); cudaFree(d_b); cudaFree(d_c);

    return 0;
}
```

### 12.2.2 线程索引计算

**一维索引**：
```cuda
int idx = blockIdx.x * blockDim.x + threadIdx.x;
```

**二维索引**：
```cuda
int row = blockIdx.y * blockDim.y + threadIdx.y;
int col = blockIdx.x * blockDim.x + threadIdx.x;
int idx = row * width + col;
```

**三维索引**：
```cuda
int x = blockIdx.x * blockDim.x + threadIdx.x;
int y = blockIdx.y * blockDim.y + threadIdx.y;
int z = blockIdx.z * blockDim.z + threadIdx.z;
int idx = z * width * height + y * width + x;
```

## 12.3 CUDA内存管理

### 12.3.1 内存类型详解

**全局内存（Global Memory）**：
- 所有线程都可以访问
- 延迟高，带宽大
- 需要显式分配和释放

```cuda
// 分配全局内存
float *d_data;
cudaMalloc(&d_data, size);

// 释放全局内存
cudaFree(d_data);
```

**共享内存（Shared Memory）**：
- 同一Block内的线程共享
- 速度快，容量有限（通常48-164KB）
- 需要在Kernel内声明

```cuda
__global__ void sharedMemoryExample() {
    // 声明共享内存
    __shared__ float shared_data[256];

    // 使用共享内存
    shared_data[threadIdx.x] = some_value;
    __syncthreads();  // 同步所有线程
}
```

**寄存器内存（Register Memory）**：
- 每个线程私有
- 速度最快，容量最小
- 编译器自动管理

```cuda
__global__ void registerExample() {
    float local_var = 1.0f;  // 存储在寄存器中
}
```

### 12.3.2 内存拷贝操作

```cuda
// 主机到设备
cudaMemcpy(d_dest, h_src, size, cudaMemcpyHostToDevice);

// 设备到主机
cudaMemcpy(h_dest, d_src, size, cudaMemcpyDeviceToHost);

// 设备到设备
cudaMemcpy(d_dest, d_src, size, cudaMemcpyDeviceToDevice);

// 异步拷贝
cudaMemcpyAsync(d_dest, h_src, size, cudaMemcpyHostToDevice, stream);
```

## 12.4 GPU并行模式

### 12.4.1 数据并行模式

**向量加法示例**：

```cuda
__global__ void vectorAdd(float *a, float *b, float *c, int n) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < n) {
        c[idx] = a[idx] + b[idx];
    }
}

// 使用示例
void launchVectorAdd() {
    int n = 1024 * 1024;
    size_t size = n * sizeof(float);

    // 内存分配和初始化...

    // 配置参数
    int threadsPerBlock = 256;
    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;

    // 启动Kernel
    vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, d_c, n);
}
```

### 12.4.2 矩阵乘法

**基本矩阵乘法**：

```cuda
__global__ void matrixMul(float *A, float *B, float *C, int N) {
    int row = blockIdx.y * blockDim.y + threadIdx.y;
    int col = blockIdx.x * blockDim.x + threadIdx.x;

    if (row < N && col < N) {
        float sum = 0.0f;
        for (int k = 0; k < N; k++) {
            sum += A[row * N + k] * B[k * N + col];
        }
        C[row * N + col] = sum;
    }
}

// 优化版本：使用共享内存
__global__ void matrixMulShared(float *A, float *B, float *C, int N) {
    __shared__ float As[16][16];
    __shared__ float Bs[16][16];

    int bx = blockIdx.x, by = blockIdx.y;
    int tx = threadIdx.x, ty = threadIdx.y;

    int row = by * 16 + ty;
    int col = bx * 16 + tx;

    float sum = 0.0f;

    // 分块计算
    for (int k = 0; k < (N / 16); k++) {
        // 加载数据到共享内存
        As[ty][tx] = A[row * N + k * 16 + tx];
        Bs[ty][tx] = B[(k * 16 + ty) * N + col];
        __syncthreads();

        // 计算部分结果
        for (int i = 0; i < 16; i++) {
            sum += As[ty][i] * Bs[i][tx];
        }
        __syncthreads();
    }

    // 存储结果
    C[row * N + col] = sum;
}
```

## 12.5 CUDA在生物信息学中的应用

### 12.5.1 序列比对加速

**Smith-Waterman算法的GPU实现**：

```cuda
__global__ void smithWaterman(float *query, float *target,
                             float *score_matrix, int *traceback,
                             int query_len, int target_len) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    int j = blockIdx.y * blockDim.y + threadIdx.y;

    if (i < query_len && j < target_len) {
        // 计算得分
        float match = score_matrix[i-1][j-1] + match_score(query[i], target[j]);
        float delete_score = score_matrix[i-1][j] + gap_penalty;
        float insert_score = score_matrix[i][j-1] + gap_penalty;

        score_matrix[i][j] = max(0.0f, max(match, max(delete_score, insert_score)));

        // 追踪路径
        if (score_matrix[i][j] == match) traceback[i][j] = 1;
        else if (score_matrix[i][j] == delete_score) traceback[i][j] = 2;
        else if (score_matrix[i][j] == insert_score) traceback[i][j] = 3;
    }
}
```

### 12.5.2 基因组数据处理

**并行BLAST搜索**：

```cuda
__global__ void parallelBlastSearch(char *database, char *query,
                                   int *results, int db_size, int query_size) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    if (idx < db_size - query_size + 1) {
        // 并行搜索数据库
        int score = 0;
        for (int i = 0; i < query_size; i++) {
            if (database[idx + i] == query[i]) {
                score++;
            }
        }

        if (score >= threshold) {
            results[idx] = score;
        }
    }
}
```

### 12.5.3 蛋白质结构预测

**分子动力学模拟的GPU实现**：

```cuda
__global__ void calculateForces(float *positions, float *velocities,
                               float *forces, int num_atoms) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    if (idx < num_atoms) {
        float fx = 0.0f, fy = 0.0f, fz = 0.0f;

        // 计算与其他原子的相互作用
        for (int j = 0; j < num_atoms; j++) {
            if (i != j) {
                float dx = positions[j*3] - positions[idx*3];
                float dy = positions[j*3+1] - positions[idx*3+1];
                float dz = positions[j*3+2] - positions[idx*3+2];

                float r2 = dx*dx + dy*dy + dz*dz;
                float r = sqrtf(r2);

                // Lennard-Jones势能
                float force = 24.0f * epsilon * (2.0f * pow(sigma/r, 12) - pow(sigma/r, 6)) / r;
                fx += force * dx / r;
                fy += force * dy / r;
                fz += force * dz / r;
            }
        }

        forces[idx*3] = fx;
        forces[idx*3+1] = fy;
        forces[idx*3+2] = fz;
    }
}
```

## 12.6 性能优化技巧

### 12.6.1 内存访问优化

**合并访问模式**：

```cuda
// 好的访问模式：连续内存访问
__global__ void goodAccessPattern(float *data) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    // 连续访问：thread 0访问data[0], thread 1访问data[1], ...
    float value = data[idx];
}

// 坏的访问模式：跨步访问
__global__ void badAccessPattern(float *data) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    // 跨步访问：thread 0访问data[0], thread 1访问data[32], ...
    float value = data[idx * 32];
}
```

**共享内存优化**：

```cuda
__global__ void optimizedMatrixMul(float *A, float *B, float *C, int N) {
    __shared__ float As[16][16];
    __shared__ float Bs[16][16];

    int tx = threadIdx.x, ty = threadIdx.y;
    int row = blockIdx.y * 16 + ty;
    int col = blockIdx.x * 16 + tx;

    float sum = 0.0f;

    // 分块加载数据
    for (int k = 0; k < N/16; k++) {
        As[ty][tx] = A[row * N + k * 16 + tx];
        Bs[ty][tx] = B[(k * 16 + ty) * N + col];
        __syncthreads();

        // 计算
        for (int i = 0; i < 16; i++) {
            sum += As[ty][i] * Bs[i][tx];
        }
        __syncthreads();
    }

    C[row * N + col] = sum;
}
```

### 12.6.2 计算优化

**向量化操作**：

```cuda
// 使用SIMD向量类型
__global__ void vectorizedOperation(float4 *data, float4 *result, int n) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    if (idx < n) {
        float4 val = data[idx];
        // 同时处理4个浮点数
        result[idx] = make_float4(val.x * 2.0f, val.y * 2.0f,
                                 val.z * 2.0f, val.w * 2.0f);
    }
}
```

**减少分支发散**：

```cuda
// 好的分支模式：线程束内分支一致
__global__ void goodBranching(float *data, int n) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    if (idx < n/2) {
        // 前一半线程执行
        data[idx] *= 2.0f;
    } else {
        // 后一半线程执行
        data[idx] *= 3.0f;
    }
}

// 坏的分支模式：线程束内分支不一致
__global__ void badBranching(float *data, int n) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    if (idx % 2 == 0) {
        // 奇数索引线程
        data[idx] *= 2.0f;
    } else {
        // 偶数索引线程
        data[idx] *= 3.0f;
    }
}
```

## 12.7 CUDA编程最佳实践

### 12.7.1 错误处理

```cuda
#define CUDA_CHECK(call) \
    do { \
        cudaError_t error = call; \
        if (error != cudaSuccess) { \
            fprintf(stderr, "CUDA error at %s:%d - %s\n", \
                    __FILE__, __LINE__, cudaGetErrorString(error)); \
            exit(1); \
        } \
    } while(0)

// 使用示例
CUDA_CHECK(cudaMalloc(&d_data, size));
CUDA_CHECK(cudaMemcpy(d_dest, h_src, size, cudaMemcpyHostToDevice));
CUDA_CHECK(cudaDeviceSynchronize());
```

### 12.7.2 内存管理最佳实践

```cuda
// 1. 使用统一内存（CUDA 6.0+）
float *data;
cudaMallocManaged(&data, size);

// 2. 使用内存池
cudaMemPool_t mempool;
cudaDeviceGetDefaultMemPool(&mempool, 0);
float *pooled_data;
cudaMallocAsync(&pooled_data, size, stream);

// 3. 零拷贝内存
float *zero_copy_data;
cudaHostAlloc(&zero_copy_data, size, cudaHostAllocWriteCombined);
```

### 12.7.3 性能分析

```bash
# 使用nvprof进行性能分析
nvprof --print-gpu-trace ./your_cuda_program

# 使用Nsight Systems
nsys profile ./your_cuda_program

# 使用Nsight Compute
ncu ./your_cuda_program
```

## 12.8 实际应用案例

### 12.8.1 基因表达数据分析

```cuda
__global__ void normalizeExpressionData(float *expression_matrix,
                                      float *normalized_matrix,
                                      float *row_sums, int rows, int cols) {
    int row = blockIdx.y * blockDim.y + threadIdx.y;
    int col = blockIdx.x * blockDim.x + threadIdx.x;

    if (row < rows && col < cols) {
        // 计算每行的总和
        float sum = 0.0f;
        for (int k = 0; k < cols; k++) {
            sum += expression_matrix[row * cols + k];
        }
        row_sums[row] = sum;

        // 标准化
        normalized_matrix[row * cols + col] =
            expression_matrix[row * cols + col] / sum;
    }
}
```

### 12.8.2 SNP检测加速

```cuda
__global__ void detectSNPs(unsigned char *reference_genome,
                          unsigned char *sample_genome,
                          int *snp_positions, int genome_size) {
    int pos = blockIdx.x * blockDim.x + threadIdx.x;

    if (pos < genome_size) {
        // 比较碱基
        if (reference_genome[pos] != sample_genome[pos]) {
            snp_positions[pos] = 1;  // 标记为SNP
        }
    }
}
```

### 12.8.3 蛋白质对接模拟

```cuda
__global__ void proteinDocking(float *receptor_coords,
                              float *ligand_coords,
                              float *energy_grid,
                              int grid_size) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    if (idx < grid_size * grid_size * grid_size) {
        int x = idx % grid_size;
        int y = (idx / grid_size) % grid_size;
        int z = idx / (grid_size * grid_size);

        float total_energy = 0.0f;

        // 计算受体与配体的相互作用能
        for (int i = 0; i < num_receptor_atoms; i++) {
            for (int j = 0; j < num_ligand_atoms; j++) {
                float dx = receptor_coords[i*3] - (x + ligand_coords[j*3]);
                float dy = receptor_coords[i*3+1] - (y + ligand_coords[j*3+1]);
                float dz = receptor_coords[i*3+2] - (z + ligand_coords[j*3+2]);

                float distance = sqrtf(dx*dx + dy*dy + dz*dz);
                float energy = calculateInteractionEnergy(distance);

                total_energy += energy;
            }
        }

        energy_grid[idx] = total_energy;
    }
}
```

## 12.9 总结

CUDA/GPU计算为生物信息学提供了强大的并行计算能力：

**优势**：
- 极高的并行度，适合大规模数据处理
- 高内存带宽，适合数据密集型应用
- 成熟的编程模型和工具链

**应用场景**：
- 序列比对和搜索
- 基因组数据分析
- 蛋白质结构预测和对接
- 分子动力学模拟
- 多组学数据整合

**挑战**：
- 编程复杂度较高
- 内存管理需要精细控制
- 算法需要重新设计以适应并行架构

**未来趋势**：
- 更高级的编程抽象（如Thrust、cuDF）
- 深度学习与传统计算的结合
- 异构计算平台的普及

通过合理利用CUDA/GPU计算，可以显著加速生物信息学中的计算密集型任务，为大规模生物数据分析提供强有力的支持。