# 第十二章：CUDA/GPU计算

## 12.1 GPU计算基础

### 12.1.1 GPU架构概述

**GPU与CPU的差异**

| 特性 | CPU | GPU |
|------|-----|-----|
| 核心数量 | 少量（4-64个） | 大量（数千个） |
| 时钟频率 | 高（3-5GHz） | 较低（1-2GHz） |
| 内存带宽 | 中等 | 极高 |
| 并行度 | 低 | 极高 |
| 适用场景 | 复杂逻辑、串行任务 | 大规模并行计算 |

**GPU核心架构特点**：

- **SIMT架构**：单指令多线程（Single Instruction Multiple Thread）
- **CUDA核心**：NVIDIA GPU中的基本计算单元
- **流多处理器（SM）**：包含多个CUDA核心的处理单元
- **内存层次**：全局内存、共享内存、寄存器、常量内存

### 12.1.2 CUDA编程模型

**CUDA核心概念**：

1. **Host（主机）**：CPU及其内存
2. **Device（设备）**：GPU及其内存
3. **Kernel（内核函数）**：在GPU上执行的函数
4. **线程层次结构**：
   - Grid（网格）
   - Block（块）
   - Thread（线程）

**内存空间**：
- **全局内存**：所有线程可访问，容量大但延迟高
- **共享内存**：同块内线程共享，容量小但速度快
- **寄存器**：每个线程私有，速度最快
- **常量内存**：只读，有缓存优化

## 12.2 CUDA环境安装与配置

### 12.2.1 系统要求检查

#### 硬件要求
```bash
# 检查GPU是否支持CUDA
nvidia-smi

# 检查CUDA兼容性
lspci | grep -i nvidia

# 检查驱动版本
nvidia-smi --query-gpu=name,driver_version,cuda_version --format=csv
```

#### 软件要求
- **操作系统**：Linux (Ubuntu 18.04+, CentOS 7+), Windows 10+, macOS (特定版本)
- **GPU**：支持CUDA的NVIDIA显卡（Compute Capability 3.5+）
- **驱动**：最新版NVIDIA驱动
- **编译器**：GCC, Clang, 或MSVC（根据操作系统）

### 12.2.2 Linux系统安装

#### Ubuntu/Debian系统

**方法1：使用CUDA仓库安装（推荐）**
```bash
# 1. 下载CUDA仓库配置包
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin

# 2. 设置仓库优先级
sudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600

# 3. 下载并安装GPG密钥
wget https://developer.download.nvidia.com/compute/cuda/12.1.0/local_installers/cuda-repo-ubuntu2004-12-1-local_12.1.0-530.30.02-1_amd64.deb
sudo dpkg -i cuda-repo-ubuntu2004-12-1-local_12.1.0-530.30.02-1_amd64.deb

# 4. 添加公钥
sudo cp /var/cuda-repo-ubuntu2004-12-1-local/cuda-530.30.02-keyring.gpg /usr/share/keyrings/

# 5. 更新包列表
sudo apt-get update

# 6. 安装CUDA工具包
sudo apt-get -y install cuda

# 7. 设置环境变量
echo 'export PATH=/usr/local/cuda-12.1/bin:$PATH' >> ~/.bashrc
echo 'export LD_LIBRARY_PATH=/usr/local/cuda-12.1/lib64:$LD_LIBRARY_PATH' >> ~/.bashrc
source ~/.bashrc
```

**方法2：使用.run文件安装**
```bash
# 1. 下载CUDA安装包
wget https://developer.download.nvidia.com/compute/cuda/12.1.0/local_installers/cuda_12.1.0_530.30.02_linux.run

# 2. 禁用Nouveau驱动（如果需要）
sudo bash -c 'echo "blacklist nouveau" >> /etc/modprobe.d/blacklist-nouveau.conf'
sudo bash -c 'echo "options nouveau modeset=0" >> /etc/modprobe.d/blacklist-nouveau.conf'
sudo update-initramfs -u

# 3. 重启系统
sudo reboot

# 4. 进入文本模式安装
sudo init 3

# 5. 运行安装程序
sudo sh cuda_12.1.0_530.30.02_linux.run

# 6. 按照提示完成安装
```

#### CentOS/RHEL系统

```bash
# 1. 下载CUDA仓库配置
wget https://developer.download.nvidia.com/compute/cuda/repos/rhel8/x86_64/cuda-rhel8.pin

# 2. 设置仓库
sudo mv cuda-rhel8.pin /etc/yum.repos.d/cuda.repo

# 3. 清理缓存
sudo yum clean all

# 4. 安装CUDA
sudo yum -y install cuda

# 5. 设置环境变量
echo 'export PATH=/usr/local/cuda-12.1/bin:$PATH' >> ~/.bashrc
echo 'export LD_LIBRARY_PATH=/usr/local/cuda-12.1/lib64:$LD_LIBRARY_PATH' >> ~/.bashrc
source ~/.bashrc
```

### 12.2.3 Windows系统安装

#### 安装步骤
```powershell
# 1. 下载CUDA安装程序
# 从 https://developer.nvidia.com/cuda-downloads 下载

# 2. 运行安装程序
# 双击下载的exe文件，按照向导安装

# 3. 设置环境变量
# 控制面板 -> 系统和安全 -> 系统 -> 高级系统设置 -> 环境变量
# 添加：
# PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.1\bin
# LD_LIBRARY_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.1\libnvvp
```

#### 验证安装
```powershell
# 检查nvcc编译器
nvcc --version

# 检查CUDA设备
nvidia-smi

# 运行示例程序
cd "C:\ProgramData\NVIDIA Corporation\CUDA Samples\v12.1\1_Utilities\deviceQuery"
deviceQuery.exe
```

### 12.2.4 macOS系统安装

#### 安装步骤
```bash
# 1. 下载CUDA安装包
# 从 https://developer.nvidia.com/cuda-downloads 下载

# 2. 运行安装包
# 双击下载的pkg文件

# 3. 设置环境变量
echo 'export PATH=/usr/local/cuda/bin:$PATH' >> ~/.zshrc
echo 'export DYLD_LIBRARY_PATH=/usr/local/cuda/lib:$DYLD_LIBRARY_PATH' >> ~/.zshrc
source ~/.zshrc
```

**注意**：macOS对CUDA的支持有限，建议使用Linux或Windows系统进行CUDA开发。

### 12.2.5 验证CUDA安装

#### 基本验证
```bash
# 检查CUDA版本
nvcc --version

# 检查CUDA设备
nvidia-smi

# 检查CUDA驱动版本
cat /proc/driver/nvidia/version
```

#### 编译测试程序
```cuda
// test_cuda.cu
#include <stdio.h>
#include <cuda_runtime.h>

__global__ void helloCUDA() {
    printf("Hello from GPU! Thread %d\n", threadIdx.x);
}

int main() {
    printf("Hello from CPU!\n");

    // 启动kernel
    helloCUDA<<<1, 5>>>();

    // 等待GPU完成
    cudaDeviceSynchronize();

    return 0;
}
```

```bash
# 编译
nvcc -o test_cuda test_cuda.cu

# 运行
./test_cuda
```

#### 运行CUDA示例
```bash
# 下载CUDA示例
cuda-install-samples-12.1.sh ~/cuda-samples

# 编译示例
cd ~/cuda-samples/NVIDIA_CUDA-12.1_Samples/1_Utilities/deviceQuery
make

# 运行设备查询
./deviceQuery
```

### 12.2.6 驱动管理

#### 更新NVIDIA驱动
```bash
# Ubuntu/Debian
sudo apt update
sudo apt install nvidia-driver-530  # 指定版本
sudo reboot

# CentOS/RHEL
sudo yum install nvidia-driver-latest-dkms
sudo reboot
```

#### 手动安装驱动
```bash
# 1. 下载驱动
wget https://us.download.nvidia.com/XFree86/Linux-x86_64/530.30.02/NVIDIA-Linux-x86_64-530.30.02.run

# 2. 停止显示管理器
sudo systemctl stop gdm3  # 或lightdm, sddm等

# 3. 进入文本模式
sudo init 3

# 4. 安装驱动
sudo sh NVIDIA-Linux-x86_64-530.30.02.run

# 5. 重启
sudo reboot
```

### 12.2.7 多版本CUDA管理

#### 使用环境模块（Environment Modules）
```bash
# 安装环境模块
sudo apt-get install environment-modules  # Ubuntu/Debian
sudo yum install environment-modules      # CentOS/RHEL

# 创建模块文件
sudo mkdir -p /usr/share/modules/modulefiles/cuda

# 创建CUDA 12.1模块
sudo tee /usr/share/modules/modulefiles/cuda/12.1 << 'EOF'
#%Module1.0
##
## CUDA 12.1 module
##
proc ModulesHelp { } {
    puts stderr "Sets the environment for using CUDA 12.1"
}

module-whatis   "Sets the environment for using CUDA 12.1"

prepend-path    PATH            /usr/local/cuda-12.1/bin
prepend-path    LD_LIBRARY_PATH /usr/local/cuda-12.1/lib64
prepend-path    C_INCLUDE_PATH  /usr/local/cuda-12.1/include
prepend-path    CPLUS_INCLUDE_PATH /usr/local/cuda-12.1/include
setenv          CUDA_HOME       /usr/local/cuda-12.1
EOF
```

#### 使用方法
```bash
# 加载CUDA 12.1
module load cuda/12.1

# 查看可用版本
module avail cuda

# 切换版本
module switch cuda/11.8 cuda/12.1
```

#### 使用脚本切换
```bash
#!/bin/bash
# cuda-switch.sh

CUDA_VERSION=$1

case $CUDA_VERSION in
    "11.8")
        export PATH=/usr/local/cuda-11.8/bin:$PATH
        export LD_LIBRARY_PATH=/usr/local/cuda-11.8/lib64:$LD_LIBRARY_PATH
        ;;
    "12.1")
        export PATH=/usr/local/cuda-12.1/bin:$PATH
        export LD_LIBRARY_PATH=/usr/local/cuda-12.1/lib64:$LD_LIBRARY_PATH
        ;;
    *)
        echo "Usage: $0 {11.8|12.1}"
        exit 1
        ;;
esac

echo "CUDA version switched to $CUDA_VERSION"
nvcc --version
```

### 12.2.8 容器化CUDA环境

#### Docker安装CUDA
```dockerfile
# Dockerfile
FROM nvidia/cuda:12.1-devel-ubuntu20.04

# 安装编译工具
RUN apt-get update && apt-get install -y \
    build-essential \
    cmake \
    wget \
    curl \
    && rm -rf /var/lib/apt/lists/*

# 设置环境变量
ENV PATH /usr/local/cuda/bin:$PATH
ENV LD_LIBRARY_PATH /usr/local/cuda/lib64:$LD_LIBRARY_PATH

WORKDIR /app
```

```bash
# 构建镜像
docker build -t cuda-dev .

# 运行容器
docker run --gpus all -it cuda-dev

# 验证GPU访问
nvidia-smi
```

#### Singularity安装CUDA
```singularity
Bootstrap: docker
From: nvidia/cuda:12.1-devel-ubuntu20.04

%post
    apt-get update
    apt-get install -y build-essential cmake
    apt-get clean

%environment
    export PATH=/usr/local/cuda/bin:$PATH
    export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH

%runscript
    echo "CUDA环境已配置"
```

### 12.2.9 常见问题解决

#### 1. CUDA版本不匹配
```bash
# 检查CUDA驱动版本
nvidia-smi

# 检查CUDA运行时版本
nvcc --version

# 解决方案：更新驱动或降级CUDA版本
```

#### 2. 编译错误：undefined reference
```bash
# 确保链接CUDA运行时库
nvcc -o program program.cu -lcudart

# 检查库路径
ldconfig -p | grep cuda
```

#### 3. 运行时错误：CUDA driver version is insufficient
```bash
# 更新NVIDIA驱动
sudo apt-get update
sudo apt-get install nvidia-driver-530
sudo reboot
```

#### 4. 内存不足错误
```bash
# 检查GPU内存使用
nvidia-smi

# 减少CUDA程序的内存使用
# 优化算法，减少数据传输
```

#### 5. 编译器版本不兼容
```bash
# 检查GCC版本
gcc --version

# CUDA 12.1要求GCC 9+
# 如果版本过低，安装更新版本
sudo apt-get install gcc-9 g++-9
export CC=gcc-9
export CXX=g++-9
```

### 12.2.10 性能优化配置

#### 编译器优化
```bash
# 基本优化
nvcc -O3 -arch=sm_75 -o program program.cu

# 高级优化
nvcc -O3 -arch=sm_75 -use_fast_math -ftz=true -prec-div=false -prec-sqrt=false program.cu

# 生成PTX代码
nvcc -arch=compute_75 -code=sm_75,compute_75 -o program program.cu
```

#### 运行时优化
```bash
# 设置GPU计算模式
nvidia-smi -i 0 -c 1  # 设置为独占计算模式

# 设置GPU时钟频率
nvidia-smi -i 0 -ac 810,1620  # 设置内存和核心频率

# 启用持久模式
nvidia-smi -i 0 -pm 1
```

#### 环境变量优化
```bash
# 启用CUDA设备运行时API
export CUDA_LAUNCH_BLOCKING=1

# 设置CUDA缓存
export CUDA_CACHE_MAXSIZE=2147483648

# 启用CUDA图形API
export CUDA_LAUNCH_BLOCKING=1
export CUDA_DEVICE_ORDER=PCI_BUS_ID
```

### 12.2.11 开发工具安装

#### CUDA开发工具包
```bash
# 安装完整工具包
sudo apt-get install cuda-toolkit-12-1

# 安装Nsight系统
sudo apt-get install nsight-systems-cli

# 安装Nsight计算
sudo apt-get install nsight-compute-cli
```

#### 第三方库
```bash
# cuBLAS, cuFFT, cuRAND等
sudo apt-get install libcublas-dev libcufft-dev curand-dev

# Thrust和CUB
# 已包含在CUDA工具包中

# cuDNN（深度学习库）
# 从NVIDIA开发者网站下载
```

#### IDE集成
```bash
# VS Code CUDA插件
code --install-extension ms-vscode.cpptools
# 配置tasks.json和launch.json

# CLion CUDA支持
# 在Settings -> Build -> CUDA Compiler中配置
```

### 12.3.1 基本语法

```cuda
// Kernel函数定义
__global__ void vectorAdd(float *a, float *b, float *c, int n) {
    // 获取线程索引
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    // 边界检查
    if (idx < n) {
        c[idx] = a[idx] + b[idx];
    }
}

// 主机代码
int main() {
    int n = 1000000;
    size_t size = n * sizeof(float);

    // 1. 分配主机内存
    float *h_a = (float*)malloc(size);
    float *h_b = (float*)malloc(size);
    float *h_c = (float*)malloc(size);

    // 2. 初始化数据
    for (int i = 0; i < n; i++) {
        h_a[i] = i;
        h_b[i] = i * 2;
    }

    // 3. 分配设备内存
    float *d_a, *d_b, *d_c;
    cudaMalloc(&d_a, size);
    cudaMalloc(&d_b, size);
    cudaMalloc(&d_c, size);

    // 4. 主机到设备内存拷贝
    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);
    cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);

    // 5. 配置执行参数
    int threadsPerBlock = 256;
    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;

    // 6. 启动Kernel
    vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, d_c, n);

    // 7. 设备到主机内存拷贝
    cudaMemcpy(h_c, d_c, size, cudaMemcpyDeviceToHost);

    // 8. 释放内存
    free(h_a); free(h_b); free(h_c);
    cudaFree(d_a); cudaFree(d_b); cudaFree(d_c);

    return 0;
}
```

### 12.2.2 线程索引计算

**一维索引**：
```cuda
int idx = blockIdx.x * blockDim.x + threadIdx.x;
```

**二维索引**：
```cuda
int row = blockIdx.y * blockDim.y + threadIdx.y;
int col = blockIdx.x * blockDim.x + threadIdx.x;
int idx = row * width + col;
```

**三维索引**：
```cuda
int x = blockIdx.x * blockDim.x + threadIdx.x;
int y = blockIdx.y * blockDim.y + threadIdx.y;
int z = blockIdx.z * blockDim.z + threadIdx.z;
int idx = z * width * height + y * width + x;
```

## 12.4 CUDA内存管理

### 12.3.1 内存类型详解

**全局内存（Global Memory）**：
- 所有线程都可以访问
- 延迟高，带宽大
- 需要显式分配和释放

```cuda
// 分配全局内存
float *d_data;
cudaMalloc(&d_data, size);

// 释放全局内存
cudaFree(d_data);
```

**共享内存（Shared Memory）**：
- 同一Block内的线程共享
- 速度快，容量有限（通常48-164KB）
- 需要在Kernel内声明

```cuda
__global__ void sharedMemoryExample() {
    // 声明共享内存
    __shared__ float shared_data[256];

    // 使用共享内存
    shared_data[threadIdx.x] = some_value;
    __syncthreads();  // 同步所有线程
}
```

**寄存器内存（Register Memory）**：
- 每个线程私有
- 速度最快，容量最小
- 编译器自动管理

```cuda
__global__ void registerExample() {
    float local_var = 1.0f;  // 存储在寄存器中
}
```

### 12.3.2 内存拷贝操作

```cuda
// 主机到设备
cudaMemcpy(d_dest, h_src, size, cudaMemcpyHostToDevice);

// 设备到主机
cudaMemcpy(h_dest, d_src, size, cudaMemcpyDeviceToHost);

// 设备到设备
cudaMemcpy(d_dest, d_src, size, cudaMemcpyDeviceToDevice);

// 异步拷贝
cudaMemcpyAsync(d_dest, h_src, size, cudaMemcpyHostToDevice, stream);
```

## 12.5 GPU并行模式

### 12.4.1 数据并行模式

**向量加法示例**：

```cuda
__global__ void vectorAdd(float *a, float *b, float *c, int n) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < n) {
        c[idx] = a[idx] + b[idx];
    }
}

// 使用示例
void launchVectorAdd() {
    int n = 1024 * 1024;
    size_t size = n * sizeof(float);

    // 内存分配和初始化...

    // 配置参数
    int threadsPerBlock = 256;
    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;

    // 启动Kernel
    vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, d_c, n);
}
```

### 12.4.2 矩阵乘法

**基本矩阵乘法**：

```cuda
__global__ void matrixMul(float *A, float *B, float *C, int N) {
    int row = blockIdx.y * blockDim.y + threadIdx.y;
    int col = blockIdx.x * blockDim.x + threadIdx.x;

    if (row < N && col < N) {
        float sum = 0.0f;
        for (int k = 0; k < N; k++) {
            sum += A[row * N + k] * B[k * N + col];
        }
        C[row * N + col] = sum;
    }
}

// 优化版本：使用共享内存
__global__ void matrixMulShared(float *A, float *B, float *C, int N) {
    __shared__ float As[16][16];
    __shared__ float Bs[16][16];

    int bx = blockIdx.x, by = blockIdx.y;
    int tx = threadIdx.x, ty = threadIdx.y;

    int row = by * 16 + ty;
    int col = bx * 16 + tx;

    float sum = 0.0f;

    // 分块计算
    for (int k = 0; k < (N / 16); k++) {
        // 加载数据到共享内存
        As[ty][tx] = A[row * N + k * 16 + tx];
        Bs[ty][tx] = B[(k * 16 + ty) * N + col];
        __syncthreads();

        // 计算部分结果
        for (int i = 0; i < 16; i++) {
            sum += As[ty][i] * Bs[i][tx];
        }
        __syncthreads();
    }

    // 存储结果
    C[row * N + col] = sum;
}
```

## 12.6 CUDA在生物信息学中的应用

### 12.5.1 序列比对加速

**Smith-Waterman算法的GPU实现**：

```cuda
__global__ void smithWaterman(float *query, float *target,
                             float *score_matrix, int *traceback,
                             int query_len, int target_len) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    int j = blockIdx.y * blockDim.y + threadIdx.y;

    if (i < query_len && j < target_len) {
        // 计算得分
        float match = score_matrix[i-1][j-1] + match_score(query[i], target[j]);
        float delete_score = score_matrix[i-1][j] + gap_penalty;
        float insert_score = score_matrix[i][j-1] + gap_penalty;

        score_matrix[i][j] = max(0.0f, max(match, max(delete_score, insert_score)));

        // 追踪路径
        if (score_matrix[i][j] == match) traceback[i][j] = 1;
        else if (score_matrix[i][j] == delete_score) traceback[i][j] = 2;
        else if (score_matrix[i][j] == insert_score) traceback[i][j] = 3;
    }
}
```

### 12.5.2 基因组数据处理

**并行BLAST搜索**：

```cuda
__global__ void parallelBlastSearch(char *database, char *query,
                                   int *results, int db_size, int query_size) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    if (idx < db_size - query_size + 1) {
        // 并行搜索数据库
        int score = 0;
        for (int i = 0; i < query_size; i++) {
            if (database[idx + i] == query[i]) {
                score++;
            }
        }

        if (score >= threshold) {
            results[idx] = score;
        }
    }
}
```

### 12.5.3 蛋白质结构预测

**分子动力学模拟的GPU实现**：

```cuda
__global__ void calculateForces(float *positions, float *velocities,
                               float *forces, int num_atoms) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    if (idx < num_atoms) {
        float fx = 0.0f, fy = 0.0f, fz = 0.0f;

        // 计算与其他原子的相互作用
        for (int j = 0; j < num_atoms; j++) {
            if (i != j) {
                float dx = positions[j*3] - positions[idx*3];
                float dy = positions[j*3+1] - positions[idx*3+1];
                float dz = positions[j*3+2] - positions[idx*3+2];

                float r2 = dx*dx + dy*dy + dz*dz;
                float r = sqrtf(r2);

                // Lennard-Jones势能
                float force = 24.0f * epsilon * (2.0f * pow(sigma/r, 12) - pow(sigma/r, 6)) / r;
                fx += force * dx / r;
                fy += force * dy / r;
                fz += force * dz / r;
            }
        }

        forces[idx*3] = fx;
        forces[idx*3+1] = fy;
        forces[idx*3+2] = fz;
    }
}
```

## 12.7 性能优化技巧

### 12.7.1 内存访问优化

**合并访问模式**：

```cuda
// 好的访问模式：连续内存访问
__global__ void goodAccessPattern(float *data) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    // 连续访问：thread 0访问data[0], thread 1访问data[1], ...
    float value = data[idx];
}

// 坏的访问模式：跨步访问
__global__ void badAccessPattern(float *data) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    // 跨步访问：thread 0访问data[0], thread 1访问data[32], ...
    float value = data[idx * 32];
}
```

**共享内存优化**：

```cuda
__global__ void optimizedMatrixMul(float *A, float *B, float *C, int N) {
    __shared__ float As[16][16];
    __shared__ float Bs[16][16];

    int tx = threadIdx.x, ty = threadIdx.y;
    int row = blockIdx.y * 16 + ty;
    int col = blockIdx.x * 16 + tx;

    float sum = 0.0f;

    // 分块加载数据
    for (int k = 0; k < N/16; k++) {
        As[ty][tx] = A[row * N + k * 16 + tx];
        Bs[ty][tx] = B[(k * 16 + ty) * N + col];
        __syncthreads();

        // 计算
        for (int i = 0; i < 16; i++) {
            sum += As[ty][i] * Bs[i][tx];
        }
        __syncthreads();
    }

    C[row * N + col] = sum;
}
```

### 12.7.2 计算优化

**向量化操作**：

```cuda
// 使用SIMD向量类型
__global__ void vectorizedOperation(float4 *data, float4 *result, int n) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    if (idx < n) {
        float4 val = data[idx];
        // 同时处理4个浮点数
        result[idx] = make_float4(val.x * 2.0f, val.y * 2.0f,
                                 val.z * 2.0f, val.w * 2.0f);
    }
}
```

**减少分支发散**：

```cuda
// 好的分支模式：线程束内分支一致
__global__ void goodBranching(float *data, int n) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    if (idx < n/2) {
        // 前一半线程执行
        data[idx] *= 2.0f;
    } else {
        // 后一半线程执行
        data[idx] *= 3.0f;
    }
}

// 坏的分支模式：线程束内分支不一致
__global__ void badBranching(float *data, int n) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    if (idx % 2 == 0) {
        // 奇数索引线程
        data[idx] *= 2.0f;
    } else {
        // 偶数索引线程
        data[idx] *= 3.0f;
    }
}
```

## 12.8 CUDA编程最佳实践

### 12.8.1 错误处理

```cuda
#define CUDA_CHECK(call) \
    do { \
        cudaError_t error = call; \
        if (error != cudaSuccess) { \
            fprintf(stderr, "CUDA error at %s:%d - %s\n", \
                    __FILE__, __LINE__, cudaGetErrorString(error)); \
            exit(1); \
        } \
    } while(0)

// 使用示例
CUDA_CHECK(cudaMalloc(&d_data, size));
CUDA_CHECK(cudaMemcpy(d_dest, h_src, size, cudaMemcpyHostToDevice));
CUDA_CHECK(cudaDeviceSynchronize());
```

### 12.8.2 内存管理最佳实践

```cuda
// 1. 使用统一内存（CUDA 6.0+）
float *data;
cudaMallocManaged(&data, size);

// 2. 使用内存池
cudaMemPool_t mempool;
cudaDeviceGetDefaultMemPool(&mempool, 0);
float *pooled_data;
cudaMallocAsync(&pooled_data, size, stream);

// 3. 零拷贝内存
float *zero_copy_data;
cudaHostAlloc(&zero_copy_data, size, cudaHostAllocWriteCombined);
```

### 12.8.3 性能分析

```bash
# 使用nvprof进行性能分析
nvprof --print-gpu-trace ./your_cuda_program

# 使用Nsight Systems
nsys profile ./your_cuda_program

# 使用Nsight Compute
ncu ./your_cuda_program
```

## 12.9 实际应用案例

### 12.9.1 基因表达数据分析

```cuda
__global__ void normalizeExpressionData(float *expression_matrix,
                                      float *normalized_matrix,
                                      float *row_sums, int rows, int cols) {
    int row = blockIdx.y * blockDim.y + threadIdx.y;
    int col = blockIdx.x * blockDim.x + threadIdx.x;

    if (row < rows && col < cols) {
        // 计算每行的总和
        float sum = 0.0f;
        for (int k = 0; k < cols; k++) {
            sum += expression_matrix[row * cols + k];
        }
        row_sums[row] = sum;

        // 标准化
        normalized_matrix[row * cols + col] =
            expression_matrix[row * cols + col] / sum;
    }
}
```

### 12.9.2 SNP检测加速

```cuda
__global__ void detectSNPs(unsigned char *reference_genome,
                          unsigned char *sample_genome,
                          int *snp_positions, int genome_size) {
    int pos = blockIdx.x * blockDim.x + threadIdx.x;

    if (pos < genome_size) {
        // 比较碱基
        if (reference_genome[pos] != sample_genome[pos]) {
            snp_positions[pos] = 1;  // 标记为SNP
        }
    }
}
```

### 12.9.3 蛋白质对接模拟

```cuda
__global__ void proteinDocking(float *receptor_coords,
                              float *ligand_coords,
                              float *energy_grid,
                              int grid_size) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    if (idx < grid_size * grid_size * grid_size) {
        int x = idx % grid_size;
        int y = (idx / grid_size) % grid_size;
        int z = idx / (grid_size * grid_size);

        float total_energy = 0.0f;

        // 计算受体与配体的相互作用能
        for (int i = 0; i < num_receptor_atoms; i++) {
            for (int j = 0; j < num_ligand_atoms; j++) {
                float dx = receptor_coords[i*3] - (x + ligand_coords[j*3]);
                float dy = receptor_coords[i*3+1] - (y + ligand_coords[j*3+1]);
                float dz = receptor_coords[i*3+2] - (z + ligand_coords[j*3+2]);

                float distance = sqrtf(dx*dx + dy*dy + dz*dz);
                float energy = calculateInteractionEnergy(distance);

                total_energy += energy;
            }
        }

        energy_grid[idx] = total_energy;
    }
}
```

## 12.10 总结

CUDA/GPU计算为生物信息学提供了强大的并行计算能力：

**优势**：
- 极高的并行度，适合大规模数据处理
- 高内存带宽，适合数据密集型应用
- 成熟的编程模型和工具链

**应用场景**：
- 序列比对和搜索
- 基因组数据分析
- 蛋白质结构预测和对接
- 分子动力学模拟
- 多组学数据整合

**挑战**：
- 编程复杂度较高
- 内存管理需要精细控制
- 算法需要重新设计以适应并行架构

**未来趋势**：
- 更高级的编程抽象（如Thrust、cuDF）
- 深度学习与传统计算的结合
- 异构计算平台的普及

通过合理利用CUDA/GPU计算，可以显著加速生物信息学中的计算密集型任务，为大规模生物数据分析提供强有力的支持。