# 第十二章 CUDA/GPU计算

本章将深入探讨利用NVIDIA GPU进行通用计算（GPGPU）的技术——CUDA。我们将从GPU的基础架构出发，逐步介绍环境配置、编程模型、内存管理，并重点展示CUDA在生物信息学领域的实际应用与性能优化策略。

## 12.1 GPU计算基础

### 12.1.1 为什么选择GPU？

GPU（图形处理单元）最初是为了处理计算机图形任务而设计的，但其高度并行的架构使其非常适合处理大规模数据并行计算任务。

**CPU与GPU的架构对比**

| 特性 | CPU (Latencry Oriented) | GPU (Throughput Oriented) |
| :--- | :--- | :--- |
| **设计目标** | 低延迟，擅长逻辑控制和串行计算 | 高吞吐量，擅长大规模并行计算 |
| **核心数量** | 少量（4-64个强大核心） | 大量（数千个轻量级核心） |
| **缓存机制** | 大容量多级缓存，减少内存延迟 | 较小缓存，利用多线程隐藏延迟 |
| **控制单元** | 复杂的分支预测和乱序执行 | 简单的控制逻辑，SIMT模式 |
| **适用场景** | 操作系统、数据库、复杂逻辑处理 | 矩阵运算、图像处理、深度学习、分子模拟 |

### 12.1.2 GPU核心架构特点

*   **SIMT (Single Instruction, Multiple Threads)**：单指令多线程。一个指令被多个线程同时执行，但每个线程处理不同的数据。
*   **SM (Streaming Multiprocessor)**：流多处理器。GPU的核心构建块，包含多个CUDA核心、共享内存、寄存器文件和调度器。
*   **CUDA Core**：执行浮点和整数运算的基本单元。

---

## 12.2 CUDA环境安装与配置

### 12.2.1 软硬件要求
*   **硬件**：支持CUDA的NVIDIA显卡（建议Compute Capability 6.0+）。
*   **系统**：Linux (推荐Ubuntu/CentOS), Windows 10/11。
*   **编译器**：`nvcc` (NVIDIA CUDA Compiler)，通常需要配合 `gcc` / `g++`。

### 12.2.2 Linux (Ubuntu) 安装指南

推荐使用包管理器安装，便于后续更新。

```bash
# 1. 移除旧版本
sudo apt-get --purge remove "*cublas*" "cuda*" "nsight*" 

# 2. 下载并安装Keyring (以Ubuntu 22.04, CUDA 12.1为例)
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.0-1_all.deb
sudo dpkg -i cuda-keyring_1.0-1_all.deb
sudo apt-get update

# 3. 安装CUDA Toolkit
sudo apt-get -y install cuda

# 4. 配置环境变量 (添加到 ~/.bashrc)
export PATH=/usr/local/cuda/bin:$PATH
export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH
```

### 12.2.3 验证安装

```bash
# 检查驱动状态
nvidia-smi

# 检查编译器版本
nvcc --version

# 编译并运行示例程序
cat > hello.cu <<EOF
#include <stdio.h>
__global__ void hello() {
    printf("Hello from GPU thread %d!\n", threadIdx.x);
}
int main() {
    hello<<<1, 5>>>();
    cudaDeviceSynchronize();
    return 0;
}
EOF

nvcc hello.cu -o hello && ./hello
```

---

## 12.3 CUDA编程模型

### 12.3.1 核心概念

CUDA扩展了C++语言，引入了**主机 (Host)** 和 **设备 (Device)** 的概念。
*   **Host**：CPU及其内存。
*   **Device**：GPU及其内存。
*   **Kernel**：运行在Device上的函数，由Host调用。

### 12.3.2 线程层次结构

CUDA通过三级层次结构组织线程，以适应GPU硬件：

1.  **Grid (网格)**：由多个Block组成，对应一次Kernel启动。
2.  **Block (线程块)**：由多个Thread组成，Block内的线程可以协同工作（共享内存、同步）。
3.  **Thread (线程)**：执行计算的最小单元。

**索引计算示例 (2D)**：

```cpp
// 假设 Kernel启动参数为: dim3 grid(2, 2); dim3 block(16, 16);
__global__ void matrixKernel(float* d_A) {
    // 计算全局唯一的行和列索引
    int row = blockIdx.y * blockDim.y + threadIdx.y;
    int col = blockIdx.x * blockDim.x + threadIdx.x;
    
    // ...
}
```

### 12.3.3 完整的向量加法示例

```cpp
#include <cuda_runtime.h>
#include <stdio.h>

// 错误检查宏
#define CUDA_CHECK(call) \
    do { \
        cudaError_t err = call; \
        if (err != cudaSuccess) { \
            fprintf(stderr, "CUDA Error: %s at line %d\n", \
                    cudaGetErrorString(err), __LINE__); \
            exit(1); \
        } \
    } while(0)

// Kernel函数：运行在GPU上
__global__ void vectorAdd(const float *A, const float *B, float *C, int numElements) {
    int i = blockDim.x * blockIdx.x + threadIdx.x;
    if (i < numElements) {
        C[i] = A[i] + B[i];
    }
}

int main() {
    int n = 50000;
    size_t size = n * sizeof(float);

    // 1. 分配主机内存
    float *h_A = (float *)malloc(size);
    float *h_B = (float *)malloc(size);
    float *h_C = (float *)malloc(size);

    // 初始化数据...
    for (int i = 0; i < n; ++i) { h_A[i] = 1.0f; h_B[i] = 2.0f; }

    // 2. 分配设备内存
    float *d_A, *d_B, *d_C;
    CUDA_CHECK(cudaMalloc(&d_A, size));
    CUDA_CHECK(cudaMalloc(&d_B, size));
    CUDA_CHECK(cudaMalloc(&d_C, size));

    // 3. 数据拷贝: Host -> Device
    CUDA_CHECK(cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice));
    CUDA_CHECK(cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice));

    // 4. 启动Kernel
    int threadsPerBlock = 256;
    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;
    vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, n);
    
    // 检查Kernel启动错误
    CUDA_CHECK(cudaGetLastError());
    // 等待GPU完成 (可选，cudaMemcpy会自动同步)
    CUDA_CHECK(cudaDeviceSynchronize());

    // 5. 数据拷贝: Device -> Host
    CUDA_CHECK(cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost));

    // 验证结果
    if (fabs(h_C[0] - 3.0f) < 1e-5) printf("Test PASSED\n");

    // 6. 释放内存
    cudaFree(d_A); cudaFree(d_B); cudaFree(d_C);
    free(h_A); free(h_B); free(h_C);

    return 0;
}
```

---

## 12.4 CUDA内存管理

理解内存层次是CUDA性能优化的关键。

### 12.4.1 内存类型详解

| 内存类型 | 作用域 | 生命周期 | 速度 | 说明 |
| :--- | :--- | :--- | :--- | :--- |
| **寄存器 (Registers)** | 线程 | 线程 | 最快 | 编译器自动分配，资源稀缺。 |
| **共享内存 (Shared Mem)**| Block | Block | 极快 | 用户可控的L1缓存，用于Block内通信。 |
| **全局内存 (Global Mem)**| Grid | 应用程序 | 较慢 | 容量最大，所有线程可见，延迟高。 |
| **常量内存 (Constant)** | Grid | 应用程序 | 快 (有缓存) | 只读，适合存储参数常量。 |
| **本地内存 (Local Mem)** | 线程 | 线程 | 较慢 | 寄存器溢出时使用，存储在DRAM中。 |

### 12.4.2 共享内存优化案例：矩阵乘法

使用共享内存进行分块（Tiling）计算，大幅减少对全局内存的访问。

```cpp
#define TILE_WIDTH 16

__global__ void matrixMulShared(float *A, float *B, float *C, int N) {
    // 声明共享内存块
    __shared__ float As[TILE_WIDTH][TILE_WIDTH];
    __shared__ float Bs[TILE_WIDTH][TILE_WIDTH];

    int bx = blockIdx.x;  int by = blockIdx.y;
    int tx = threadIdx.x; int ty = threadIdx.y;

    // 计算当前线程处理的结果矩阵坐标
    int Row = by * TILE_WIDTH + ty;
    int Col = bx * TILE_WIDTH + tx;
    float Pvalue = 0;

    // 循环遍历所有Tile
    for (int m = 0; m < (N - 1) / TILE_WIDTH + 1; ++m) {
        // 1. 将数据从全局内存加载到共享内存
        if (Row < N && m * TILE_WIDTH + tx < N)
             As[ty][tx] = A[Row * N + m * TILE_WIDTH + tx];
        else As[ty][tx] = 0.0f;

        if (Col < N && m * TILE_WIDTH + ty < N)
             Bs[ty][tx] = B[(m * TILE_WIDTH + ty) * N + Col];
        else Bs[ty][tx] = 0.0f;
        
        // 必须同步，确保所有线程完成加载
        __syncthreads();

        // 2. 在共享内存上进行计算
        for (int k = 0; k < TILE_WIDTH; ++k)
            Pvalue += As[ty][k] * Bs[k][tx];
            
        // 必须同步，确保计算完成再加载下一个Tile
        __syncthreads();
    }

    if (Row < N && Col < N)
        C[Row * N + Col] = Pvalue;
}
```

---

## 12.5 CUDA在生物信息学中的应用

### 12.5.1 Smith-Waterman 序列比对加速

Smith-Waterman 是局部序列比对的黄金标准，但计算量大 ($O(MN)$)。GPU可以通过并行计算对角线上的单元格来加速。

**核心思想**：
动态规划矩阵中，反对角线上的元素 $ (i, j) $ 仅依赖于左上方的元素，彼此之间无依赖，可以并行计算。

```cpp
// 伪代码示例
__global__ void smith_waterman_kernel(...) {
    // 计算当前线程负责的矩阵单元格 (i, j)
    // 从共享内存或纹理内存读取序列数据
    // 计算得分：match/mismatch, gap penalty
    // 更新 Score Matrix
}
```

### 12.5.2 分子动力学模拟 (Molecular Dynamics)

分子动力学模拟（如GROMACS, AMBER）涉及计算大量原子间的相互作用力（如范德华力、库仑力），这是典型的 $N$-body 问题，非常适合GPU加速。

```cpp
__global__ void calculateForces(float4* pos, float3* force, int N) {
    int i = blockDim.x * blockIdx.x + threadIdx.x;
    if (i >= N) return;

    float3 f = make_float3(0.0f, 0.0f, 0.0f);
    float4 myPos = pos[i];

    // 计算原子 i 与所有其他原子 j 的相互作用
    for (int j = 0; j < N; j++) {
        if (i == j) continue;
        float3 diff;
        diff.x = pos[j].x - myPos.x;
        // ... 计算距离和力 ...
        f.x += force_val * dx;
        // ...
    }
    force[i] = f;
}
```

---

## 12.6 性能优化最佳实践

1.  **最大化并行度**：确保有足够的Block和Thread来占满GPU的所有SM，隐藏内存延迟。
2.  **内存合并访问 (Coalesced Access)**：确保Warp内的线程访问连续的全局内存地址，以利用内存总线带宽。
3.  **减少分支发散 (Warp Divergence)**：避免同一Warp内的线程执行不同的 `if-else` 分支路径。
4.  **利用快速内存**：尽可能使用共享内存和寄存器，减少对全局内存的依赖。
5.  **主机-设备传输优化**：减少PCIe传输次数，使用 `cudaMemcpyAsync` 和 Stream 实现计算与传输的重叠。

## 12.7 总结

CUDA为高性能计算开辟了新的天地。通过将计算密集型任务从CPU转移到GPU，我们可以获得数十倍甚至上百倍的加速。在生物信息学领域，从基因组组装到蛋白质结构预测，GPU计算已成为不可或缺的工具。掌握CUDA编程模型和优化技巧，是开发下一代高效生物信息学算法的关键。