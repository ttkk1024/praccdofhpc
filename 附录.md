# 附录

## A. 常用术语表

### 基础概念
- **并行度 (Parallelism)**：同时执行的任务数量
- **并发 (Concurrency)**：多个任务交替执行的能力
- **吞吐量 (Throughput)**：单位时间内完成的工作量
- **延迟 (Latency)**：任务从开始到完成的时间
- **带宽 (Bandwidth)**：系统或网络的数据传输能力，通常以每秒传输的字节数表示
- **吞吐率 (Throughput Rate)**：实际完成工作的速率，考虑了所有开销
- **响应时间 (Response Time)**：从请求发出到获得响应的总时间
- **周转时间 (Turnaround Time)**：作业从提交到完成的总时间
- **等待时间 (Waiting Time)**：作业在就绪队列中等待的时间
- **服务时间 (Service Time)**：处理器实际执行作业的时间
- **利用率 (Utilization)**：资源被有效使用的时间比例
- **空闲时间 (Idle Time)**：处理器等待任务的时间
- **吞吐量延迟积 (Throughput-Latency Product)**：系统处理能力和响应速度的综合指标
- **资源争用 (Resource Contention)**：多个任务竞争同一资源的情况

### 性能指标
- **FLOPS**：每秒浮点运算次数 (Floating Point Operations Per Second)
- **MFLOPS**：每秒百万次浮点运算 (10⁶ FLOPS)
- **GFLOPS**：每秒十亿次浮点运算 (10⁹ FLOPS)
- **TFLOPS**：每秒万亿次浮点运算 (10¹² FLOPS)
- **PFLOPS**：每秒千万亿次浮点运算 (10¹⁵ FLOPS)
- **EFLOPS**：每秒百亿亿次浮点运算 (10¹⁸ FLOPS)
- **理论峰值性能**：Rpeak = CPU数量 × 核心数 × 频率 × FLOP/周期
- **实际性能**：Rmax = 实际测得的持续性能
- **效率**：Efficiency = Rmax / Rpeak × 100%

### 并行计算
- **加速比 (Speedup)**：并行程序相对于串行程序的加速倍数
- **效率 (Efficiency)**：并行程序利用计算资源的效率
- **可扩展性 (Scalability)**：系统处理更大问题或更多处理器的能力
- **Amdahl定律**：并行计算理论加速比上限
- **Gustafson定律**：可扩展问题的加速比理论

### 通信与同步
- **消息传递 (Message Passing)**：进程间通信方式
- **共享内存 (Shared Memory)**：多个处理器共享的内存空间
- **同步 (Synchronization)**：协调多个并行任务的执行
- **屏障同步 (Barrier)**：所有进程到达指定点后继续执行
- **竞态条件 (Race Condition)**：多个线程访问共享资源时的不确定性
- **死锁 (Deadlock)**：多个进程相互等待对方释放资源
- **活锁 (Livelock)**：进程不断重复相同动作而无法前进

### 内存与存储
- **缓存 (Cache)**：高速缓冲存储器
- **缓存命中 (Cache Hit)**：请求的数据在缓存中找到
- **缓存未命中 (Cache Miss)**：请求的数据不在缓存中
- **局部性原理 (Locality Principle)**：时间局部性和空间局部性
- **虚拟内存 (Virtual Memory)**：扩展物理内存的技术
- **分页 (Paging)**：内存管理技术

### 网络与通信
- **带宽 (Bandwidth)**：网络传输能力
- **延迟 (Latency)**：数据传输延迟时间
- **吞吐量 (Throughput)**：实际传输速率
- **拓扑结构 (Topology)**：网络连接结构
- **路由 (Routing)**：数据包传输路径选择

### GPU计算
- **CUDA核心**：NVIDIA GPU的基本计算单元
- **流处理器**：AMD GPU的计算单元
- **SM (Streaming Multiprocessor)**：GPU计算单元
- **Warp**：CUDA中的线程组
- **Block**：线程块
- **Grid**：线程网格

### 分布式系统
- **集群 (Cluster)**：多台计算机组成的计算系统
- **节点 (Node)**：集群中的单个计算单元
- **主节点 (Master Node)**：控制和协调其他节点
- **工作节点 (Worker Node)**：执行具体计算任务
- **容错 (Fault Tolerance)**：系统在部分组件失效时继续运行的能力
- **负载均衡 (Load Balancing)**：将工作均匀分配给所有处理器

### 大数据
- **HDFS**：Hadoop分布式文件系统
- **MapReduce**：分布式计算编程模型
- **Spark**：内存计算框架
- **数据分区 (Partitioning)**：将大数据集分割成小块
- **数据倾斜 (Data Skew)**：数据分布不均匀

### 人工智能
- **深度学习 (Deep Learning)**：多层神经网络
- **神经网络 (Neural Network)**：模拟人脑的学习模型
- **卷积神经网络 (CNN)**：用于图像处理的神经网络
- **循环神经网络 (RNN)**：处理序列数据的神经网络
- **梯度下降 (Gradient Descent)**：优化算法
- **反向传播 (Backpropagation)**：神经网络训练算法

## B. 数学基础

### 线性代数
- **矩阵乘法**：O(n³)复杂度，可并行化
- **LU分解**：矩阵分解算法
- **特征值计算**：矩阵特征分析
- **奇异值分解 (SVD)**：矩阵分解方法

### 数值分析
- **误差分析**：舍入误差和截断误差
- **稳定性**：算法对误差的敏感性
- **收敛性**：迭代算法的收敛性质
- **精度**：计算结果的精确程度

### 概率统计
- **蒙特卡洛方法**：随机模拟方法
- **统计分布**：正态分布、泊松分布等
- **假设检验**：统计推断方法
- **回归分析**：变量关系分析

## C. 常用算法复杂度

### 排序算法
- **冒泡排序**：O(n²)
- **快速排序**：O(n log n) 平均，O(n²) 最坏
- **归并排序**：O(n log n)
- **堆排序**：O(n log n)

### 搜索算法
- **线性搜索**：O(n)
- **二分搜索**：O(log n)
- **广度优先搜索**：O(V + E)
- **深度优先搜索**：O(V + E)

### 图算法
- **Dijkstra算法**：O((V + E) log V)
- **Floyd-Warshall**：O(V³)
- **Prim算法**：O(E log V)
- **Kruskal算法**：O(E log E)

### 矩阵算法
- **矩阵乘法**：O(n³)
- **高斯消元**：O(n³)
- **LU分解**：O(n³)
- **特征值计算**：O(n³)

## D. 硬件架构

### CPU架构
- **x86-64**：主流桌面和服务器架构
- **ARM**：移动设备和嵌入式系统
- **RISC-V**：开源指令集架构
- **SIMD**：单指令多数据流

### GPU架构
- **NVIDIA CUDA**：并行计算架构
- **AMD ROCm**：AMD的GPU计算平台
- **OpenCL**：跨平台并行计算框架
- **Tensor Core**：NVIDIA的矩阵计算单元

### 存储系统
- **SSD**：固态硬盘
- **NVMe**：高速存储接口
- **RAID**：磁盘阵列技术
- **分布式存储**：跨多节点的存储系统

### 网络互连
- **InfiniBand**：高速网络互连
- **Ethernet**：以太网
- **RoCE**：RDMA over Converged Ethernet
- **Omni-Path**：Intel的高性能网络

## E. 编程语言和库

### C/C++
- **标准库**：STL容器和算法
- **Boost**：C++扩展库
- **Eigen**：线性代数库
- **OpenMP**：共享内存并行

### Python
- **NumPy**：数值计算库
- **SciPy**：科学计算库
- **Pandas**：数据分析库
- **Scikit-learn**：机器学习库
- **TensorFlow**：深度学习框架
- **PyTorch**：深度学习框架

### Fortran
- **BLAS**：基础线性代数子程序
- **LAPACK**：线性代数包
- **ScaLAPACK**：分布式线性代数包
- **MPI**：消息传递接口

### Java
- **Hadoop**：大数据处理框架
- **Spark**：内存计算框架
- **Akka**：并发编程框架

## F. 性能分析工具

### 开源工具
- **gprof**：GNU性能分析器
- **perf**：Linux性能分析工具
- **Valgrind**：内存和性能分析
- **TAU**：Tuning and Analysis Utilities
- **Vampir**：可视化性能分析

### 商业工具
- **Intel VTune**：Intel性能分析器
- **AMD uProf**：AMD性能分析工具
- **NVIDIA Nsight**：NVIDIA开发工具
- **TotalView**：并行调试器
- **Allinea DDT**：并行调试器

## G. 常用命令和脚本

### Linux系统命令
```bash
# 查看CPU信息
lscpu

# 查看内存信息
free -h

# 查看进程信息
ps aux | grep process_name

# 查看网络连接
netstat -an

# 查看磁盘使用
df -h

# 查看系统负载
uptime
```

### 性能监控脚本
```bash
#!/bin/bash
# 系统性能监控脚本

echo "=== CPU Usage ==="
top -bn1 | grep "Cpu(s)" | sed "s/.*, *\([0-9.]*\)%* id.*/\1/" | awk '{print 100 - $1"%"}'

echo "=== Memory Usage ==="
free -h | awk 'NR==2{printf "Memory Usage: %s/%s (%.2f%%)\n", $3,$2,$3*100/$2 }'

echo "=== Disk Usage ==="
df -h | awk '$5 > 80 {print $0}'

echo "=== Network Connections ==="
netstat -an | grep ESTABLISHED | wc -l
```

### 编译和构建脚本
```bash
#!/bin/bash
# 并行程序编译脚本

# 设置编译器
CC=mpicc
CXX=mpicxx
FC=mpif90

# 编译选项
CFLAGS="-O3 -march=native -funroll-loops"
CXXFLAGS="$CFLAGS"
FCFLAGS="$CFLAGS"

# 编译MPI程序
$CC $CFLAGS -o mpi_program mpi_program.c

# 编译OpenMP程序
$CC $CFLAGS -fopenmp -o omp_program omp_program.c

# 编译CUDA程序
nvcc -O3 -arch=sm_75 -o cuda_program cuda_program.cu
```

## H. 参考资源

### 在线资源
- **TOP500**：https://www.top500.org/ - 全球超级计算机排名
- **HPCwire**：https://www.hpcwire.com/ - HPC新闻和资源
- **arXiv**：https://arxiv.org/ - 计算机科学论文
- **GitHub**：https://github.com/ - 开源项目

### 标准文档
- **MPI标准**：https://www.mpi-forum.org/docs/
- **OpenMP标准**：https://www.openmp.org/
- **CUDA文档**：https://docs.nvidia.com/cuda/
- **OpenCL规范**：https://www.khronos.org/opencl/

### 教育资源
- **Coursera**：并行计算和HPC课程
- **edX**：高性能计算相关课程
- **MIT OpenCourseWare**：计算机科学课程
- **NVIDIA DLI**：深度学习和GPU编程培训

## I. 常见问题解答

### Q: 如何选择合适的并行编程模型？
A: 根据应用特点选择：
- 共享内存系统：OpenMP
- 分布式内存系统：MPI
- GPU加速：CUDA/OpenCL
- 大数据处理：Spark/Hadoop

### Q: 如何提高并行程序的性能？
A: 从以下几个方面考虑：
- 算法优化：选择合适的并行算法
- 负载均衡：确保工作量均匀分布
- 通信优化：减少通信开销
- 内存优化：提高缓存命中率

### Q: 如何调试并行程序？
A: 使用专门的调试工具：
- MPI程序：TotalView、Allinea DDT
- OpenMP程序：Intel Inspector、Valgrind
- GPU程序：CUDA-GDB、Nsight

### Q: 如何评估并行程序的可扩展性？
A: 使用Amdahl定律和Gustafson定律：
- 测量串行部分比例
- 测试不同处理器数量下的性能
- 计算加速比和效率

## J. 索引

### 按字母顺序
- Amdahl定律 - 3.2节
- BLAS - 附录E
- CUDA - 12.1节
- FFTW - 15.2节
- GPU - 4.1节
- HPL - 13.3节
- LINPACK - 13.2节
- MPI - 10.1节
- NUMA - 15.2节
- OpenMP - 11.1节
- SIMD - 2.1节
- STREAM - 13.2节

### 按主题分类
- 性能评估：第13章
- 性能分析：第14章
- 优化策略：第15章
- 工具框架：第四部分
- 实际应用：第三部分

---

*本附录提供了并行计算与高性能计算领域的基础知识和参考资料，便于读者快速查找和学习。*