# 第九章：系统生物学

## 目录

- [9.1 系统生物学概述](#9.1 系统生物学概述)
  - [9.1.1 系统生物学定义](#9.1.1 系统生物学定义)
  - [9.1.2 系统生物学层次](#9.1.2 系统生物学层次)
  - [9.1.3 系统生物学研究方法](#9.1.3 系统生物学研究方法)
  - [9.1.4 系统生物学挑战](#9.1.4 系统生物学挑战)
- [9.2 代谢网络建模](#9.2 代谢网络建模)
  - [9.2.1 代谢网络基础](#9.2.1 代谢网络基础)
  - [9.2.2 通量平衡分析（FBA）](#9.2.2 通量平衡分析（FBA）)
  - [9.2.3 通量变异性分析（FVA）](#9.2.3 通量变异性分析（FVA）)
  - [9.2.4 基因敲除分析](#9.2.4 基因敲除分析)
  - [9.2.5 并行代谢网络优化](#9.2.5 并行代谢网络优化)
- [9.3 信号通路分析](#9.3 信号通路分析)
  - [9.3.1 信号通路网络建模](#9.3.1 信号通路网络建模)
  - [9.3.2 动力学模拟](#9.3.2 动力学模拟)
  - [9.3.3 通路富集分析](#9.3.3 通路富集分析)
  - [9.3.4 网络拓扑分析](#9.3.4 网络拓扑分析)
- [9.4 多组学数据整合](#9.4 多组学数据整合)
  - [9.4.1 组学数据类型](#9.4.1 组学数据类型)
  - [9.4.2 数据标准化](#9.4.2 数据标准化)
  - [9.4.3 特征选择](#9.4.3 特征选择)
  - [9.4.4 网络重建](#9.4.4 网络重建)
  - [9.4.5 系统级分析](#9.4.5 系统级分析)
- [9.5 系统生物学工具](#9.5 系统生物学工具)
  - [9.5.1 常用软件工具](#9.5.1 常用软件工具)
  - [9.5.2 专用软件平台](#9.5.2 专用软件平台)
- [9.6 并行计算在系统生物学中的应用](#9.6 并行计算在系统生物学中的应用)
  - [9.6.1 大规模基因组分析](#9.6.1 大规模基因组分析)
  - [9.6.2 分子动力学模拟](#9.6.2 分子动力学模拟)
  - [9.6.3 单细胞数据分析](#9.6.3 单细胞数据分析)
- [9.7 实际案例研究](#9.7 实际案例研究)
  - [9.7.1 癌症系统生物学](#9.7.1 癌症系统生物学)
  - [9.7.2 微生物组系统生物学](#9.7.2 微生物组系统生物学)
  - [9.7.3 合成生物学](#9.7.3 合成生物学)
- [本章小结](#本章小结)
  - [核心领域](#核心领域)
  - [关键技术](#关键技术)
  - [实际应用](#实际应用)
  - [未来方向](#未来方向)


## 9.1 系统生物学概述

### 9.1.1 系统生物学定义

**系统生物学（Systems Biology）** 是一门整合生物学、数学、计算机科学和工程学的交叉学科，旨在从系统层面理解生物体的复杂性。

**核心特征**：
- **整体性**：研究生物系统的整体行为而非单个组分
- **整合性**：整合多种数据类型和分析方法
- **动态性**：关注系统随时间的变化
- **预测性**：建立可预测的数学模型

### 9.1.2 系统生物学层次

**分子层次**：
- 基因表达调控
- 蛋白质相互作用
- 代谢反应网络

**细胞层次**：
- 信号转导通路
- 细胞周期调控
- 细胞代谢

**组织和器官层次**：
- 器官功能协调
- 组织发育
- 系统生理学

**生物体层次**：
- 整体生理功能
- 行为学
- 进化适应

### 9.1.3 系统生物学研究方法

**自下而上（Bottom-up）**：
```python

# 基于组分构建系统模型
def bottom_up_modeling():
    # 1. 识别生物分子组分
    genes = identify_genes()
    proteins = identify_proteins()
    metabolites = identify_metabolites()

    # 2. 确定相互作用
    interactions = map_interactions(genes, proteins, metabolites)

    # 3. 构建数学模型
    model = build_mathematical_model(interactions)

    # 4. 模拟系统行为
    simulation = simulate_system(model)

    return simulation
```

**自上而下（Top-down）**：
```python

# 基于系统行为推断机制
def top_down_analysis():
    # 1. 观察系统表型
    phenotype = observe_phenotype()

    # 2. 生成组学数据
    omics_data = generate_omics_data(phenotype)

    # 3. 识别关键分子
    key_molecules = identify_key_molecules(omics_data)

    # 4. 验证假设
    validate_hypothesis(key_molecules)

    return validated_model
```

### 9.1.4 系统生物学挑战

**数据复杂性**：
- 多层次、多维度数据整合
- 数据噪声和不确定性
- 数据标准化和质量控制

**计算挑战**：
- 大规模模型求解
- 参数优化
- 实时模拟和预测

**生物学复杂性**：
- 非线性动态行为
- 反馈调节机制
- 环境和遗传变异

## 9.2 代谢网络建模

### 9.2.1 代谢网络基础

#### 9.2.1.1 代谢网络定义

**代谢网络（Metabolic Network）** 是描述生物体内所有代谢反应及其相互关系的网络模型。

**网络组成**：
- **代谢物（Metabolites）**：网络中的节点
- **反应（Reactions）**：连接代谢物的边
- **酶（Enzymes）**：催化反应的蛋白质
- **基因（Genes）**：编码酶的遗传信息

#### 9.2.1.2 代谢网络表示

**化学计量矩阵**：
```python
import numpy as np
import pandas as pd

class MetabolicNetwork:
    def __init__(self, metabolites, reactions, stoichiometry):
        self.metabolites = metabolites  # 代谢物列表
        self.reactions = reactions      # 反应列表
        self.S = stoichiometry          # 化学计量矩阵

    def build_stoichiometry_matrix(self, reaction_data):
        """构建化学计量矩阵"""
        n_metabolites = len(self.metabolites)
        n_reactions = len(self.reactions)

        # 初始化化学计量矩阵
        S = np.zeros((n_metabolites, n_reactions))

        for i, reaction in enumerate(self.reactions):
            for metabolite, coefficient in reaction_data[reaction].items():
                j = self.metabolites.index(metabolite)
                S[j, i] = coefficient

        return S

# 示例：简单的糖酵解网络
metabolites = ['Glucose', 'Glucose-6-P', 'Fructose-6-P', 'Fructose-1,6-BP', 'ATP', 'ADP']
reactions = ['Hexokinase', 'Phosphoglucose isomerase', 'Phosphofructokinase']

reaction_data = {
    'Hexokinase': {'Glucose': -1, 'ATP': -1, 'Glucose-6-P': 1, 'ADP': 1},
    'Phosphoglucose isomerase': {'Glucose-6-P': -1, 'Fructose-6-P': 1},
    'Phosphofructokinase': {'Fructose-6-P': -1, 'ATP': -1, 'Fructose-1,6-BP': 1, 'ADP': 1}
}

network = MetabolicNetwork(metabolites, reactions, None)
S = network.build_stoichiometry_matrix(reaction_data)
print("化学计量矩阵:")
print(pd.DataFrame(S, index=metabolites, columns=reactions))
```

#### 9.2.1.3 代谢网络拓扑分析

**网络拓扑指标**：
```python
import networkx as nx

def analyze_network_topology(S, metabolites, reactions):
    """分析代谢网络拓扑结构"""
    # 构建网络图
    G = nx.DiGraph()

    # 添加代谢物节点
    for metabolite in metabolites:
        G.add_node(metabolite, type='metabolite')

    # 添加反应节点和边
    for i, reaction in enumerate(reactions):
        reaction_node = f"R_{reaction}"
        G.add_node(reaction_node, type='reaction')

        # 连接反应和代谢物
        for j, metabolite in enumerate(metabolites):
            coefficient = S[j, i]
            if coefficient != 0:
                if coefficient < 0:  # 底物
                    G.add_edge(metabolite, reaction_node, weight=abs(coefficient))
                else:  # 产物
                    G.add_edge(reaction_node, metabolite, weight=coefficient)

    # 计算拓扑指标
    metrics = {}

    # 节点度分布
    degrees = dict(G.degree())
    metrics['degree_distribution'] = degrees

    # 连通性
    metrics['number_of_nodes'] = G.number_of_nodes()
    metrics['number_of_edges'] = G.number_of_edges()
    metrics['connected_components'] = list(nx.connected_components(G.to_undirected()))

    # 中心性分析
    betweenness_centrality = nx.betweenness_centrality(G)
    closeness_centrality = nx.closeness_centrality(G)
    metrics['betweenness_centrality'] = betweenness_centrality
    metrics['closeness_centrality'] = closeness_centrality

    # 路径分析
    try:
        metrics['diameter'] = nx.diameter(G.to_undirected())
        metrics['average_path_length'] = nx.average_shortest_path_length(G.to_undirected())
    except nx.NetworkXError:
        metrics['diameter'] = "Not connected"
        metrics['average_path_length'] = "Not connected"

    return metrics, G

# 分析网络拓扑
metrics, graph = analyze_network_topology(S, metabolites, reactions)

print("网络拓扑分析结果:")
print(f"节点数: {metrics['number_of_nodes']}")
print(f"边数: {metrics['number_of_edges']}")
print(f"平均路径长度: {metrics['average_path_length']}")
```

### 9.2.2 通量平衡分析（FBA）

#### 9.2.2.1 FBA原理

**通量平衡分析（Flux Balance Analysis, FBA）** 是一种基于约束的代谢网络分析方法，通过线性规划求解代谢通量分布。

**基本假设**：
- 稳态假设：代谢物浓度不随时间变化
- 约束条件：反应热力学和酶容量限制
- 目标函数：生物体适应性最大化

**数学模型**：
```
最大化：v_bio (生物量合成速率)
约束条件：S·v = 0 (稳态约束)
          v_min ≤ v ≤ v_max (通量边界)
```

#### 9.2.2.2 FBA实现

**线性规划求解**：
```python
import numpy as np
from scipy.optimize import linprog

class FluxBalanceAnalysis:
    def __init__(self, stoichiometry_matrix, metabolites, reactions):
        self.S = stoichiometry_matrix
        self.metabolites = metabolites
        self.reactions = reactions
        self.n_metabolites = len(metabolites)
        self.n_reactions = len(reactions)

    def set_bounds(self, bounds_dict):
        """设置反应通量边界"""
        self.bounds = []
        for reaction in self.reactions:
            if reaction in bounds_dict:
                self.bounds.append(bounds_dict[reaction])
            else:
                self.bounds.append((-1000, 1000))  # 默认边界

    def set_objective(self, objective_coefficients):
        """设置目标函数系数"""
        self.c = objective_coefficients

    def solve_fba(self):
        """求解FBA问题"""
        # 约束条件：S·v = 0
        A_eq = self.S
        b_eq = np.zeros(self.n_metabolites)

        # 求解线性规划（注意：linprog默认最小化，所以取负号）
        result = linprog(
            c=-np.array(self.c),  # 最大化转为最小化
            A_eq=A_eq,
            b_eq=b_eq,
            bounds=self.bounds,
            method='highs'
        )

        return result

    def set_growth_objective(self, growth_reaction_index):
        """设置生长目标函数"""
        objective = np.zeros(self.n_reactions)
        objective[growth_reaction_index] = 1
        self.c = objective

# 使用示例
fba = FluxBalanceAnalysis(S, metabolites, reactions)

# 设置通量边界
bounds = {
    'Hexokinase': (0, 100),  # 单向反应
    'Phosphoglucose isomerase': (-100, 100),  # 双向反应
    'Phosphofructokinase': (0, 100)
}
fba.set_bounds(bounds)

# 设置目标函数（假设最后一个反应是生物量合成）
fba.set_growth_objective(len(reactions) - 1)

# 求解FBA
result = fba.solve_fba()

if result.success:
    print("FBA求解成功!")
    print(f"最大生长速率: {result.fun * -1}")
    print("通量分布:")
    for i, reaction in enumerate(reactions):
        print(f"  {reaction}: {result.x[i]:.4f}")
else:
    print("FBA求解失败:", result.message)
```

#### 9.2.2.3 FBA高级功能

**多个目标函数**：
```python
class MultiObjectiveFBA(FluxBalanceAnalysis):
    def optimize_multiple_objectives(self, objectives, weights):
        """多目标优化"""
        # 加权求和法
        combined_objective = np.zeros(self.n_reactions)

        for obj, weight in zip(objectives, weights):
            combined_objective += weight * np.array(obj)

        self.c = combined_objective
        return self.solve_fba()

    def pareto_optimization(self, objective1, objective2, steps=10):
        """Pareto前沿分析"""
        results = []

        for i in range(steps + 1):
            weight1 = i / steps
            weight2 = 1 - weight1

            # 约束第一个目标
            result1 = self.optimize_single_objective(objective1)
            if result1.success:
                constraint_value = np.dot(objective1, result1.x)

                # 优化第二个目标，约束第一个目标
                self.add_constraint(objective1, constraint_value)
                result2 = self.optimize_single_objective(objective2)

                if result2.success:
                    results.append({
                        'weight1': weight1,
                        'weight2': weight2,
                        'obj1_value': np.dot(objective1, result2.x),
                        'obj2_value': np.dot(objective2, result2.x),
                        'fluxes': result2.x
                    })

        return results

    def optimize_single_objective(self, objective):
        """优化单个目标"""
        self.c = objective
        return self.solve_fba()
```

### 9.2.3 通量变异性分析（FVA）

#### 9.2.3.1 FVA原理

**通量变异性分析（Flux Variability Analysis, FVA）** 用于分析在给定目标函数值下，各个反应通量的变化范围。

**分析目的**：
- 识别必须反应（通量范围为0）
- 识别灵活反应（通量范围大）
- 评估代谢网络的鲁棒性

#### 9.2.3.2 FVA实现

```python
class FluxVariabilityAnalysis:
    def __init__(self, fba_instance):
        self.fba = fba_instance
        self.original_objective = fba_instance.c.copy()
        self.original_bounds = fba_instance.bounds.copy()

    def analyze_flux_variability(self, objective_fraction=0.99):
        """分析通量变异性"""
        n_reactions = len(self.fba.reactions)
        min_fluxes = np.zeros(n_reactions)
        max_fluxes = np.zeros(n_reactions)

        # 设置目标约束
        self.fba.set_bounds(self.original_bounds)
        result = self.fba.solve_fba()

        if not result.success:
            raise ValueError("FBA求解失败，无法进行FVA")

        optimal_value = result.fun * -1  # 转回正值
        objective_constraint = optimal_value * objective_fraction

        # 对每个反应进行FVA
        for i in range(n_reactions):
            # 最小化反应i的通量
            self.fba.c = np.zeros(n_reactions)
            self.fba.c[i] = 1
            min_result = self.fba.solve_fba()

            # 最大化反应i的通量
            self.fba.c[i] = -1
            max_result = self.fba.solve_fba()

            if min_result.success:
                min_fluxes[i] = min_result.x[i]
            else:
                min_fluxes[i] = 0

            if max_result.success:
                max_fluxes[i] = -max_result.x[i]  # 转回正值
            else:
                max_fluxes[i] = 0

            # 恢复原始目标
            self.fba.c = self.original_objective.copy()

        return min_fluxes, max_fluxes

    def identify_essential_reactions(self, min_fluxes, max_fluxes, tolerance=1e-6):
        """识别必需反应"""
        essential_reactions = []
        flexible_reactions = []

        for i, reaction in enumerate(self.fba.reactions):
            if abs(max_fluxes[i] - min_fluxes[i]) < tolerance:
                if abs(max_fluxes[i]) > tolerance:
                    essential_reactions.append(reaction)
            else:
                flexible_reactions.append(reaction)

        return essential_reactions, flexible_reactions

# 使用示例
fva = FluxVariabilityAnalysis(fba)
min_fluxes, max_fluxes = fva.analyze_flux_variability()

essential, flexible = fva.identify_essential_reactions(min_fluxes, max_fluxes)

print("必需反应:")
for reaction in essential:
    print(f"  {reaction}")

print("\n灵活反应:")
for reaction in flexible:
    print(f"  {reaction}")
```

### 9.2.4 基因敲除分析

#### 9.2.4.1 基因-反应关联

**基因-蛋白质-反应（GPR）关系**：
```python
class GeneKnockoutAnalysis:
    def __init__(self, metabolic_network, gpr_mapping):
        self.network = metabolic_network
        self.gpr_mapping = gpr_mapping  # 基因到反应的映射
        self.original_bounds = None

    def build_gpr_mapping(self, gene_reaction_rules):
        """构建GPR映射"""
        gpr = {}
        for reaction, rule in gene_reaction_rules.items():
            genes = self.parse_gpr_rule(rule)
            gpr[reaction] = genes
        return gpr

    def parse_gpr_rule(self, rule):
        """解析GPR规则"""
        # 简单的GPR规则解析（实际应用中更复杂）
        # 例如: "gene1 and gene2" 或 "gene1 or gene2"
        import re

        # 移除空格
        rule = rule.replace(" ", "")

        # 解析AND关系
        if "and" in rule:
            genes = rule.split("and")
            return {'type': 'AND', 'genes': genes}

        # 解析OR关系
        elif "or" in rule:
            genes = rule.split("or")
            return {'type': 'OR', 'genes': genes}

        # 单个基因
        else:
            return {'type': 'SINGLE', 'genes': [rule]}

    def knockout_gene(self, gene_name):
        """敲除特定基因"""
        if self.original_bounds is None:
            self.original_bounds = self.network.bounds.copy()

        affected_reactions = []

        # 找到受该基因影响的反应
        for reaction, gpr in self.gpr_mapping.items():
            if gene_name in gpr['genes']:
                affected_reactions.append(reaction)

        # 根据GPR逻辑决定是否禁用反应
        for reaction in affected_reactions:
            gpr = self.gpr_mapping[reaction]
            if gpr['type'] == 'SINGLE':
                # 单个基因，直接禁用
                self.network.bounds[self.network.reactions.index(reaction)] = (0, 0)
            elif gpr['type'] == 'AND':
                # AND关系，该基因敲除禁用反应
                self.network.bounds[self.network.reactions.index(reaction)] = (0, 0)
            elif gpr['type'] == 'OR':
                # OR关系，需要检查其他基因
                remaining_genes = [g for g in gpr['genes'] if g != gene_name]
                if not remaining_genes:  # 没有其他基因
                    self.network.bounds[self.network.reactions.index(reaction)] = (0, 0)

        return affected_reactions

    def restore_bounds(self):
        """恢复原始边界"""
        if self.original_bounds:
            self.network.bounds = self.original_bounds.copy()
            self.original_bounds = None
```

#### 9.2.4.2 全局基因敲除分析

```python
def comprehensive_gene_knockout_analysis(network, gpr_mapping, essential_threshold=0.01):
    """全面的基因敲除分析"""
    knockout_analyzer = GeneKnockoutAnalysis(network, gpr_mapping)

    # 获取所有基因
    all_genes = set()
    for gpr in gpr_mapping.values():
        all_genes.update(gpr['genes'])

    results = {}

    # 对每个基因进行敲除分析
    for gene in all_genes:
        print(f"分析基因敲除: {gene}")

        # 敲除基因
        affected_reactions = knockout_analyzer.knockout_gene(gene)

        # 运行FBA
        result = network.solve_fba()

        if result.success:
            growth_rate = result.fun * -1
            essential = growth_rate < essential_threshold
        else:
            growth_rate = 0
            essential = True

        results[gene] = {
            'growth_rate': growth_rate,
            'essential': essential,
            'affected_reactions': affected_reactions
        }

        # 恢复原始状态
        knockout_analyzer.restore_bounds()

    return results

# 使用示例

# 构建GPR映射
gene_reaction_rules = {
    'Hexokinase': 'HK1',
    'Phosphoglucose isomerase': 'PGI1',
    'Phosphofructokinase': 'PFK1 and PFK2'
}

gpr_mapping = build_gpr_mapping(gene_reaction_rules)

# 进行基因敲除分析
knockout_results = comprehensive_gene_knockout_analysis(fba, gpr_mapping)

print("基因敲除分析结果:")
for gene, result in knockout_results.items():
    status = "必需" if result['essential'] else "非必需"
    print(f"{gene}: 生长速率={result['growth_rate']:.4f}, {status}")
```

### 9.2.5 并行代谢网络优化

#### 9.2.5.1 并行FBA求解

```python
import multiprocessing as mp
from concurrent.futures import ProcessPoolExecutor
import numpy as np

class ParallelFBASolver:
    def __init__(self, stoichiometry_matrix, metabolites, reactions):
        self.S = stoichiometry_matrix
        self.metabolites = metabolites
        self.reactions = reactions

    def solve_fba_single(self, task):
        """单个FBA求解任务"""
        bounds, objective = task
        n_reactions = len(self.reactions)

        # 设置边界
        full_bounds = []
        for i, reaction in enumerate(self.reactions):
            if i in bounds:
                full_bounds.append(bounds[i])
            else:
                full_bounds.append((-1000, 1000))

        # 求解FBA
        from scipy.optimize import linprog
        result = linprog(
            c=-np.array(objective),
            A_eq=self.S,
            b_eq=np.zeros(len(self.metabolites)),
            bounds=full_bounds,
            method='highs'
        )

        return {
            'success': result.success,
            'optimal_value': result.fun * -1 if result.success else 0,
            'fluxes': result.x if result.success else None
        }

    def parallel_fba_analysis(self, parameter_sets, num_processes=None):
        """并行FBA分析"""
        if num_processes is None:
            num_processes = mp.cpu_count()

        with ProcessPoolExecutor(max_workers=num_processes) as executor:
            results = list(executor.map(self.solve_fba_single, parameter_sets))

        return results

    def parallel_gene_knockout(self, gene_list, wild_type_bounds):
        """并行基因敲除分析"""
        tasks = []

        for gene in gene_list:
            # 创建该基因敲除的边界条件
            knockout_bounds = wild_type_bounds.copy()

            # 这里需要根据GPR关系确定哪些反应被禁用
            # 简化示例：假设每个基因对应一个反应
            reaction_index = hash(gene) % len(self.reactions)
            knockout_bounds[reaction_index] = (0, 0)

            # 设置目标函数（生物量合成）
            objective = np.zeros(len(self.reactions))
            objective[-1] = 1  # 假设最后一个反应是生物量合成

            tasks.append((knockout_bounds, objective))

        return self.parallel_fba_analysis(tasks)

# 使用示例
parallel_solver = ParallelFBASolver(S, metabolites, reactions)

# 并行基因敲除分析
genes_to_test = ['gene1', 'gene2', 'gene3', 'gene4', 'gene5']
wild_type_bounds = [(-1000, 1000)] * len(reactions)

knockout_results = parallel_solver.parallel_gene_knockout(genes_to_test, wild_type_bounds)

print("并行基因敲除结果:")
for i, result in enumerate(knockout_results):
    gene = genes_to_test[i]
    status = "致死" if result['optimal_value'] < 0.01 else "存活"
    print(f"{gene}: 生长速率={result['optimal_value']:.4f}, {status}")
```

#### 9.2.5.2 GPU加速代谢模拟

```cuda
// CUDA加速的代谢网络模拟
#include <cuda_runtime.h>
#include <device_launch_parameters.h>

__global__ void simulate_metabolic_network(
    float* concentrations,
    float* reaction_rates,
    float* stoichiometry,
    int n_metabolites,
    int n_reactions,
    float dt
) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    if (idx < n_metabolites) {
        float d_conc = 0.0f;

        // 计算该代谢物的浓度变化
        for (int j = 0; j < n_reactions; j++) {
            int matrix_idx = idx * n_reactions + j;
            d_conc += stoichiometry[matrix_idx] * reaction_rates[j];
        }

        // 更新浓度
        concentrations[idx] += d_conc * dt;
    }
}

// 主机代码示例
void gpu_metabolic_simulation() {
    // 分配设备内存
    float *d_concentrations, *d_reaction_rates, *d_stoichiometry;

    cudaMalloc(&d_concentrations, n_metabolites * sizeof(float));
    cudaMalloc(&d_reaction_rates, n_reactions * sizeof(float));
    cudaMalloc(&d_stoichiometry, n_metabolites * n_reactions * sizeof(float));

    // 传输数据到设备
    cudaMemcpy(d_concentrations, h_concentrations,
               n_metabolites * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_reaction_rates, h_reaction_rates,
               n_reactions * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_stoichiometry, h_stoichiometry,
               n_metabolites * n_reactions * sizeof(float), cudaMemcpyHostToDevice);

    // 配置kernel执行
    int threads_per_block = 256;
    int num_blocks = (n_metabolites + threads_per_block - 1) / threads_per_block;

    // 时间步进模拟
    for (int step = 0; step < n_steps; step++) {
        simulate_metabolic_network<<<num_blocks, threads_per_block>>>(
            d_concentrations, d_reaction_rates, d_stoichiometry,
            n_metabolites, n_reactions, dt
        );

        // 同步
        cudaDeviceSynchronize();
    }

    // 从设备获取结果
    cudaMemcpy(h_concentrations, d_concentrations,
               n_metabolites * sizeof(float), cudaMemcpyDeviceToHost);

    // 释放设备内存
    cudaFree(d_concentrations);
    cudaFree(d_reaction_rates);
    cudaFree(d_stoichiometry);
}
```

## 9.3 信号通路分析

### 9.3.1 信号通路网络建模

#### 9.3.1.1 信号通路基础

**信号通路（Signaling Pathway）** 是细胞内外信号传递的分子网络，调控细胞的各种生理活动。

**信号通路类型**：
- **受体介导通路**：配体-受体结合启动信号
- **激酶级联通路**：磷酸化级联反应
- **转录调控通路**：影响基因表达
- **代谢调控通路**：调节代谢活动

#### 9.3.1.2 信号通路建模

**布尔网络模型**：
```python
import numpy as np
import networkx as nx

class BooleanSignalingModel:
    def __init__(self, network_structure):
        self.nodes = list(network_structure.keys())
        self.connections = network_structure
        self.state = {node: False for node in self.nodes}

    def update_rule(self, node, current_state):
        """布尔更新规则"""
        if node not in self.connections:
            return current_state[node]

        inputs = self.connections[node]['inputs']
        logic = self.connections[node]['logic']

        if logic == 'AND':
            return all(current_state[input_node] for input_node in inputs)
        elif logic == 'OR':
            return any(current_state[input_node] for input_node in inputs)
        elif logic == 'NOT':
            return not current_state[inputs[0]]
        else:
            return current_state[node]

    def simulate_step(self):
        """模拟一步更新"""
        new_state = {}
        for node in self.nodes:
            new_state[node] = self.update_rule(node, self.state)
        self.state = new_state

    def simulate(self, steps):
        """模拟多步"""
        trajectories = [self.state.copy()]

        for _ in range(steps):
            self.simulate_step()
            trajectories.append(self.state.copy())

        return trajectories

# 示例：简单的MAPK信号通路
mapk_network = {
    'Ligand': {'inputs': [], 'logic': 'INPUT'},
    'Receptor': {'inputs': ['Ligand'], 'logic': 'AND'},
    'Ras': {'inputs': ['Receptor'], 'logic': 'AND'},
    'Raf': {'inputs': ['Ras'], 'logic': 'AND'},
    'MEK': {'inputs': ['Raf'], 'logic': 'AND'},
    'ERK': {'inputs': ['MEK'], 'logic': 'AND'},
    'Transcription': {'inputs': ['ERK'], 'logic': 'AND'}
}

model = BooleanSignalingModel(mapk_network)

# 设置初始条件
model.state['Ligand'] = True

# 模拟信号传递
trajectories = model.simulate(10)

print("信号通路模拟结果:")
for step, state in enumerate(trajectories):
    active_nodes = [node for node, active in state.items() if active]
    print(f"Step {step}: {active_nodes}")
```

**微分方程模型**：
```python
import numpy as np
from scipy.integrate import odeint
import matplotlib.pyplot as plt

class ODESignalingModel:
    def __init__(self, parameters):
        self.params = parameters

    def signaling_odes(self, y, t):
        """信号通路微分方程"""
        # y = [Receptor, Ras, Raf, MEK, ERK]
        R, Ras, Raf, MEK, ERK = y

        # 参数
        k1, k2, k3, k4, k5 = self.params['activation_rates']
        d1, d2, d3, d4, d5 = self.params['degradation_rates']

        # 微分方程
        dR_dt = -k1 * R + d1
        dRas_dt = k1 * R - k2 * Ras - d2 * Ras
        dRaf_dt = k2 * Ras - k3 * Raf - d3 * Raf
        dMEK_dt = k3 * Raf - k4 * MEK - d4 * MEK
        dERK_dt = k4 * MEK - k5 * ERK - d5 * ERK

        return [dR_dt, dRas_dt, dRaf_dt, dMEK_dt, dERK_dt]

    def simulate(self, initial_conditions, time_points):
        """模拟信号通路动态"""
        return odeint(self.signaling_odes, initial_conditions, time_points)

# 使用示例
parameters = {
    'activation_rates': [0.1, 0.2, 0.3, 0.4, 0.5],
    'degradation_rates': [0.05, 0.05, 0.05, 0.05, 0.05]
}

model = ODESignalingModel(parameters)

# 初始条件：受体被激活
initial_conditions = [1.0, 0.0, 0.0, 0.0, 0.0]

# 时间点
time_points = np.linspace(0, 50, 500)

# 模拟
solution = model.simulate(initial_conditions, time_points)

# 绘图
plt.figure(figsize=(10, 6))
species = ['Receptor', 'Ras', 'Raf', 'MEK', 'ERK']
for i, species_name in enumerate(species):
    plt.plot(time_points, solution[:, i], label=species_name, linewidth=2)

plt.xlabel('Time')
plt.ylabel('Concentration')
plt.title('MAPK Signaling Pathway Dynamics')
plt.legend()
plt.grid(True)
plt.show()
```

### 9.3.2 动力学模拟

#### 9.3.2.1 确定性模拟

**Runge-Kutta方法**：
```python
def runge_kutta_4(f, y0, t, args=()):
    """四阶Runge-Kutta方法"""
    n = len(t)
    y = np.zeros((n, len(y0)))
    y[0] = y0

    for i in range(n - 1):
        h = t[i+1] - t[i]
        k1 = h * f(y[i], t[i], *args)
        k2 = h * f(y[i] + 0.5 * k1, t[i] + 0.5 * h, *args)
        k3 = h * f(y[i] + 0.5 * k2, t[i] + 0.5 * h, *args)
        k4 = h * f(y[i] + k3, t[i] + h, *args)

        y[i+1] = y[i] + (k1 + 2*k2 + 2*k3 + k4) / 6

    return y

# 使用示例：模拟钙振荡
def calcium_oscillation_model(y, t, IP3, V1, V2, k3, k4):
    """钙振荡模型"""
    Ca_cyt, Ca_er = y

    # 参数
    k1 = 0.1
    k2 = 1.0
    V5 = 0.1

    # IP3受体动力学
    R = 1 / (1 + (Ca_cyt / k3)**2)
    S = 1 / (1 + IP3 / k4)

    # 微分方程
    dCa_cyt_dt = V1 * R * S * Ca_er - V2 * Ca_cyt - k2 * Ca_cyt + V5
    dCa_er_dt = -V1 * R * S * Ca_er + k2 * Ca_cyt

    return np.array([dCa_cyt_dt, dCa_er_dt])

# 参数设置
IP3 = 1.0
V1, V2, k3, k4 = 1.0, 0.1, 0.5, 0.5
parameters = (IP3, V1, V2, k3, k4)

# 初始条件
y0 = [0.1, 1.0]

# 时间点
t = np.linspace(0, 100, 1000)

# 模拟
solution = runge_kutta_4(calcium_oscillation_model, y0, t, parameters)

# 绘图
plt.figure(figsize=(12, 6))

plt.subplot(2, 1, 1)
plt.plot(t, solution[:, 0], 'b-', linewidth=2, label='Cytosolic Ca²⁺')
plt.plot(t, solution[:, 1], 'r-', linewidth=2, label='ER Ca²⁺')
plt.xlabel('Time')
plt.ylabel('Concentration')
plt.title('Calcium Oscillation Simulation')
plt.legend()
plt.grid(True)

plt.subplot(2, 1, 2)
plt.plot(solution[:, 0], solution[:, 1], 'g-', linewidth=2)
plt.xlabel('Cytosolic Ca²⁺')
plt.ylabel('ER Ca²⁺')
plt.title('Phase Plane')
plt.grid(True)

plt.tight_layout()
plt.show()
```

#### 9.3.2.2 随机模拟

**Gillespie算法**：
```python
import numpy as np

class GillespieSimulator:
    def __init__(self, reactions, species):
        self.reactions = reactions  # 反应列表
        self.species = species      # 物种列表

    def calculate_propensities(self, state):
        """计算反应倾向性"""
        propensities = []

        for reaction in self.reactions:
            propensity = reaction['rate']

            # 计算底物浓度的乘积
            for substrate, stoich in reaction['substrates'].items():
                if stoich > 0:
                    propensity *= state[substrate] ** stoich

            propensities.append(propensity)

        return np.array(propensities)

    def select_reaction(self, propensities):
        """选择下一个反应"""
        total_propensity = np.sum(propensities)

        if total_propensity == 0:
            return None, 0

        # 选择反应
        r1 = np.random.random()
        cumulative = 0
        selected_reaction = None

        for i, propensity in enumerate(propensities):
            cumulative += propensity
            if r1 * total_propensity < cumulative:
                selected_reaction = i
                break

        # 计算时间步长
        r2 = np.random.random()
        time_step = (1 / total_propensity) * np.log(1 / r2)

        return selected_reaction, time_step

    def update_state(self, state, reaction_index):
        """更新状态"""
        reaction = self.reactions[reaction_index]

        # 更新底物
        for substrate, stoich in reaction['substrates'].items():
            state[substrate] -= stoich

        # 更新产物
        for product, stoich in reaction['products'].items():
            state[product] += stoich

        return state

    def simulate(self, initial_state, max_time):
        """Gillespie模拟"""
        state = initial_state.copy()
        time = 0
        trajectory = [(time, state.copy())]

        while time < max_time:
            # 计算倾向性
            propensities = self.calculate_propensities(state)

            # 选择反应
            reaction_index, time_step = self.select_reaction(propensities)

            if reaction_index is None:
                break

            # 更新时间和状态
            time += time_step
            state = self.update_state(state, reaction_index)

            trajectory.append((time, state.copy()))

        return trajectory

# 使用示例：简单的基因表达模型
reactions = [
    {
        'name': 'Transcription',
        'rate': 0.5,
        'substrates': {'DNA': 1},
        'products': {'DNA': 1, 'mRNA': 1}
    },
    {
        'name': 'mRNA degradation',
        'rate': 0.1,
        'substrates': {'mRNA': 1},
        'products': {}
    },
    {
        'name': 'Translation',
        'rate': 1.0,
        'substrates': {'mRNA': 1},
        'products': {'mRNA': 1, 'Protein': 1}
    },
    {
        'name': 'Protein degradation',
        'rate': 0.05,
        'substrates': {'Protein': 1},
        'products': {}
    }
]

species = ['DNA', 'mRNA', 'Protein']
initial_state = {'DNA': 1, 'mRNA': 0, 'Protein': 0}

simulator = GillespieSimulator(reactions, species)
trajectory = simulator.simulate(initial_state, 100)

# 绘图
times = [t for t, _ in trajectory]
mRNA_levels = [state['mRNA'] for _, state in trajectory]
protein_levels = [state['Protein'] for _, state in trajectory]

plt.figure(figsize=(10, 6))
plt.step(times, mRNA_levels, 'b-', where='post', label='mRNA', linewidth=2)
plt.step(times, protein_levels, 'r-', where='post', label='Protein', linewidth=2)
plt.xlabel('Time')
plt.ylabel('Molecule Count')
plt.title('Stochastic Gene Expression Simulation')
plt.legend()
plt.grid(True)
plt.show()
```

### 9.3.3 通路富集分析

#### 9.3.3.1 富集分析原理

**通路富集分析（Pathway Enrichment Analysis）** 用于识别在特定条件下显著富集的生物通路。

**统计方法**：
- **超几何检验**：检验基因集在通路中的富集程度
- **Fisher精确检验**：小样本情况下的精确检验
- **GSEA**：基因集富集分析

#### 9.3.3.2 富集分析实现

```python
import numpy as np
from scipy import stats
from collections import Counter

class PathwayEnrichmentAnalysis:
    def __init__(self, pathway_database):
        self.pathway_db = pathway_database  # 通路数据库

    def hypergeometric_test(self, gene_list, pathway_genes, background_genes):
        """超几何检验"""
        N = len(background_genes)      # 总基因数
        K = len(pathway_genes)         # 通路中基因数
        n = len(gene_list)             # 差异基因数
        k = len(set(gene_list) & set(pathway_genes))  # 重叠基因数

        if k == 0:
            return 1.0, 0.0

        # 超几何分布概率
        p_value = stats.hypergeom.sf(k-1, N, K, n)

        # 富集因子
        enrichment_factor = (k / n) / (K / N)

        return p_value, enrichment_factor

    def perform_enrichment(self, differential_genes, background_genes=None):
        """执行富集分析"""
        if background_genes is None:
            background_genes = list(set(differential_genes))

        results = []

        for pathway_name, pathway_genes in self.pathway_db.items():
            # 过滤不在背景中的基因
            pathway_genes = [g for g in pathway_genes if g in background_genes]

            if len(pathway_genes) < 3:  # 通路太小，跳过
                continue

            # 计算富集
            p_value, enrichment_factor = self.hypergeometric_test(
                differential_genes, pathway_genes, background_genes
            )

            # 多重检验校正（Benjamini-Hochberg）
            results.append({
                'pathway': pathway_name,
                'p_value': p_value,
                'adjusted_p_value': None,  # 稍后校正
                'enrichment_factor': enrichment_factor,
                'overlap_genes': len(set(differential_genes) & set(pathway_genes)),
                'pathway_size': len(pathway_genes),
                'gene_list_size': len(differential_genes)
            })

        # FDR校正
        results = self.adjust_p_values(results)

        return sorted(results, key=lambda x: x['adjusted_p_value'])

    def adjust_p_values(self, results):
        """Benjamini-Hochberg FDR校正"""
        p_values = [r['p_value'] for r in results]
        sorted_indices = np.argsort(p_values)
        n = len(p_values)

        # BH校正
        for i, idx in enumerate(sorted_indices):
            raw_p = p_values[idx]
            adjusted_p = raw_p * n / (i + 1)
            results[idx]['adjusted_p_value'] = min(adjusted_p, 1.0)

        return results

    def visualize_enrichment(self, results, top_n=10):
        """可视化富集结果"""
        import matplotlib.pyplot as plt

        top_results = results[:top_n]
        pathways = [r['pathway'] for r in top_results]
        p_values = [-np.log10(r['adjusted_p_value']) for r in top_results]
        enrichment_factors = [r['enrichment_factor'] for r in top_results]

        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

        # 富集显著性
        ax1.barh(range(len(pathways)), p_values)
        ax1.set_yticks(range(len(pathways)))
        ax1.set_yticklabels(pathways)
        ax1.set_xlabel('-log10(Adjusted P-value)')
        ax1.set_title('Pathway Enrichment Significance')
        ax1.invert_yaxis()

        # 富集因子
        ax2.scatter(enrichment_factors, p_values, s=100, alpha=0.7)
        ax2.set_xlabel('Enrichment Factor')
        ax2.set_ylabel('-log10(Adjusted P-value)')
        ax2.set_title('Enrichment Factor vs Significance')

        plt.tight_layout()
        plt.show()

# 使用示例
pathway_database = {
    'MAPK signaling': ['MAPK1', 'MAPK3', 'RAF1', 'MEK1'],
    'PI3K-Akt signaling': ['AKT1', 'PIK3CA', 'MTOR', 'PDK1'],
    'Wnt signaling': ['CTNNB1', 'APC', 'AXIN1', 'GSK3B'],
    'Cell cycle': ['CDK1', 'CCNB1', 'CDC25C', 'PLK1']
}

enrichment_analyzer = PathwayEnrichmentAnalysis(pathway_database)

# 模拟差异表达基因
differential_genes = ['MAPK1', 'MAPK3', 'AKT1', 'PIK3CA', 'CDK1', 'CCNB1', 'CTNNB1']

# 执行富集分析
results = enrichment_analyzer.perform_enrichment(differential_genes)

# 显示结果
print("通路富集分析结果:")
for result in results:
    print(f"{result['pathway']}: "
          f"P={result['adjusted_p_value']:.4f}, "
          f"Enrichment={result['enrichment_factor']:.2f}, "
          f"Overlap={result['overlap_genes']}")

# 可视化
enrichment_analyzer.visualize_enrichment(results)
```

### 9.3.4 网络拓扑分析

#### 9.3.4.1 网络中心性分析

```python
import networkx as nx
import numpy as np

class NetworkTopologyAnalyzer:
    def __init__(self, interaction_network):
        self.graph = self.build_network(interaction_network)

    def build_network(self, interactions):
        """构建网络图"""
        G = nx.DiGraph()

        for protein1, protein2, interaction_type in interactions:
            G.add_edge(protein1, protein2, type=interaction_type)

        return G

    def calculate_centralities(self):
        """计算各种中心性指标"""
        centralities = {}

        # 度中心性
        centralities['degree'] = nx.degree_centrality(self.graph)

        # 介数中心性
        centralities['betweenness'] = nx.betweenness_centrality(self.graph)

        # 接近中心性
        try:
            centralities['closeness'] = nx.closeness_centrality(self.graph)
        except nx.NetworkXError:
            centralities['closeness'] = {}

        # 特征向量中心性
        try:
            centralities['eigenvector'] = nx.eigenvector_centrality(self.graph)
        except nx.NetworkXError:
            centralities['eigenvector'] = {}

        return centralities

    def identify_essential_proteins(self, centralities, threshold=0.8):
        """识别重要蛋白"""
        essential_proteins = {}

        for metric, scores in centralities.items():
            # 标准化分数
            if scores:
                values = list(scores.values())
                mean_val = np.mean(values)
                std_val = np.std(values)

                # Z-score > threshold的蛋白被认为是重要的
                essential = {protein: score for protein, score in scores.items()
                           if (score - mean_val) / std_val > threshold}

                essential_proteins[metric] = essential

        return essential_proteins

    def analyze_network_modules(self):
        """分析网络模块"""
        # 社区检测
        communities = nx.community.greedy_modularity_communities(self.graph)

        # 模块内连接密度
        module_properties = {}
        for i, community in enumerate(communities):
            subgraph = self.graph.subgraph(community)

            # 模块大小
            module_size = len(community)

            # 模块内连接密度
            internal_edges = subgraph.number_of_edges()
            max_possible_edges = module_size * (module_size - 1) / 2
            density = internal_edges / max_possible_edges if max_possible_edges > 0 else 0

            # 模块间连接
            external_edges = 0
            for node in community:
                external_edges += len([n for n in self.graph.neighbors(node) if n not in community])

            module_properties[f'Module_{i}'] = {
                'size': module_size,
                'density': density,
                'external_connections': external_edges,
                'proteins': list(community)
            }

        return module_properties

    def visualize_network_topology(self):
        """可视化网络拓扑"""
        import matplotlib.pyplot as plt

        plt.figure(figsize=(12, 8))

        # 布局
        pos = nx.spring_layout(self.graph, k=2, iterations=50)

        # 绘制节点
        centralities = self.calculate_centralities()
        node_sizes = [v * 1000 for v in centralities['degree'].values()]

        nx.draw_networkx_nodes(self.graph, pos, node_size=node_sizes,
                             node_color='lightblue', alpha=0.8)

        # 绘制边
        nx.draw_networkx_edges(self.graph, pos, alpha=0.5, arrows=True)

        # 标签
        nx.draw_networkx_labels(self.graph, pos, font_size=8, font_family='sans-serif')

        plt.title('Signaling Network Topology')
        plt.axis('off')
        plt.show()

# 使用示例

# 模拟信号通路相互作用数据
interactions = [
    ('EGFR', 'GRB2', 'phosphorylation'),
    ('GRB2', 'SOS1', 'binding'),
    ('SOS1', 'RAS', 'activation'),
    ('RAS', 'RAF1', 'activation'),
    ('RAF1', 'MEK1', 'phosphorylation'),
    ('MEK1', 'ERK1', 'phosphorylation'),
    ('ERK1', 'ELK1', 'phosphorylation'),
    ('PI3K', 'AKT1', 'activation'),
    ('AKT1', 'MTOR', 'phosphorylation'),
    ('MTOR', 'S6K1', 'phosphorylation')
]

analyzer = NetworkTopologyAnalyzer(interactions)

# 计算中心性
centralities = analyzer.calculate_centralities()

print("网络中心性分析:")
for metric, scores in centralities.items():
    print(f"\n{metric} centrality:")
    sorted_scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)
    for protein, score in sorted_scores[:5]:
        print(f"  {protein}: {score:.4f}")

# 识别重要蛋白
essential = analyzer.identify_essential_proteins(centralities)
print(f"\n重要蛋白 ({len(essential)} 指标):")
for metric, proteins in essential.items():
    print(f"{metric}: {list(proteins.keys())}")

# 分析网络模块
modules = analyzer.analyze_network_modules()
print(f"\n网络模块分析:")
for module, props in modules.items():
    print(f"{module}: 大小={props['size']}, 密度={props['density']:.3f}")

# 可视化
analyzer.visualize_network_topology()
```

## 9.4 多组学数据整合

### 9.4.1 组学数据类型

#### 9.4.1.1 基因组学数据

**基因组数据特征**：
- **SNP数据**：单核苷酸多态性
- **CNV数据**：拷贝数变异
- **结构变异**：插入、缺失、倒位、易位

```python
import pandas as pd
import numpy as np

class GenomicsData:
    def __init__(self, snp_file, cnv_file):
        self.snps = self.load_snp_data(snp_file)
        self.cnvs = self.load_cnv_data(cnv_file)

    def load_snp_data(self, file_path):
        """加载SNP数据"""
        return pd.read_csv(file_path, sep='\t')

    def load_cnv_data(self, file_path):
        """加载CNV数据"""
        return pd.read_csv(file_path, sep='\t')

    def annotate_variants(self, annotation_file):
        """变异注释"""
        annotations = pd.read_csv(annotation_file)
        return pd.merge(self.snps, annotations, on='variant_id')

    def calculate_genetic_risk_scores(self, risk_variants):
        """计算遗传风险评分"""
        risk_scores = {}
        for sample in self.snps['sample_id'].unique():
            sample_data = self.snps[self.snps['sample_id'] == sample]

            score = 0
            for _, variant in sample_data.iterrows():
                if variant['variant_id'] in risk_variants:
                    # 假设每个风险等位基因贡献1分
                    score += variant['dosage']

            risk_scores[sample] = score

        return risk_scores
```

#### 9.4.1.2 转录组学数据

**RNA-seq数据分析**：
```python
import pandas as pd
import numpy as np
from scipy.stats import ttest_ind

class TranscriptomicsData:
    def __init__(self, count_matrix_file, sample_info_file):
        self.counts = pd.read_csv(count_matrix_file, index_col=0)
        self.sample_info = pd.read_csv(sample_info_file)

    def normalize_counts(self, method='TPM'):
        """表达量标准化"""
        if method == 'TPM':
            # TPM标准化
            gene_lengths = self.counts.iloc[:, -1]  # 假设最后一列是基因长度
            read_counts = self.counts.iloc[:, :-1]

            # RPK (Reads Per Kilobase)
            rpkm = read_counts.div(gene_lengths, axis=0) / 1000

            # TPM (Transcripts Per Million)
            scaling_factors = rpkm.sum(axis=0) / 1e6
            tpm = rpkm.div(scaling_factors, axis=1)

            return tpm

        elif method == 'FPKM':
            # FPKM标准化
            pass

    def differential_expression(self, condition_col, case_group, control_group):
        """差异表达分析"""
        # 获取样本分组
        case_samples = self.sample_info[
            self.sample_info[condition_col] == case_group
        ]['sample_id'].tolist()

        control_samples = self.sample_info[
            self.sample_info[condition_col] == control_group
        ]['sample_id'].tolist()

        results = []

        for gene in self.counts.index:
            case_expr = self.counts.loc[gene, case_samples]
            control_expr = self.counts.loc[gene, control_samples]

            # t检验
            t_stat, p_val = ttest_ind(case_expr, control_expr)

            # 计算log2 fold change
            mean_case = np.mean(case_expr)
            mean_control = np.mean(control_expr)
            log2_fc = np.log2((mean_case + 1) / (mean_control + 1))

            results.append({
                'gene': gene,
                'log2_fold_change': log2_fc,
                'p_value': p_val,
                'significant': p_val < 0.05
            })

        return pd.DataFrame(results)

    def coexpression_network(self, correlation_method='pearson'):
        """共表达网络构建"""
        expr_matrix = self.counts.T  # 样本×基因矩阵

        # 计算相关性
        correlation_matrix = expr_matrix.corr(method=correlation_method)

        # 构建网络
        edges = []
        threshold = 0.8  # 相关性阈值

        genes = correlation_matrix.columns
        for i in range(len(genes)):
            for j in range(i+1, len(genes)):
                corr = correlation_matrix.iloc[i, j]
                if abs(corr) > threshold:
                    edges.append((genes[i], genes[j], abs(corr)))

        return edges
```

#### 9.4.1.3 蛋白质组学数据

**质谱数据分析**：
```python
import pandas as pd
import numpy as np
from scipy.stats import ttest_ind

class ProteomicsData:
    def __init__(self, protein_abundance_file, peptide_file):
        self.protein_data = pd.read_csv(protein_abundance_file)
        self.peptide_data = pd.read_csv(peptide_file)

    def normalize_protein_abundance(self, method='quantile'):
        """蛋白质丰度标准化"""
        if method == 'quantile':
            # 分位数标准化
            from sklearn.preprocessing import QuantileTransformer

            transformer = QuantileTransformer(output_distribution='normal')
            normalized_data = transformer.fit_transform(self.protein_data.iloc[:, 2:])

            result = self.protein_data.copy()
            result.iloc[:, 2:] = normalized_data

            return result

    def protein_identification_confidence(self):
        """蛋白质鉴定置信度评估"""
        # 基于肽段数量和质量分数
        self.protein_data['confidence_score'] = (
            self.protein_data['peptide_count'] *
            self.protein_data['mean_peptide_score']
        )

        return self.protein_data

    def differential_protein_expression(self, condition_col, case_group, control_group):
        """差异蛋白表达分析"""
        # 类似转录组学的差异分析
        pass

    def protein_protein_interactions(self, interaction_database):
        """蛋白质相互作用网络"""
        # 基于已知的PPI数据库
        pass
```

#### 9.4.1.4 代谢组学数据

**代谢物检测数据**：
```python
import pandas as pd
import numpy as np
from scipy import stats

class MetabolomicsData:
    def __init__(self, metabolite_data_file, metadata_file):
        self.metabolites = pd.read_csv(metabolite_data_file, index_col=0)
        self.metadata = pd.read_csv(metadata_file)

    def metabolite_annotation(self, database_file):
        """代谢物注释"""
        database = pd.read_csv(database_file)
        annotated = pd.merge(self.metabolites, database,
                           left_index=True, right_on='metabolite_id')
        return annotated

    def metabolic_pathway_analysis(self, pathway_database):
        """代谢通路分析"""
        # 将代谢物映射到通路
        pathway_mapping = {}
        for pathway, metabolites in pathway_database.items():
            mapped_metabolites = [m for m in metabolites
                                if m in self.metabolites.index]
            if mapped_metabolites:
                pathway_mapping[pathway] = mapped_metabolites

        return pathway_mapping

    def metabolic_signature_discovery(self, condition_col, case_group, control_group):
        """代谢特征发现"""
        # 寻找差异代谢物
        case_samples = self.metadata[
            self.metadata[condition_col] == case_group
        ]['sample_id'].tolist()

        control_samples = self.metadata[
            self.metadata[condition_col] == control_group
        ]['sample_id'].tolist()

        results = []

        for metabolite in self.metabolites.index:
            case_vals = self.metabolites.loc[metabolite, case_samples]
            control_vals = self.metabolites.loc[metabolite, control_samples]

            # 统计检验
            statistic, p_value = stats.mannwhitneyu(case_vals, control_vals)

            # 效应大小
            effect_size = abs(case_vals.mean() - control_vals.mean()) / case_vals.std()

            results.append({
                'metabolite': metabolite,
                'p_value': p_value,
                'effect_size': effect_size,
                'significant': p_value < 0.05
            })

        return pd.DataFrame(results)
```

### 9.4.2 数据标准化

#### 9.4.2.1 多组学数据整合标准化

```python
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.decomposition import PCA

class MultiOmicsIntegration:
    def __init__(self, genomics_data, transcriptomics_data,
                 proteomics_data, metabolomics_data):
        self.genomics = genomics_data
        self.transcriptomics = transcriptomics_data
        self.proteomics = proteomics_data
        self.metabolomics = metabolomics_data

    def normalize_all_data(self):
        """统一标准化所有组学数据"""
        normalized_data = {}

        # 基因组数据标准化
        if hasattr(self.genomics, 'snps'):
            # SNP数据：等位基因频率标准化
            snp_matrix = self.genomics.snps.pivot(
                index='sample_id', columns='variant_id', values='genotype'
            )
            normalized_data['genomics'] = self.normalize_snp_data(snp_matrix)

        # 转录组数据标准化
        if hasattr(self.transcriptomics, 'counts'):
            normalized_data['transcriptomics'] = self.transcriptomics.normalize_counts()

        # 蛋白质组数据标准化
        if hasattr(self.proteomics, 'protein_data'):
            normalized_data['proteomics'] = self.proteomics.normalize_protein_abundance()

        # 代谢组数据标准化
        if hasattr(self.metabolomics, 'metabolites'):
            normalized_data['metabolomics'] = self.normalize_metabolomics_data()

        return normalized_data

    def normalize_snp_data(self, snp_matrix):
        """SNP数据标准化"""
        # 等位基因剂量标准化
        scaler = StandardScaler()
        normalized = scaler.fit_transform(snp_matrix.fillna(0))

        return pd.DataFrame(normalized, index=snp_matrix.index,
                          columns=snp_matrix.columns)

    def normalize_metabolomics_data(self):
        """代谢组数据标准化"""
        # 内标物标准化 + Pareto缩放
        metabolite_data = self.metabolomics.metabolites.copy()

        # 移除零值和常数列
        metabolite_data = metabolite_data.loc[:, (metabolite_data != 0).any(axis=0)]
        metabolite_data = metabolite_data.loc[:, metabolite_data.std() > 0]

        # Pareto缩放
        scaler = StandardScaler()
        scaled_data = scaler.fit_transform(metabolite_data)

        # 转换为DataFrame
        return pd.DataFrame(scaled_data, index=metabolite_data.index,
                          columns=metabolite_data.columns)

    def batch_effect_correction(self, data_dict, batch_column='batch'):
        """批次效应校正"""
        corrected_data = {}

        for omics_type, data in data_dict.items():
            if batch_column in self.metadata.columns:
                # 使用ComBat进行批次效应校正
                corrected_data[omics_type] = self.combat_correction(data)
            else:
                corrected_data[omics_type] = data

        return corrected_data

    def combat_correction(self, data_matrix):
        """ComBat批次效应校正"""
        # 简化版本的ComBat实现
        # 实际应用中建议使用sva包
        pass

    def integrate_multi_omics(self, normalized_data):
        """多组学数据整合"""
        # 方法1: 简单拼接
        integrated_data = pd.concat(normalized_data.values(), axis=1)

        # 方法2: 基于生物学关系的整合
        # 这里需要先验知识来定义组学间的映射关系

        return integrated_data

    def dimensionality_reduction(self, integrated_data, method='PCA', n_components=10):
        """降维分析"""
        if method == 'PCA':
            pca = PCA(n_components=n_components)
            reduced_data = pca.fit_transform(integrated_data)

            return {
                'components': reduced_data,
                'explained_variance': pca.explained_variance_ratio_,
                'loadings': pca.components_
            }

        elif method == 't-SNE':
            from sklearn.manifold import TSNE
            tsne = TSNE(n_components=2, perplexity=30, n_iter=1000)
            reduced_data = tsne.fit_transform(integrated_data)
            return reduced_data
```

### 9.4.3 特征选择

#### 9.4.3.1 多组学特征选择

```python
import numpy as np
import pandas as pd
from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import Lasso
import networkx as nx

class MultiOmicsFeatureSelection:
    def __init__(self, integrated_data, labels):
        self.data = integrated_data
        self.labels = labels

    def univariate_selection(self, k=1000, method='f_score'):
        """单变量特征选择"""
        if method == 'f_score':
            selector = SelectKBest(score_func=f_classif, k=k)
        elif method == 'mutual_info':
            selector = SelectKBest(score_func=mutual_info_classif, k=k)

        selected_data = selector.fit_transform(self.data, self.labels)
        selected_features = self.data.columns[selector.get_support()]

        return selected_data, selected_features

    def lasso_selection(self, alpha=0.1):
        """Lasso特征选择"""
        lasso = Lasso(alpha=alpha, max_iter=2000)
        lasso.fit(self.data, self.labels)

        # 选择非零系数的特征
        selected_indices = np.where(lasso.coef_ != 0)[0]
        selected_features = self.data.columns[selected_indices]
        selected_data = self.data.iloc[:, selected_indices]

        return selected_data, selected_features

    def random_forest_selection(self, n_estimators=100, importance_threshold=0.01):
        """随机森林特征选择"""
        rf = RandomForestClassifier(n_estimators=n_estimators)
        rf.fit(self.data, self.labels)

        # 基于特征重要性选择
        importances = rf.feature_importances_
        selected_indices = np.where(importances > importance_threshold)[0]
        selected_features = self.data.columns[selected_indices]
        selected_data = self.data.iloc[:, selected_indices]

        return selected_data, selected_features

    def network_based_selection(self, interaction_network, alpha=0.5):
        """基于网络的特征选择"""
        # 结合网络拓扑和统计显著性
        # 构建特征-特征相互作用网络

        # 计算统计显著性
        p_values = self.calculate_p_values()

        # 计算网络中心性
        centralities = self.calculate_network_centralities(interaction_network)

        # 综合评分
        combined_scores = {}
        for feature in self.data.columns:
            if feature in p_values and feature in centralities:
                stat_score = -np.log10(p_values[feature])
                net_score = centralities[feature]
                combined_scores[feature] = alpha * stat_score + (1 - alpha) * net_score

        # 选择高分特征
        sorted_features = sorted(combined_scores.items(),
                               key=lambda x: x[1], reverse=True)

        return [f[0] for f in sorted_features]

    def calculate_p_values(self):
        """计算特征的统计显著性"""
        p_values = {}
        for column in self.data.columns:
            from scipy.stats import ttest_ind

            # 假设标签是二分类的
            class0_data = self.data[self.labels == 0][column]
            class1_data = self.data[self.labels == 1][column]

            _, p_val = ttest_ind(class0_data, class1_data)
            p_values[column] = p_val

        return p_values

    def calculate_network_centralities(self, interaction_network):
        """计算网络中心性"""
        G = nx.Graph()
        G.add_edges_from(interaction_network)

        # 计算度中心性
        centralities = nx.degree_centrality(G)

        return centralities

    def ensemble_feature_selection(self, methods=['univariate', 'lasso', 'random_forest']):
        """集成特征选择"""
        selected_features = {}

        for method in methods:
            if method == 'univariate':
                _, features = self.univariate_selection(k=500)
            elif method == 'lasso':
                _, features = self.lasso_selection()
            elif method == 'random_forest':
                _, features = self.random_forest_selection()

            selected_features[method] = set(features)

        # 找出在多个方法中都被选中的特征
        common_features = set.intersection(*selected_features.values())

        return list(common_features)
```

### 9.4.4 网络重建

#### 9.4.4.1 基因调控网络重建

```python
import numpy as np
import pandas as pd
from sklearn.linear_model import Lasso
from sklearn.covariance import GraphicalLasso
import networkx as nx

class GeneRegulatoryNetwork:
    def __init__(self, expression_data, tf_targets_file=None):
        self.expression_data = expression_data  # 样本×基因矩阵
        self.tf_targets = self.load_tf_targets(tf_targets_file)

    def load_tf_targets(self, file_path):
        """加载转录因子-靶基因关系"""
        if file_path:
            return pd.read_csv(file_path)
        return None

    def infer_network_lasso(self, alpha=0.1):
        """使用Lasso推断网络"""
        n_genes = self.expression_data.shape[1]
        network = np.zeros((n_genes, n_genes))

        genes = self.expression_data.columns

        for i, target_gene in enumerate(genes):
            print(f"Infering regulators for {target_gene}...")

            # 目标基因表达
            y = self.expression_data[target_gene].values

            # 预测因子（其他基因）
            X = self.expression_data.drop(columns=[target_gene]).values

            # Lasso回归
            lasso = Lasso(alpha=alpha, max_iter=1000)
            lasso.fit(X, y)

            # 记录非零系数
            network[i, :-1] = lasso.coef_[:i]  # 前半部分
            network[i, i+1:] = lasso.coef_[i:]  # 后半部分

        return network, genes

    def infer_network_glasso(self, alpha=0.01):
        """使用图Lasso推断网络"""
        glasso = GraphicalLasso(alpha=alpha, mode='cd')
        glasso.fit(self.expression_data)

        # 精确矩阵（负相关矩阵）
        precision_matrix = glasso.precision_

        return precision_matrix

    def incorporate_prior_knowledge(self, network_matrix, genes):
        """整合先验知识"""
        if self.tf_targets is None:
            return network_matrix

        prior_network = np.zeros_like(network_matrix)

        for _, row in self.tf_targets.iterrows():
            tf = row['TF']
            target = row['Target']
            confidence = row.get('Confidence', 1.0)

            if tf in genes and target in genes:
                tf_idx = list(genes).index(tf)
                target_idx = list(genes).index(target)
                prior_network[target_idx, tf_idx] = confidence

        # 结合先验知识和数据驱动的结果
        combined_network = network_matrix * 0.7 + prior_network * 0.3

        return combined_network

    def validate_network(self, known_interactions, threshold=0.1):
        """网络验证"""
        predicted_interactions = []

        for i in range(len(self.expression_data.columns)):
            for j in range(len(self.expression_data.columns)):
                if abs(self.network[i, j]) > threshold:
                    predicted_interactions.append(
                        (self.expression_data.columns[j],
                         self.expression_data.columns[i])
                    )

        # 计算精确率和召回率
        true_positives = len(set(predicted_interactions) & set(known_interactions))
        precision = true_positives / len(predicted_interactions) if predicted_interactions else 0
        recall = true_positives / len(known_interactions) if known_interactions else 0

        return precision, recall

    def visualize_network(self, threshold=0.1):
        """可视化调控网络"""
        import matplotlib.pyplot as plt

        G = nx.DiGraph()

        # 添加节点
        for gene in self.expression_data.columns:
            G.add_node(gene)

        # 添加边
        genes = self.expression_data.columns
        for i in range(len(genes)):
            for j in range(len(genes)):
                if abs(self.network[i, j]) > threshold:
                    weight = abs(self.network[i, j])
                    G.add_edge(genes[j], genes[i], weight=weight)

        # 绘图
        plt.figure(figsize=(12, 8))
        pos = nx.spring_layout(G, k=2, iterations=50)

        # 绘制边
        edges = G.edges()
        weights = [G[u][v]['weight'] for u, v in edges]
        nx.draw_networkx_edges(G, pos, alpha=0.6, width=weights,
                             edge_color='blue', arrows=True)

        # 绘制节点
        nx.draw_networkx_nodes(G, pos, node_color='lightblue', node_size=500)

        # 标签
        nx.draw_networkx_labels(G, pos, font_size=8)

        plt.title('Gene Regulatory Network')
        plt.axis('off')
        plt.show()

# 使用示例

# 假设有表达数据
expression_data = pd.DataFrame(np.random.randn(100, 50),
                             columns=[f'Gene_{i}' for i in range(50)])

# 构建调控网络
grn = GeneRegulatoryNetwork(expression_data)

# 推断网络
network_matrix, genes = grn.infer_network_lasso(alpha=0.1)

# 整合先验知识
combined_network = grn.incorporate_prior_knowledge(network_matrix, genes)

# 存储结果
grn.network = combined_network
grn.genes = genes

# 可视化
grn.visualize_network(threshold=0.2)
```

### 9.4.5 系统级分析

#### 9.4.5.1 多尺度建模

```python
import numpy as np
import pandas as pd
from scipy.integrate import odeint

class MultiScaleBiologicalModel:
    def __init__(self, genomic_data, regulatory_network, metabolic_network):
        self.genomic_data = genomic_data
        self.regulatory_network = regulatory_network
        self.metabolic_network = metabolic_network

    def integrate_multi_scale_data(self):
        """整合多尺度数据"""
        # 1. 基因组水平：遗传变异影响
        genetic_effects = self.model_genetic_effects()

        # 2. 转录组水平：基因表达调控
        expression_dynamics = self.model_expression_dynamics()

        # 3. 代谢组水平：代谢通量平衡
        metabolic_fluxes = self.model_metabolic_fluxes()

        return {
            'genetic_effects': genetic_effects,
            'expression_dynamics': expression_dynamics,
            'metabolic_fluxes': metabolic_fluxes
        }

    def model_genetic_effects(self):
        """建模遗传效应"""
        # 基于SNP数据建模等位基因特异性表达
        genetic_effects = {}

        for variant in self.genomic_data.variants:
            # 计算等位基因频率
            af = self.genomic_data.get_allele_frequency(variant)

            # 预测功能影响
            impact = self.predict_variant_impact(variant)

            genetic_effects[variant] = {
                'allele_frequency': af,
                'functional_impact': impact,
                'target_genes': self.get_target_genes(variant)
            }

        return genetic_effects

    def model_expression_dynamics(self):
        """建模表达动态"""
        # 基于调控网络的微分方程模型
        def expression_odes(y, t, parameters):
            # y: 基因表达水平向量
            # parameters: 调控参数

            dydt = np.zeros_like(y)

            for i, gene in enumerate(self.regulatory_network.genes):
                # 计算调控输入
                regulators = self.regulatory_network.get_regulators(gene)
                input_signal = 0

                for regulator in regulators:
                    reg_idx = self.regulatory_network.genes.index(regulator)
                    weight = self.regulatory_network.get_weight(regulator, gene)
                    input_signal += weight * y[reg_idx]

                # 基础表达 + 调控 - 降解
                dydt[i] = parameters['basal'][i] + input_signal - parameters['decay'][i] * y[i]

            return dydt

        # 初始条件
        initial_conditions = self.get_initial_expression()

        # 参数
        parameters = self.get_expression_parameters()

        # 时间点
        time_points = np.linspace(0, 100, 1000)

        # 数值求解
        solution = odeint(expression_odes, initial_conditions, time_points, args=(parameters,))

        return {
            'time_series': solution,
            'steady_state': solution[-1, :],
            'dynamics': self.analyze_dynamics(solution)
        }

    def model_metabolic_fluxes(self):
        """建模代谢通量"""
        # 结合FBA和表达数据
        integrated_model = self.metabolic_network.copy()

        # 基于表达水平约束反应通量
        for reaction in integrated_model.reactions:
            if reaction.gene_association:
                # 获取相关基因的表达水平
                gene_expr = self.get_gene_expression(reaction.gene_association)
                # 设置通量上限
                integrated_model.reactions[reaction].upper_bound *= np.mean(gene_expr)

        # 运行整合的FBA
        fba_result = self.run_integrated_fba(integrated_model)

        return fba_result

    def predict_phenotype(self, environmental_conditions):
        """预测表型"""
        # 整合所有层次的信息预测最终表型
        multi_scale_data = self.integrate_multi_scale_data()

        # 基于机器学习的表型预测
        phenotype_predictor = self.train_phenotype_predictor(multi_scale_data)

        predicted_phenotype = phenotype_predictor.predict(environmental_conditions)

        return predicted_phenotype

    def sensitivity_analysis(self, parameters):
        """敏感性分析"""
        # 分析系统对参数变化的敏感性
        sensitivity_results = {}

        for param_name, param_values in parameters.items():
            param_sensitivity = []

            for value in param_values:
                # 修改参数
                self.modify_parameter(param_name, value)

                # 重新模拟
                result = self.simulate()

                # 记录响应
                param_sensitivity.append(self.extract_response(result))

            sensitivity_results[param_name] = param_sensitivity

        return sensitivity_results

    def run_integrated_simulation(self, conditions):
        """运行整合模拟"""
        # 多层次耦合模拟
        simulation_results = {}

        # 1. 基因组模拟
        genetic_state = self.simulate_genome(conditions)

        # 2. 转录组模拟
        expression_state = self.simulate_transcriptome(genetic_state, conditions)

        # 3. 代谢组模拟
        metabolic_state = self.simulate_metabolome(expression_state, conditions)

        # 4. 表型预测
        phenotype = self.predict_from_states(genetic_state, expression_state, metabolic_state)

        return {
            'genetic_state': genetic_state,
            'expression_state': expression_state,
            'metabolic_state': metabolic_state,
            'predicted_phenotype': phenotype
        }
```

## 9.5 系统生物学工具

### 9.5.1 常用软件工具

#### 9.5.1.1 Python生态系统

**主要库**：
- **COBRApy**：代谢网络建模
- **NetworkX**：网络分析
- **BioPython**：生物信息学工具
- **Scikit-learn**：机器学习
- **PyMC3**：贝叶斯建模

```python

# COBRApy示例：代谢网络建模
import cobra
from cobra import Model, Reaction, Metabolite

# 创建简单的代谢模型
model = Model('simple_model')

# 添加代谢物
glc = Metabolite('glc', name='Glucose')
glc_6_p = Metabolite('glc_6_p', name='Glucose-6-phosphate')
atp = Metabolite('atp', name='ATP')
adp = Metabolite('adp', name='ADP')
h = Metabolite('h', name='H+')

# 添加反应
reaction1 = Reaction('HEX1')
reaction1.name = 'Hexokinase'
reaction1.add_metabolites({
    glc: -1,
    atp: -1,
    glc_6_p: 1,
    adp: 1,
    h: 1
})
reaction1.lower_bound = 0
reaction1.upper_bound = 1000

model.add_reactions([reaction1])

# 设置目标函数
model.objective = 'HEX1'

# 运行FBA
solution = model.optimize()
print(f"Optimal flux: {solution.objective_value}")
```

#### 9.5.1.2 R/Bioconductor生态系统

**主要包**：
- **limma**：差异表达分析
- **clusterProfiler**：富集分析
- **igraph**：网络分析
- **DESeq2**：RNA-seq分析

```r

# R示例：通路富集分析
library(clusterProfiler)
library(org.Hs.eg.db)

# 差异表达基因列表
de_genes <- c("TP53", "EGFR", "AKT1", "MAPK1")

# 转换为ENTREZ ID
entrez_ids <- mapIds(org.Hs.eg.db,
                     keys=de_genes,
                     column="ENTREZID",
                     keytype="SYMBOL")

# GO富集分析
go_enrich <- enrichGO(gene = entrez_ids$ENTREZID,
                     OrgDb = org.Hs.eg.db,
                     keyType = "ENTREZID",
                     ont = "BP",
                     pAdjustMethod = "BH",
                     pvalueCutoff = 0.05,
                     qvalueCutoff = 0.05)

# 可视化
dotplot(go_enrich, showCategory=20)
```

### 9.5.2 专用软件平台

#### 9.5.2.1 Cytoscape

**网络可视化和分析**：
- **插件生态系统**：丰富的第三方插件
- **数据导入**：支持多种格式
- **网络分析**：拓扑分析、模块检测
- **可视化**：高级图形渲染

#### 9.5.2.2 CellDesigner

**生物通路建模**：
- **SBML支持**：标准模型交换格式
- **图形界面**：直观的通路编辑
- **模拟功能**：动力学模拟
- **数据库集成**：KEGG、Reactome等

#### 9.5.2.3 Gephi

**大规模网络分析**：
- **性能优化**：处理大规模网络
- **布局算法**：多种网络布局
- **动态网络**：时间序列网络分析
- **社区检测**：自动模块识别

## 9.6 并行计算在系统生物学中的应用

### 9.6.1 大规模基因组分析

```python
import multiprocessing as mp
from concurrent.futures import ProcessPoolExecutor
import numpy as np

def parallel_genome_wide_association(data_chunks, phenotype):
    """并行全基因组关联分析"""
    results = []

    def process_chunk(chunk):
        chunk_results = []
        for variant in chunk:
            # GWAS分析
            statistic = perform_gwas(variant, phenotype)
            chunk_results.append(statistic)
        return chunk_results

    # 并行处理
    with ProcessPoolExecutor() as executor:
        futures = [executor.submit(process_chunk, chunk) for chunk in data_chunks]
        for future in futures:
            results.extend(future.result())

    return results

def parallel_pathway_analysis(pathways, expression_data):
    """并行通路富集分析"""
    def analyze_pathway(pathway):
        # 单个通路分析
        return pathway_enrichment_test(pathway, expression_data)

    with ProcessPoolExecutor() as executor:
        results = list(executor.map(analyze_pathway, pathways))

    return results
```

### 9.6.2 分子动力学模拟

```cuda
// CUDA加速分子动力学
__global__ void compute_forces(float* positions, float* forces,
                              int n_atoms, float cutoff) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;

    if (i < n_atoms) {
        float fx = 0.0f, fy = 0.0f, fz = 0.0f;

        for (int j = 0; j < n_atoms; j++) {
            if (i != j) {
                float dx = positions[j*3] - positions[i*3];
                float dy = positions[j*3+1] - positions[i*3+1];
                float dz = positions[j*3+2] - positions[i*3+2];

                float r2 = dx*dx + dy*dy + dz*dz;
                if (r2 < cutoff*cutoff) {
                    float r = sqrtf(r2);
                    float force = compute_lennard_jones_force(r);
                    fx += force * dx / r;
                    fy += force * dy / r;
                    fz += force * dz / r;
                }
            }
        }

        forces[i*3] = fx;
        forces[i*3+1] = fy;
        forces[i*3+2] = fz;
    }
}
```

### 9.6.3 单细胞数据分析

```python
import scanpy as sc
import pandas as pd
from multiprocessing import Pool

def parallel_single_cell_analysis(expression_matrix, metadata):
    """并行单细胞数据分析"""

    # 1. 数据预处理（可以并行）
    def preprocess_chunk(chunk_data):
        # 标准化、过滤等
        return preprocess(chunk_data)

    # 2. 降维分析
    def dimensionality_reduction(data):
        # PCA、UMAP等
        return reduce_dimensions(data)

    # 3. 聚类分析
    def cluster_cells(data):
        # Louvain、Leiden等
        return cluster(data)

    # 并行执行
    with Pool() as pool:
        # 预处理
        preprocessed_data = pool.map(preprocess_chunk, data_chunks)

        # 降维
        reduced_data = dimensionality_reduction(preprocessed_data)

        # 聚类
        clusters = cluster_cells(reduced_data)

    return {
        'reduced_data': reduced_data,
        'clusters': clusters,
        'markers': find_cluster_markers(reduced_data, clusters)
    }
```

## 9.7 实际案例研究

### 9.7.1 癌症系统生物学

#### 9.7.1.1 肿瘤异质性分析

```python
import numpy as np
import pandas as pd
from sklearn.decomposition import NMF
from scipy.spatial.distance import pdist, squareform

class TumorHeterogeneityAnalysis:
    def __init__(self, multi_region_data):
        self.data = multi_region_data  # 多区域测序数据

    def identify_subclones(self, n_components=5):
        """识别肿瘤亚克隆"""
        # 非负矩阵分解
        nmf = NMF(n_components=n_components, random_state=42)
        W = nmf.fit_transform(self.data)
        H = nmf.components_

        return {
            'subclone_proportions': W,
            'mutational_signatures': H,
            'explained_variance': nmf.reconstruction_err_
        }

    def reconstruct_phylogenetic_tree(self, subclones):
        """重建系统发育树"""
        # 计算亚克隆间距离
        distances = pdist(subclones, metric='euclidean')
        distance_matrix = squareform(distances)

        # 构建系统发育树
        tree = self.build_tree(distance_matrix)

        return tree

    def analyze_evolutionary_patterns(self, phylogenetic_tree):
        """分析进化模式"""
        # 分支长度分析
        # 突变积累模式
        # 选择压力分析

        return evolutionary_metrics
```

#### 9.7.1.2 药物响应预测

```python
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import cross_val_score

class DrugResponsePrediction:
    def __init__(self, multiomics_data, drug_sensitivity):
        self.multiomics = multiomics_data
        self.drug_response = drug_sensitivity

    def integrate_multiomics_for_prediction(self):
        """整合多组学数据预测药物响应"""

        # 1. 特征工程
        genomic_features = self.extract_genomic_features()
        transcriptomic_features = self.extract_transcriptomic_features()
        epigenomic_features = self.extract_epigenomic_features()

        # 2. 特征融合
        integrated_features = self.fuse_features([
            genomic_features,
            transcriptomic_features,
            epigenomic_features
        ])

        # 3. 模型训练
        model = RandomForestRegressor(n_estimators=1000, random_state=42)
        cv_scores = cross_val_score(model, integrated_features,
                                  self.drug_response, cv=5)

        # 4. 特征重要性分析
        model.fit(integrated_features, self.drug_response)
        feature_importance = model.feature_importances_

        return {
            'cv_scores': cv_scores,
            'feature_importance': feature_importance,
            'predicted_response': model.predict(integrated_features)
        }
```

### 9.7.2 微生物组系统生物学

#### 9.7.2.1 宏基因组数据分析

```python
import numpy as np
import pandas as pd
from scipy.stats import spearmanr
import networkx as nx

class MicrobiomeSystemsAnalysis:
    def __init__(self, metagenomic_data, metadata):
        self.taxa_abundance = metagenomic_data
        self.metadata = metadata

    def construct_microbial_network(self, correlation_threshold=0.6):
        """构建微生物相互作用网络"""
        # 计算物种间相关性
        correlations = self.taxa_abundance.corr(method='spearman')

        # 构建网络
        G = nx.Graph()

        # 添加节点
        for taxa in self.taxa_abundance.columns:
            G.add_node(taxa)

        # 添加边
        for i, taxa1 in enumerate(self.taxa_abundance.columns):
            for j, taxa2 in enumerate(self.taxa_abundance.columns):
                if i < j:  # 避免重复
                    corr = correlations.iloc[i, j]
                    if abs(corr) > correlation_threshold:
                        G.add_edge(taxa1, taxa2, weight=abs(corr))

        return G

    def identify_keystone_species(self, network):
        """识别关键物种"""
        # 计算网络中心性
        centrality = nx.betweenness_centrality(network)
        closeness = nx.closeness_centrality(network)
        degree = dict(network.degree())

        # 综合评分
        keystone_scores = {}
        for node in network.nodes():
            score = (centrality[node] * 0.4 +
                    closeness[node] * 0.3 +
                    degree[node] / max(degree.values()) * 0.3)
            keystone_scores[node] = score

        return sorted(keystone_scores.items(), key=lambda x: x[1], reverse=True)

    def analyze_community_structure(self, network):
        """分析群落结构"""
        # 社区检测
        communities = nx.community.greedy_modularity_communities(network)

        # 群落特征
        community_features = {}
        for i, community in enumerate(communities):
            subgraph = network.subgraph(community)

            community_features[f'community_{i}'] = {
                'size': len(community),
                'density': nx.density(subgraph),
                'diversity': self.calculate_diversity(community)
            }

        return community_features
```

### 9.7.3 合成生物学

#### 9.7.3.1 代谢通路设计

```python
import numpy as np
from scipy.optimize import minimize
import cobra

class MetabolicPathwayDesign:
    def __init__(self, host_model, target_product):
        self.host_model = host_model
        self.target_product = target_product

    def optimize_pathway_flux(self, pathway_reactions):
        """优化代谢通路通量"""

        # 添加异源反应到宿主模型
        engineered_model = self.host_model.copy()
        for reaction in pathway_reactions:
            engineered_model.add_reactions([reaction])

        # 设置目标产物合成反应
        target_reaction = self.create_target_reaction(self.target_product)
        engineered_model.add_reactions([target_reaction])

        # 设置目标函数
        engineered_model.objective = target_reaction.id

        # 运行FBA优化
        solution = engineered_model.optimize()

        return {
            'max_yield': solution.objective_value,
            'flux_distribution': solution.fluxes,
            'growth_coupling': self.analyze_growth_coupling(solution)
        }

    def design_genetic_circuits(self, circuit_components):
        """设计遗传回路"""

        # 定义遗传元件
        promoters = circuit_components['promoters']
        rbs = circuit_components['rbs']
        coding_sequences = circuit_components['coding_sequences']

        # 优化组合
        best_design = self.optimize_circuit_design(
            promoters, rbs, coding_sequences
        )

        return best_design

    def predict_circuit_behavior(self, genetic_design):
        """预测回路行为"""

        # 建立动力学模型
        model = self.build_circuit_model(genetic_design)

        # 数值模拟
        time_course = self.simulate_circuit_dynamics(model)

        return time_course
```

## 本章小结

本章深入探讨了系统生物学的核心内容，包括：

### 核心领域
1. **代谢网络建模**：FBA、FVA、基因敲除分析
2. **信号通路分析**：网络建模、动力学模拟、富集分析
3. **多组学数据整合**：数据标准化、特征选择、网络重建
4. **系统级分析**：多尺度建模、表型预测

### 关键技术
- **数学建模**：微分方程、线性规划、统计模型
- **网络分析**：拓扑结构、中心性、模块检测
- **并行计算**：大规模数据分析、GPU加速
- **机器学习**：特征选择、模式识别、预测建模

### 实际应用
- **疾病机制研究**：癌症异质性、药物响应
- **微生物组分析**：群落结构、功能预测
- **合成生物学**：代谢工程、遗传回路设计
- **精准医学**：个性化治疗、生物标志物发现

### 未来方向
- **单细胞系统生物学**：细胞异质性分析
- **空间系统生物学**：组织空间结构
- **人工智能整合**：深度学习、知识图谱
- **实时监测**：动态系统建模

系统生物学作为21世纪生命科学的重要前沿，正在深刻改变我们对生命系统的理解方式，为疾病治疗、生物技术和生命科学研究提供强有力的理论基础和技术手段。