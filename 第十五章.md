# 第十五章：优化策略

## 15.1 算法层面优化

### 15.1.1 算法选择与并行化潜力评估

**算法并行化潜力分析**：

| 算法类型 | 并行化潜力 | 适用场景 | 优化策略 |
|----------|------------|----------|----------|
| 分治算法 | 极高 | 排序、搜索、矩阵运算 | 递归分解，独立子问题 |
| 动态规划 | 中等 | 序列比对、最短路径 | 依赖关系分析，波前并行 |
| 贪心算法 | 低到中等 | 图算法、调度问题 | 局部优化，减少依赖 |
| 分支限界 | 低 | 组合优化、搜索树 | 工作窃取，负载均衡 |

**算法复杂度优化**：

```python
# 串行实现：O(n²)
def matrix_multiplication_serial(A, B):
    n = len(A)
    C = [[0 for _ in range(n)] for _ in range(n)]
    for i in range(n):
        for j in range(n):
            for k in range(n):
                C[i][j] += A[i][k] * B[k][j]
    return C

# 分块并行实现：O(n³/p) + 通信开销
def block_matrix_multiplication_parallel(A, B, num_processors):
    n = len(A)
    block_size = n // num_processors
    C = [[0 for _ in range(n)] for _ in range(n)]

    # 并行计算每个块
    def compute_block(p):
        start = p * block_size
        end = (p + 1) * block_size if p < num_processors - 1 else n

        for i in range(start, end):
            for j in range(n):
                for k in range(n):
                    C[i][j] += A[i][k] * B[k][j]

    # 启动并行任务
    import multiprocessing
    processes = []
    for p in range(num_processors):
        proc = multiprocessing.Process(target=compute_block, args=(p,))
        processes.append(proc)
        proc.start()

    for proc in processes:
        proc.join()

    return C
```

### 15.1.2 数据结构优化

**缓存友好的数据结构设计**：

```c
// 不友好的内存访问模式
typedef struct {
    int id;
    double value;
    char name[256];  // 大字段导致缓存浪费
} DataItem;

// 优化后的结构体
typedef struct {
    int id;
    double value;
    // 将大字段分离
} DataItemOptimized;

typedef struct {
    int id;
    char name[256];
} NameItem;

// 数组结构体 vs 结构体数组
// 结构体数组 - 更好的缓存局部性
typedef struct {
    float *x, *y, *z;  // SoA (Structure of Arrays)
    int count;
} ParticleSystem;

// 对比：数组结构体 - 缓存不友好
typedef struct {
    float x, y, z;     // AoS (Array of Structures)
} Particle;
```

**空间填充曲线优化**：

```python
import numpy as np

def hilbert_curve_index(x, y, n):
    """计算Hilbert曲线索引"""
    rx, ry = 0, 0
    s = n // 2
    d = 0

    while s > 0:
        rx = (x & s) > 0
        ry = (y & s) > 0
        d += s * s * ((3 * rx) ^ ry)

        if ry == 0:
            if rx == 1:
                x = n - 1 - x
                y = n - 1 - y

            # 交换x和y
            x, y = y, x

        s //= 2

    return d

def optimize_matrix_access_order(matrix):
    """使用Hilbert曲线优化矩阵访问顺序"""
    n = matrix.shape[0]
    optimized_order = []

    for i in range(n):
        for j in range(n):
            hilbert_idx = hilbert_curve_index(i, j, n)
            optimized_order.append((hilbert_idx, i, j))

    # 按Hilbert索引排序
    optimized_order.sort()

    return optimized_order
```

### 15.1.3 计算复杂度优化

**Strassen矩阵乘法**：

```python
def strassen_multiply(A, B):
    """Strassen算法：O(n^log₂7) ≈ O(n^2.807)"""
    n = len(A)

    if n == 1:
        return [[A[0][0] * B[0][0]]]

    # 分块
    mid = n // 2
    A11, A12, A21, A22 = split_matrix(A, mid)
    B11, B12, B21, B22 = split_matrix(B, mid)

    # 计算7个乘积
    M1 = strassen_multiply(add_matrices(A11, A22), add_matrices(B11, B22))
    M2 = strassen_multiply(add_matrices(A21, A22), B11)
    M3 = strassen_multiply(A11, subtract_matrices(B12, B22))
    M4 = strassen_multiply(A22, subtract_matrices(B21, B11))
    M5 = strassen_multiply(add_matrices(A11, A12), B22)
    M6 = strassen_multiply(subtract_matrices(A21, A11), add_matrices(B11, B12))
    M7 = strassen_multiply(subtract_matrices(A12, A22), add_matrices(B21, B22))

    # 组合结果
    C11 = add_matrices(subtract_matrices(add_matrices(M1, M4), M5), M7)
    C12 = add_matrices(M3, M5)
    C21 = add_matrices(M2, M4)
    C22 = add_matrices(subtract_matrices(add_matrices(M1, M3), M2), M6)

    return combine_matrices(C11, C12, C21, C22)

def split_matrix(matrix, mid):
    """矩阵分块"""
    A11 = [row[:mid] for row in matrix[:mid]]
    A12 = [row[mid:] for row in matrix[:mid]]
    A21 = [row[:mid] for row in matrix[mid:]]
    A22 = [row[mid:] for row in matrix[mid:]]
    return A11, A12, A21, A22
```

## 15.2 系统层面优化

### 15.2.1 编译器优化

**GCC优化选项**：

```bash
# 基本优化
gcc -O2 -march=native -mtune=native program.c -o program

# 高级优化
gcc -O3 -flto -ffast-math -mavx2 -mfma program.c -o program

# 针对特定架构优化
gcc -O3 -march=skylake -mtune=skylake program.c -o program

# 向量化优化
gcc -O3 -ftree-vectorize -mavx2 program.c -o program
```

**编译器内建函数**：

```c
#include <immintrin.h>

// 使用SIMD指令优化向量加法
void vector_add_simd(float *a, float *b, float *c, int n) {
    int i = 0;

    // 处理16个float的块（AVX2）
    for (; i <= n - 8; i += 8) {
        __m256 va = _mm256_loadu_ps(&a[i]);
        __m256 vb = _mm256_loadu_ps(&b[i]);
        __m256 vc = _mm256_add_ps(va, vb);
        _mm256_storeu_ps(&c[i], vc);
    }

    // 处理剩余元素
    for (; i < n; i++) {
        c[i] = a[i] + b[i];
    }
}
```

### 15.2.2 数学库优化

**BLAS库选择与配置**：

```python
import numpy as np
from scipy.linalg import blas

# 检查BLAS实现
print("BLAS implementation:", np.__config__.show())

# 使用OpenBLAS优化矩阵运算
def optimized_matrix_multiply(A, B):
    """使用BLAS优化的矩阵乘法"""
    return blas.dgemm(alpha=1.0, a=A, b=B)

# Intel MKL优化
import mkl
mkl.set_num_threads(4)  # 设置线程数

# ATLAS配置
# 在编译时指定：./configure --with-netlib-lapack=yes
```

**FFTW优化**：

```c
#include <fftw3.h>

// 创建优化的FFT计划
fftw_plan create_optimized_fft_plan(int n) {
    fftw_complex *in, *out;
    fftw_plan plan;

    // 分配对齐内存
    in = (fftw_complex*) fftw_malloc(sizeof(fftw_complex) * n);
    out = (fftw_complex*) fftw_malloc(sizeof(fftw_complex) * n);

    // 创建测量计划（会进行实际测量）
    plan = fftw_plan_dft_1d(n, in, out, FFTW_FORWARD, FFTW_MEASURE);

    // 或者使用估计计划（更快创建）
    // plan = fftw_plan_dft_1d(n, in, out, FFTW_FORWARD, FFTW_ESTIMATE);

    fftw_free(in);
    fftw_free(out);

    return plan;
}

// 多维FFT优化
fftw_plan create_2d_fft_plan(int rows, int cols) {
    fftw_complex *in, *out;
    in = (fftw_complex*) fftw_malloc(sizeof(fftw_complex) * rows * cols);
    out = (fftw_complex*) fftw_malloc(sizeof(fftw_complex) * rows * cols);

    // 创建2D FFT计划
    fftw_plan plan = fftw_plan_dft_2d(rows, cols, in, out,
                                     FFTW_FORWARD, FFTW_MEASURE);

    fftw_free(in);
    fftw_free(out);

    return plan;
}
```

### 15.2.3 系统配置优化

**Linux系统调优**：

```bash
# CPU频率调节
echo performance | sudo tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor

# 禁用NUMA平衡
echo 0 | sudo tee /proc/sys/kernel/numa_balancing

# 内存管理优化
echo 1 | sudo tee /proc/sys/vm/overcommit_memory
echo 80 | sudo tee /proc/sys/vm/dirty_ratio

# 网络优化
echo 1 | sudo tee /proc/sys/net/ipv4/tcp_low_latency

# 文件系统优化
mount -o noatime,nodiratime /dev/sda1 /data
```

**NUMA感知优化**：

```c
#include <numa.h>
#include <numaif.h>

// NUMA感知的内存分配
void *numa_aware_malloc(size_t size, int node) {
    void *ptr = numa_alloc_onnode(size, node);
    return ptr;
}

// 绑定进程到特定NUMA节点
void bind_to_numa_node(int node) {
    struct bitmask *mask = numa_allocate_nodemask();
    numa_bitmask_clearall(mask);
    numa_bitmask_setbit(mask, node);
    numa_bind(mask);
    numa_free_nodemask(mask);
}

// 获取NUMA拓扑信息
void print_numa_topology() {
    int num_nodes = numa_num_available_nodes();
    printf("Available NUMA nodes: %d\n", num_nodes);

    for (int i = 0; i < num_nodes; i++) {
        if (numa_bitmask_isbitset(numa_nodes_ptr, i)) {
            unsigned long size = numa_node_size(i, NULL);
            printf("Node %d: %lu bytes\n", i, size);
        }
    }
}
```

## 15.3 并行层面优化

### 15.3.1 负载均衡策略

**静态负载均衡**：

```python
def static_load_balancing(tasks, num_processors):
    """静态负载均衡：平均分配任务"""
    chunk_size = len(tasks) // num_processors
    remainder = len(tasks) % num_processors

    assignments = []
    start = 0

    for i in range(num_processors):
        end = start + chunk_size + (1 if i < remainder else 0)
        assignments.append(tasks[start:end])
        start = end

    return assignments

def block_distribution(matrix, num_processors):
    """块分布：将矩阵按行分块"""
    n = len(matrix)
    block_size = n // num_processors
    blocks = []

    for p in range(num_processors):
        start_row = p * block_size
        end_row = (p + 1) * block_size if p < num_processors - 1 else n
        blocks.append(matrix[start_row:end_row])

    return blocks
```

**动态负载均衡**：

```python
import multiprocessing as mp
from queue import Queue
import threading

class WorkStealingScheduler:
    def __init__(self, num_workers):
        self.num_workers = num_workers
        self.work_queues = [Queue() for _ in range(num_workers)]
        self.locks = [threading.Lock() for _ in range(num_workers)]
        self.workers = []

    def submit_work(self, work_item, worker_id=None):
        """提交工作项"""
        if worker_id is None:
            # 负载均衡：选择最轻的队列
            worker_id = min(range(self.num_workers),
                          key=lambda i: self.work_queues[i].qsize())

        self.work_queues[worker_id].put(work_item)

    def steal_work(self, thief_id):
        """工作窃取"""
        for victim_id in range(self.num_workers):
            if victim_id != thief_id and not self.work_queues[victim_id].empty():
                with self.locks[victim_id]:
                    if not self.work_queues[victim_id].empty():
                        work_item = self.work_queues[victim_id].get()
                        self.work_queues[thief_id].put(work_item)
                        return True
        return False

    def worker_loop(self, worker_id):
        """工作线程循环"""
        while True:
            try:
                # 尝试从自己的队列获取任务
                work_item = self.work_queues[worker_id].get(timeout=1)
                self.process_work(work_item, worker_id)
            except:
                # 队列为空，尝试窃取工作
                if not self.steal_work(worker_id):
                    break  # 没有工作可做

    def process_work(self, work_item, worker_id):
        """处理工作项"""
        # 实际的工作处理逻辑
        result = work_item()
        # 处理结果...
```

**自适应负载均衡**：

```python
class AdaptiveLoadBalancer:
    def __init__(self, num_processors):
        self.num_processors = num_processors
        self.processor_load = [0] * num_processors
        self.processor_speed = [1.0] * num_processors  # 相对速度
        self.task_history = []

    def estimate_task_cost(self, task_type):
        """基于历史数据估算任务成本"""
        relevant_history = [h for h in self.task_history
                           if h['type'] == task_type]

        if not relevant_history:
            return 1.0  # 默认成本

        # 计算平均执行时间
        avg_time = sum(h['time'] for h in relevant_history) / len(relevant_history)
        return avg_time

    def assign_task(self, task):
        """智能任务分配"""
        task_cost = self.estimate_task_cost(task.type)

        # 计算每个处理器的预期完成时间
        completion_times = []
        for i in range(self.num_processors):
            expected_time = self.processor_load[i] + task_cost / self.processor_speed[i]
            completion_times.append(expected_time)

        # 选择最早完成的处理器
        selected_processor = min(range(self.num_processors),
                               key=lambda i: completion_times[i])

        # 更新负载信息
        self.processor_load[selected_processor] += task_cost

        return selected_processor

    def update_performance(self, processor_id, actual_time, task_type):
        """更新性能信息"""
        # 更新负载
        self.processor_load[processor_id] -= actual_time

        # 添加到历史记录
        self.task_history.append({
            'processor': processor_id,
            'time': actual_time,
            'type': task_type
        })

        # 保持历史记录在合理大小
        if len(self.task_history) > 1000:
            self.task_history.pop(0)
```

### 15.3.2 通信优化

**通信聚合**：

```c
// MPI通信聚合示例
void optimized_mpi_communication(float *data, int size, MPI_Comm comm) {
    int rank, size;
    MPI_Comm_rank(comm, &rank);
    MPI_Comm_size(comm, &size);

    // 使用非阻塞通信
    MPI_Request *requests = malloc(size * sizeof(MPI_Request));
    MPI_Status *statuses = malloc(size * sizeof(MPI_Status));

    // 聚合多个小消息为大消息
    int chunk_size = size / 10;  // 每个消息包含10个元素
    int num_chunks = (size + chunk_size - 1) / chunk_size;

    for (int i = 0; i < num_chunks; i++) {
        int start = i * chunk_size;
        int count = (i == num_chunks - 1) ? (size - start) : chunk_size;

        // 非阻塞发送
        MPI_Isend(&data[start], count, MPI_FLOAT, (rank + 1) % size,
                 i, comm, &requests[i]);

        // 非阻塞接收
        MPI_Irecv(&data[start], count, MPI_FLOAT, (rank - 1 + size) % size,
                 i, comm, &requests[i + num_chunks]);
    }

    // 等待所有通信完成
    MPI_Waitall(2 * num_chunks, requests, statuses);

    free(requests);
    free(statuses);
}
```

**拓扑优化**：

```c
// MPI进程拓扑优化
void create_optimized_topology(MPI_Comm comm, int *dims) {
    int num_procs;
    MPI_Comm_size(comm, &num_procs);

    // 计算最优的2D网格维度
    int sqrt_procs = (int)sqrt(num_procs);
    while (sqrt_procs * sqrt_procs < num_procs) sqrt_procs++;

    dims[0] = sqrt_procs;
    dims[1] = (num_procs + sqrt_procs - 1) / sqrt_procs;

    // 创建笛卡尔拓扑
    int periods[2] = {1, 1};  // 周期性边界
    MPI_Comm cart_comm;
    MPI_Cart_create(comm, 2, dims, periods, 1, &cart_comm);

    // 获取邻居信息
    int coords[2];
    MPI_Cart_coords(cart_comm, 0, 2, coords);

    int neighbors[4];
    MPI_Cart_shift(cart_comm, 0, 1, &neighbors[0], &neighbors[1]);
    MPI_Cart_shift(cart_comm, 1, 1, &neighbors[2], &neighbors[3]);
}
```

**通信隐藏**：

```c
// 重叠计算和通信
void compute_and_communicate_overlap(float *matrix, int size, MPI_Comm comm) {
    int rank, num_procs;
    MPI_Comm_rank(comm, &rank);
    MPI_Comm_size(comm, &num_procs);

    MPI_Request send_req, recv_req;
    MPI_Status status;

    // 启动异步通信
    if (rank < num_procs - 1) {
        MPI_Isend(&matrix[size-1][0], size, MPI_FLOAT, rank+1, 0, comm, &send_req);
    }
    if (rank > 0) {
        MPI_Irecv(&matrix[0][0], size, MPI_FLOAT, rank-1, 0, comm, &recv_req);
    }

    // 在通信进行时执行计算
    for (int i = 1; i < size-1; i++) {
        for (int j = 0; j < size; j++) {
            // 执行计算
            matrix[i][j] = compute_value(matrix, i, j);
        }
    }

    // 等待通信完成
    if (rank < num_procs - 1) {
        MPI_Wait(&send_req, &status);
    }
    if (rank > 0) {
        MPI_Wait(&recv_req, &status);
    }
}
```

### 15.3.3 同步优化

**减少同步点**：

```c
// 减少MPI Barrier的使用
void optimized_synchronization(int iterations, MPI_Comm comm) {
    int rank, num_procs;
    MPI_Comm_rank(comm, &rank);
    MPI_Comm_size(comm, &num_procs);

    for (int iter = 0; iter < iterations; iter++) {
        // 局部计算
        local_computation();

        // 只在必要时同步
        if (iter % 10 == 0) {  // 每10次迭代同步一次
            MPI_Barrier(comm);
        }

        // 局部通信替代全局同步
        int neighbor = (rank + 1) % num_procs;
        MPI_Sendrecv(local_data, size, MPI_FLOAT, neighbor, iter,
                    remote_data, size, MPI_FLOAT, neighbor, iter, comm, MPI_STATUS_IGNORE);
    }
}
```

**流水线同步**：

```c
// 流水线处理减少同步
void pipeline_processing(float *data, int n, int stages, MPI_Comm comm) {
    int rank, num_procs;
    MPI_Comm_rank(comm, &rank);
    MPI_Comm_size(comm, &num_procs);

    // 每个进程处理不同的流水线阶段
    int stage = rank % stages;

    for (int i = 0; i < n; i++) {
        // 阶段1：数据预处理
        if (stage == 0) {
            preprocess_data(&data[i]);
            MPI_Send(&data[i], 1, MPI_FLOAT, rank + 1, 0, comm);
        }
        // 阶段2：主要计算
        else if (stage == 1) {
            MPI_Recv(&data[i], 1, MPI_FLOAT, rank - 1, 0, comm, MPI_STATUS_IGNORE);
            compute_data(&data[i]);
            MPI_Send(&data[i], 1, MPI_FLOAT, rank + 1, 0, comm);
        }
        // 阶段3：后处理
        else if (stage == 2) {
            MPI_Recv(&data[i], 1, MPI_FLOAT, rank - 1, 0, comm, MPI_STATUS_IGNORE);
            postprocess_data(&data[i]);
        }
    }
}
```

## 15.4 生物信息学特定优化

### 15.4.1 序列分析优化

**K-mer计数优化**：

```python
import numpy as np
from collections import defaultdict

def optimized_kmer_counting(sequence, k=6):
    """优化的K-mer计数"""
    # 使用滑动窗口避免重复计算
    kmer_counts = defaultdict(int)
    current_kmer = sequence[:k]

    # 预计算第一个k-mer
    kmer_counts[current_kmer] += 1

    # 滑动窗口
    for i in range(1, len(sequence) - k + 1):
        # 移除第一个字符，添加新字符
        current_kmer = current_kmer[1:] + sequence[i + k - 1]
        kmer_counts[current_kmer] += 1

    return kmer_counts

def parallel_kmer_counting(sequences, k=6, num_threads=4):
    """并行K-mer计数"""
    import multiprocessing as mp

    def count_kmers_chunk(chunk):
        counts = defaultdict(int)
        for seq in chunk:
            counts.update(optimized_kmer_counting(seq, k))
        return counts

    # 分块
    chunk_size = len(sequences) // num_threads
    chunks = [sequences[i:i+chunk_size] for i in range(0, len(sequences), chunk_size)]

    # 并行处理
    with mp.Pool(num_threads) as pool:
        results = pool.map(count_kmers_chunk, chunks)

    # 合并结果
    final_counts = defaultdict(int)
    for result in results:
        for kmer, count in result.items():
            final_counts[kmer] += count

    return final_counts
```

**序列比对优化**：

```python
def optimized_sequence_alignment(seq1, seq2, match_score=1, mismatch_score=-1, gap_score=-2):
    """优化的序列比对算法"""
    m, n = len(seq1), len(seq2)

    # 使用一维数组减少内存使用
    prev_row = [0] * (n + 1)
    curr_row = [0] * (n + 1)

    # 初始化第一行
    for j in range(1, n + 1):
        prev_row[j] = prev_row[j-1] + gap_score

    # 动态规划填表
    for i in range(1, m + 1):
        curr_row[0] = prev_row[0] + gap_score

        for j in range(1, n + 1):
            # 计算三种可能的得分
            match = prev_row[j-1] + (match_score if seq1[i-1] == seq2[j-1] else mismatch_score)
            delete = prev_row[j] + gap_score
            insert = curr_row[j-1] + gap_score

            curr_row[j] = max(0, match, delete, insert)

        # 交换行
        prev_row, curr_row = curr_row, prev_row

    return prev_row[n]

def vectorized_sequence_alignment(seq1, seq2):
    """向量化序列比对"""
    import numpy as np

    m, n = len(seq1), len(seq2)
    dp = np.zeros((m + 1, n + 1), dtype=np.int32)

    # 向量化初始化
    dp[0, 1:] = np.arange(1, n + 1) * -2
    dp[1:, 0] = np.arange(1, m + 1) * -2

    # 向量化填表
    for i in range(1, m + 1):
        # 计算匹配得分
        matches = dp[i-1, :-1] + np.where(np.array(list(seq1[i-1])) == np.array(list(seq2)), 1, -1)

        # 计算插入和删除得分
        deletes = dp[i-1, 1:] - 2
        inserts = dp[i, :-1] - 2

        # 向量化最大值计算
        dp[i, 1:] = np.maximum.reduce([np.zeros(n), matches, deletes, inserts])

    return dp[m, n]
```

### 15.4.2 基因组组装优化

**De Bruijn图优化**：

```python
from collections import defaultdict
import threading

class OptimizedDeBruijnGraph:
    def __init__(self, k=31):
        self.k = k
        self.graph = defaultdict(set)
        self.locks = {}

    def add_kmer(self, kmer):
        """添加k-mer到图中"""
        if kmer not in self.locks:
            self.locks[kmer] = threading.Lock()

        with self.locks[kmer]:
            prefix = kmer[:-1]
            suffix = kmer[1:]
            self.graph[prefix].add(suffix)

    def parallel_build_graph(self, sequences, num_threads=4):
        """并行构建De Bruijn图"""
        import multiprocessing as mp

        def process_chunk(chunk):
            local_graph = OptimizedDeBruijnGraph(self.k)
            for seq in chunk:
                for i in range(len(seq) - self.k + 1):
                    kmer = seq[i:i+self.k]
                    local_graph.add_kmer(kmer)
            return local_graph

        # 分块处理
        chunk_size = len(sequences) // num_threads
        chunks = [sequences[i:i+chunk_size] for i in range(0, len(sequences), chunk_size)]

        # 并行处理
        with mp.Pool(num_threads) as pool:
            results = pool.map(process_chunk, chunks)

        # 合并结果
        for result in results:
            for node, neighbors in result.graph.items():
                self.graph[node].update(neighbors)

    def find_contigs(self):
        """寻找contigs"""
        contigs = []
        visited = set()

        for node in self.graph:
            if node not in visited and self._is_linear_path(node):
                contig = self._extract_linear_path(node)
                contigs.append(contig)
                visited.update(contig)

        return contigs

    def _is_linear_path(self, start_node):
        """检查是否为线性路径"""
        current = start_node
        while current in self.graph and len(self.graph[current]) == 1:
            next_node = list(self.graph[current])[0]
            if next_node in self.graph and len(self.graph[next_node]) == 1:
                current = next_node
            else:
                break
        return True

    def _extract_linear_path(self, start_node):
        """提取线性路径"""
        path = [start_node]
        current = start_node

        while current in self.graph and len(self.graph[current]) == 1:
            next_node = list(self.graph[current])[0]
            path.append(next_node)
            current = next_node

        return path
```

### 15.4.3 蛋白质结构预测优化

**分子动力学模拟优化**：

```python
import numpy as np
from numba import jit, prange

@jit(nopython=True, parallel=True)
def optimized_force_calculation(positions, velocities, forces, masses, box_size):
    """优化的力计算"""
    num_atoms = positions.shape[0]
    cutoff = 2.5  # 截断距离

    # 并行计算力
    for i in prange(num_atoms):
        fx, fy, fz = 0.0, 0.0, 0.0

        for j in range(num_atoms):
            if i != j:
                # 计算距离（周期性边界条件）
                dx = positions[j, 0] - positions[i, 0]
                dy = positions[j, 1] - positions[i, 1]
                dz = positions[j, 2] - positions[i, 2]

                # 最小镜像约定
                if dx > box_size / 2: dx -= box_size
                elif dx < -box_size / 2: dx += box_size
                if dy > box_size / 2: dy -= box_size
                elif dy < -box_size / 2: dy += box_size
                if dz > box_size / 2: dz -= box_size
                elif dz < -box_size / 2: dz += box_size

                r2 = dx*dx + dy*dy + dz*dz

                if r2 < cutoff*cutoff:
                    r = np.sqrt(r2)
                    # Lennard-Jones势能
                    inv_r6 = (1.0 / r) ** 6
                    inv_r12 = inv_r6 * inv_r6
                    force = 24.0 * (2.0 * inv_r12 - inv_r6) / r

                    fx += force * dx / r
                    fy += force * dy / r
                    fz += force * dz / r

        forces[i, 0] = fx
        forces[i, 1] = fy
        forces[i, 2] = fz

@jit(nopython=True)
def velocity_verlet_integrator(positions, velocities, forces, masses, dt):
    """Velocity Verlet积分器"""
    num_atoms = positions.shape[0]

    # 第一步：更新速度（半步）
    for i in range(num_atoms):
        velocities[i, 0] += 0.5 * forces[i, 0] / masses[i] * dt
        velocities[i, 1] += 0.5 * forces[i, 1] / masses[i] * dt
        velocities[i, 2] += 0.5 * forces[i, 2] / masses[i] * dt

    # 第二步：更新位置
    for i in range(num_atoms):
        positions[i, 0] += velocities[i, 0] * dt
        positions[i, 1] += velocities[i, 1] * dt
        positions[i, 2] += velocities[i, 2] * dt

    # 应用周期性边界条件
    box_size = 10.0
    for i in range(num_atoms):
        if positions[i, 0] >= box_size: positions[i, 0] -= box_size
        elif positions[i, 0] < 0: positions[i, 0] += box_size
        if positions[i, 1] >= box_size: positions[i, 1] -= box_size
        elif positions[i, 1] < 0: positions[i, 1] += box_size
        if positions[i, 2] >= box_size: positions[i, 2] -= box_size
        elif positions[i, 2] < 0: positions[i, 2] += box_size

    # 重新计算力
    forces_new = np.zeros_like(forces)
    optimized_force_calculation(positions, velocities, forces_new, masses, box_size)

    # 第三步：更新速度（半步）
    for i in range(num_atoms):
        velocities[i, 0] += 0.5 * forces_new[i, 0] / masses[i] * dt
        velocities[i, 1] += 0.5 * forces_new[i, 1] / masses[i] * dt
        velocities[i, 2] += 0.5 * forces_new[i, 2] / masses[i] * dt

    return positions, velocities, forces_new
```

## 15.5 性能监控与分析

### 15.5.1 性能指标收集

```python
import time
import psutil
import threading
from dataclasses import dataclass
from typing import Dict, List

@dataclass
class PerformanceMetrics:
    """性能指标数据结构"""
    timestamp: float
    cpu_usage: float
    memory_usage: float
    gpu_usage: float
    network_io: Dict
    disk_io: Dict
    execution_time: float

class PerformanceMonitor:
    def __init__(self, interval=1.0):
        self.interval = interval
        self.metrics = []
        self.monitoring = False
        self.thread = None

    def start_monitoring(self):
        """开始性能监控"""
        self.monitoring = True
        self.thread = threading.Thread(target=self._monitor_loop)
        self.thread.start()

    def stop_monitoring(self):
        """停止性能监控"""
        self.monitoring = False
        if self.thread:
            self.thread.join()

    def _monitor_loop(self):
        """监控循环"""
        start_time = time.time()

        while self.monitoring:
            current_time = time.time()

            # 收集系统指标
            cpu_usage = psutil.cpu_percent(interval=None)
            memory_info = psutil.virtual_memory()
            disk_io = psutil.disk_io_counters()
            network_io = psutil.net_io_counters()

            # GPU指标（如果可用）
            try:
                import pynvml
                pynvml.nvmlInit()
                handle = pynvml.nvmlDeviceGetHandleByIndex(0)
                gpu_info = pynvml.nvmlDeviceGetUtilizationRates(handle)
                gpu_usage = gpu_info.gpu
            except:
                gpu_usage = 0.0

            # 计算执行时间
            execution_time = current_time - start_time

            # 存储指标
            metrics = PerformanceMetrics(
                timestamp=current_time,
                cpu_usage=cpu_usage,
                memory_usage=memory_info.percent,
                gpu_usage=gpu_usage,
                network_io={
                    'bytes_sent': network_io.bytes_sent,
                    'bytes_recv': network_io.bytes_recv
                },
                disk_io={
                    'read_bytes': disk_io.read_bytes,
                    'write_bytes': disk_io.write_bytes
                },
                execution_time=execution_time
            )

            self.metrics.append(metrics)
            time.sleep(self.interval)

    def get_performance_report(self):
        """生成性能报告"""
        if not self.metrics:
            return "No metrics collected"

        # 计算统计数据
        cpu_values = [m.cpu_usage for m in self.metrics]
        memory_values = [m.memory_usage for m in self.metrics]
        gpu_values = [m.gpu_usage for m in self.metrics]

        report = f"""
性能监控报告：
==============
总执行时间: {self.metrics[-1].execution_time:.2f} 秒
采样点数: {len(self.metrics)}

CPU使用率:
  平均: {np.mean(cpu_values):.2f}%
  最大: {max(cpu_values):.2f}%
  最小: {min(cpu_values):.2f}%

内存使用率:
  平均: {np.mean(memory_values):.2f}%
  最大: {max(memory_values):.2f}%
  最小: {min(memory_values):.2f}%

GPU使用率:
  平均: {np.mean(gpu_values):.2f}%
  最大: {max(gpu_values):.2f}%
  最小: {min(gpu_values):.2f}%
        """

        return report

def profile_function(func):
    """函数性能分析装饰器"""
    def wrapper(*args, **kwargs):
        start_time = time.perf_counter()
        start_cpu = psutil.cpu_percent(interval=None)
        start_memory = psutil.virtual_memory().used

        result = func(*args, **kwargs)

        end_cpu = psutil.cpu_percent(interval=None)
        end_memory = psutil.virtual_memory().used
        end_time = time.perf_counter()

        print(f"函数 {func.__name__} 执行时间: {end_time - start_time:.4f} 秒")
        print(f"CPU使用率变化: {end_cpu - start_cpu:.2f}%")
        print(f"内存使用变化: {(end_memory - start_memory) / 1024 / 1024:.2f} MB")

        return result

    return wrapper
```

### 15.5.2 瓶颈识别

```python
import cProfile
import pstats
import io
from contextlib import contextmanager

class BottleneckAnalyzer:
    def __init__(self):
        self.profiler = cProfile.Profile()

    @contextmanager
    def profile_section(self, section_name):
        """分析特定代码段"""
        print(f"开始分析: {section_name}")
        self.profiler.enable()

        try:
            yield
        finally:
            self.profiler.disable()
            print(f"完成分析: {section_name}")

    def analyze_bottlenecks(self, sort_by='cumulative', limit=20):
        """分析性能瓶颈"""
        s = io.StringIO()
        ps = pstats.Stats(self.profiler, stream=s).sort_stats(sort_by)
        ps.print_stats(limit)

        return s.getvalue()

    def compare_versions(self, func_v1, func_v2, *args, **kwargs):
        """比较两个版本的性能"""
        # 测试版本1
        profiler1 = cProfile.Profile()
        profiler1.enable()
        result1 = func_v1(*args, **kwargs)
        profiler1.disable()

        # 测试版本2
        profiler2 = cProfile.Profile()
        profiler2.enable()
        result2 = func_v2(*args, **kwargs)
        profiler2.disable()

        # 比较结果
        stats1 = pstats.Stats(profiler1)
        stats2 = pstats.Stats(profiler2)

        print("版本1统计:")
        stats1.sort_stats('cumulative').print_stats(10)

        print("\n版本2统计:")
        stats2.sort_stats('cumulative').print_stats(10)

        # 计算性能提升
        time1 = stats1.total_tt
        time2 = stats2.total_tt
        improvement = (time1 - time2) / time1 * 100

        print(f"\n性能提升: {improvement:.2f}%")

def identify_communication_bottlenecks(comm_pattern):
    """识别通信瓶颈"""
    # 分析通信模式
    send_counts = {}
    recv_counts = {}
    communication_volume = {}

    for pattern in comm_pattern:
        sender = pattern['sender']
        receiver = pattern['receiver']
        size = pattern['size']

        send_counts[sender] = send_counts.get(sender, 0) + 1
        recv_counts[receiver] = recv_counts.get(receiver, 0) + 1
        communication_volume[sender] = communication_volume.get(sender, 0) + size

    # 识别瓶颈
    max_sender = max(send_counts.items(), key=lambda x: x[1])
    max_receiver = max(recv_counts.items(), key=lambda x: x[1])
    max_volume = max(communication_volume.items(), key=lambda x: x[1])

    print(f"发送瓶颈: 进程 {max_sender[0]} 发送 {max_sender[1]} 次")
    print(f"接收瓶颈: 进程 {max_receiver[0]} 接收 {max_receiver[1]} 次")
    print(f"通信量瓶颈: 进程 {max_volume[0]} 传输 {max_volume[1]} 字节")

    return {
        'sender_bottleneck': max_sender,
        'receiver_bottleneck': max_receiver,
        'volume_bottleneck': max_volume
    }
```

## 15.6 优化策略总结

### 15.6.1 优化层次总结

| 优化层次 | 主要目标 | 关键技术 | 工具支持 |
|----------|----------|----------|----------|
| 算法层面 | 降低复杂度 | 分治、动态规划、贪心 | 算法分析工具 |
| 系统层面 | 提高效率 | 编译器优化、库优化 | GCC、BLAS、FFTW |
| 并行层面 | 增强并行性 | 负载均衡、通信优化 | MPI、OpenMP |
| 内存层面 | 改善局部性 | 缓存友好、内存池 | Valgrind、perf |
| 硬件层面 | 利用特性 | SIMD、NUMA感知 | Intel VTune、Nsight |

### 15.6.2 优化检查清单

**算法优化检查**：
- [ ] 是否选择了最优算法？
- [ ] 数据结构是否缓存友好？
- [ ] 是否有不必要的计算？
- [ ] 是否可以使用近似算法？

**系统优化检查**：
- [ ] 编译器优化选项是否合适？
- [ ] 是否使用了优化的数学库？
- [ ] 系统参数是否调优？
- [ ] NUMA配置是否正确？

**并行优化检查**：
- [ ] 负载是否均衡？
- [ ] 通信开销是否最小？
- [ ] 同步点是否必要？
- [ ] 是否有数据竞争？

**性能监控检查**：
- [ ] 是否有性能基线？
- [ ] 关键指标是否监控？
- [ ] 瓶颈是否识别？
- [ ] 优化效果是否验证？

### 15.6.3 最佳实践

**开发阶段**：
1. **原型优先**：先实现正确性，再优化性能
2. **渐进优化**：逐步改进，避免过度优化
3. **测试驱动**：确保优化不破坏功能
4. **文档记录**：记录优化决策和效果

**部署阶段**：
1. **环境适配**：根据硬件配置调整参数
2. **监控告警**：设置性能监控和告警
3. **持续优化**：定期分析性能数据
4. **回滚机制**：保留快速回滚能力

**维护阶段**：
1. **性能回归测试**：防止性能退化
2. **定期评估**：重新评估优化策略
3. **技术更新**：跟踪新技术发展
4. **知识分享**：积累和分享优化经验

通过系统性的优化策略，可以在算法、系统和并行等多个层面显著提升生物信息学应用的性能，为大规模数据分析提供强有力的支持。