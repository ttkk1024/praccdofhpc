# 第三章：并行算法设计

## 目录
- [3.1 并行算法设计原则](#31-并行算法设计原则)
- [3.2 常见并行算法模式](#32-常见并行算法模式)
  - [3.2.1 分治法](#321-分治法)
  - [3.2.2 流水线](#322-流水线)
  - [3.2.3 主从模式](#323-主从模式)
  - [3.2.4 工作窃取](#324-工作窃取)
- [3.3 并行算法性能分析](#33-并行算法性能分析)
- [3.4 并行算法设计实例](#34-并行算法设计实例)
- [3.5 并行算法优化策略](#35-并行算法优化策略)

## 3.1 并行算法设计原则

### 3.1.1 分解（Decomposition）

**概念**：将复杂问题分解为可独立处理的子问题

**分解策略**：
- **数据分解**：将数据集分割给不同处理器
- **功能分解**：将计算任务按功能模块分割
- **递归分解**：递归地将问题分解为更小子问题

**分解原则**：
- 子问题应尽可能独立
- 子问题规模应大致相等
- 分解粒度要适中（太细：通信开销大；太粗：负载不均）

```python
# 数据分解示例：矩阵乘法
def parallel_matrix_multiply(A, B, num_processors):
    # 将矩阵A按行分割
    rows_per_processor = len(A) // num_processors
    results = []

    for i in range(num_processors):
        start_row = i * rows_per_processor
        end_row = (i + 1) * rows_per_processor if i < num_processors - 1 else len(A)
        # 每个处理器处理指定行
        processor_result = multiply_rows(A[start_row:end_row], B)
        results.append(processor_result)

    return combine_results(results)
```

### 3.1.2 通信（Communication）

**概念**：确定子问题间的数据交换需求

**通信模式**：
- **点对点通信**：两个处理器间直接交换数据
- **集体通信**：多个处理器间的协调通信
- **共享内存通信**：通过共享变量交换数据

**通信优化原则**：
- 最小化通信量
- 减少通信次数
- 重叠计算和通信

```c
// MPI点对点通信示例
MPI_Send(data, count, MPI_INT, dest, tag, MPI_COMM_WORLD);
MPI_Recv(buffer, count, MPI_INT, source, tag, MPI_COMM_WORLD, &status);
```

### 3.1.3 同步（Synchronization）

**概念**：协调多个并行任务的执行时序

**同步机制**：
- **屏障同步**：所有进程到达同步点后继续
- **互斥锁**：保护共享资源
- **条件变量**：基于条件的同步
- **信号量**：计数型同步原语

**同步设计原则**：
- 最小化同步点
- 避免死锁
- 减少同步开销

```c
// OpenMP屏障同步
#pragma omp parallel
{
    // 并行计算
    #pragma omp barrier
    // 所有线程到达此处后继续
}
```

### 3.1.4 映射（Mapping）

**概念**：将子问题分配给处理器

**映射策略**：
- **静态映射**：编译时确定任务分配
- **动态映射**：运行时根据负载动态分配
- **自适应映射**：根据性能反馈调整分配

**映射原则**：
- 考虑处理器能力差异
- 优化数据局部性
- 平衡通信开销

## 3.2 常见并行算法模式

### 3.2.1 分治法（Divide and Conquer）

#### 3.2.1.1 基本思想
将问题递归分解为更小的子问题，独立求解后合并结果。

#### 3.2.1.2 算法特征
- **可分解性**：问题可分解为独立子问题
- **可合并性**：子问题解可合并为原问题解
- **递归结构**：自然支持并行递归

#### 3.2.1.3 典型应用

**归并排序并行化**：
```python
def parallel_merge_sort(arr, depth=0, max_depth=3):
    if len(arr) <= 1 or depth >= max_depth:
        return sorted(arr)

    # 分解：将数组分为两部分
    mid = len(arr) // 2
    left_part = arr[:mid]
    right_part = arr[mid:]

    # 并行求解子问题
    if depth < max_depth:
        with ThreadPoolExecutor(max_workers=2) as executor:
            left_future = executor.submit(parallel_merge_sort, left_part, depth + 1, max_depth)
            right_future = executor.submit(parallel_merge_sort, right_part, depth + 1, max_depth)

            left_sorted = left_future.result()
            right_sorted = right_future.result()
    else:
        left_sorted = parallel_merge_sort(left_part, depth + 1, max_depth)
        right_sorted = parallel_merge_sort(right_part, depth + 1, max_depth)

    # 合并：合并两个有序数组
    return merge(left_sorted, right_sorted)
```

**快速排序并行化**：
```c
// OpenMP并行快速排序
void parallel_quicksort(int arr[], int low, int high) {
    if (low < high) {
        int pivot = partition(arr, low, high);

        #pragma omp parallel sections
        {
            #pragma omp section
            {
                parallel_quicksort(arr, low, pivot - 1);
            }
            #pragma omp section
            {
                parallel_quicksort(arr, pivot + 1, high);
            }
        }
    }
}
```

**矩阵乘法分治**（Strassen算法）：
```python
def strassen_parallel_multiply(A, B, threshold=64):
    n = len(A)

    if n <= threshold:
        return standard_matrix_multiply(A, B)

    # 分解矩阵为4个子矩阵
    mid = n // 2
    A11, A12, A21, A22 = split_matrix(A, mid)
    B11, B12, B21, B22 = split_matrix(B, mid)

    # 计算7个乘积
    with ThreadPoolExecutor(max_workers=7) as executor:
        M1_future = executor.submit(strassen_parallel_multiply,
                                   add_matrices(A11, A22), add_matrices(B11, B22))
        M2_future = executor.submit(strassen_parallel_multiply,
                                   add_matrices(A21, A22), B11)
        M3_future = executor.submit(strassen_parallel_multiply,
                                   A11, subtract_matrices(B12, B22))
        M4_future = executor.submit(strassen_parallel_multiply,
                                   A22, subtract_matrices(B21, B11))
        M5_future = executor.submit(strassen_parallel_multiply,
                                   add_matrices(A11, A12), B22)
        M6_future = executor.submit(strassen_parallel_multiply,
                                   subtract_matrices(A21, A11), add_matrices(B11, B12))
        M7_future = executor.submit(strassen_parallel_multiply,
                                   subtract_matrices(A12, A22), add_matrices(B21, B22))

        M1, M2, M3, M4, M5, M6, M7 = (
            M1_future.result(), M2_future.result(), M3_future.result(),
            M4_future.result(), M5_future.result(), M6_future.result(), M7_future.result()
        )

    # 合并结果
    C11 = add_matrices(subtract_matrices(add_matrices(M1, M4), M5), M7)
    C12 = add_matrices(M3, M5)
    C21 = add_matrices(M2, M4)
    C22 = add_matrices(subtract_matrices(add_matrices(M1, M3), M2), M6)

    return combine_matrices(C11, C12, C21, C22)
```

#### 3.2.1.4 性能分析
- **理论加速比**：理想情况下可达 O(log n)
- **实际限制**：递归深度、通信开销
- **适用场景**：问题规模大、子问题独立性强

### 3.2.2 流水线（Pipeline）

#### 3.2.2.1 基本思想
将计算分解为多个阶段，数据流经各个阶段进行处理。

#### 3.2.2.2 流水线结构
```
Stage 1 → Stage 2 → Stage 3 → ... → Stage k
   ↓         ↓         ↓               ↓
  Data → Processed → Further → Final
  Input   Data      Processed   Output
                    Data
```

#### 3.2.2.3 典型应用

**图像处理流水线**：
```python
import multiprocessing as mp
from queue import Queue

def image_processing_pipeline(image_data, num_stages=4):
    # 创建阶段间队列
    queues = [Queue() for _ in range(num_stages)]

    def stage_1_process():
        for image in image_data:
            processed = preprocess_image(image)
            queues[0].put(processed)
        queues[0].put(None)  # 标记结束

    def stage_2_process():
        while True:
            data = queues[0].get()
            if data is None:
                queues[1].put(None)
                break
            processed = enhance_image(data)
            queues[1].put(processed)

    def stage_3_process():
        while True:
            data = queues[1].get()
            if data is None:
                queues[2].put(None)
                break
            processed = detect_features(data)
            queues[2].put(processed)

    def stage_4_process():
        results = []
        while True:
            data = queues[2].get()
            if data is None:
                break
            result = analyze_features(data)
            results.append(result)
        return results

    # 启动各阶段进程
    p1 = mp.Process(target=stage_1_process)
    p2 = mp.Process(target=stage_2_process)
    p3 = mp.Process(target=stage_3_process)

    p1.start()
    p2.start()
    p3.start()

    # 主进程处理最后阶段
    final_results = stage_4_process()

    p1.join()
    p2.join()
    p3.join()

    return final_results
```

**编译器优化流水线**：
```c
// MPI流水线编译器示例
void compiler_pipeline(char* source_code) {
    int rank, size;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    char* intermediate_code;

    // 阶段1：词法分析
    if (rank == 0) {
        intermediate_code = lexical_analysis(source_code);
        MPI_Send(intermediate_code, strlen(intermediate_code) + 1, MPI_CHAR, 1, 0, MPI_COMM_WORLD);
    }

    // 阶段2：语法分析
    if (rank == 1) {
        char buffer[10000];
        MPI_Recv(buffer, sizeof(buffer), MPI_CHAR, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);
        intermediate_code = syntax_analysis(buffer);
        MPI_Send(intermediate_code, strlen(intermediate_code) + 1, MPI_CHAR, 2, 0, MPI_COMM_WORLD);
    }

    // 阶段3：语义分析
    if (rank == 2) {
        char buffer[10000];
        MPI_Recv(buffer, sizeof(buffer), MPI_CHAR, 1, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);
        intermediate_code = semantic_analysis(buffer);
        MPI_Send(intermediate_code, strlen(intermediate_code) + 1, MPI_CHAR, 3, 0, MPI_COMM_WORLD);
    }

    // 阶段4：代码生成
    if (rank == 3) {
        char buffer[10000];
        MPI_Recv(buffer, sizeof(buffer), MPI_CHAR, 2, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);
        char* final_code = code_generation(buffer);
        printf("Generated code: %s\n", final_code);
    }
}
```

**数据流处理流水线**：
```python
import asyncio

class DataPipeline:
    def __init__(self, stages):
        self.stages = stages
        self.queues = [asyncio.Queue() for _ in range(len(stages))]

    async def run_stage(self, stage_id):
        stage_func = self.stages[stage_id]
        input_queue = self.queues[stage_id - 1] if stage_id > 0 else None
        output_queue = self.queues[stage_id] if stage_id < len(self.stages) - 1 else None

        while True:
            if input_queue:
                data = await input_queue.get()
                if data is None:  # 结束信号
                    if output_queue:
                        await output_queue.put(None)
                    break

            if stage_id == 0:  # 第一阶段，从外部获取数据
                data = await self.get_external_data()

            # 执行阶段处理
            result = await stage_func(data)

            if output_queue:
                await output_queue.put(result)

    async def run(self):
        tasks = []
        for i in range(len(self.stages)):
            task = asyncio.create_task(self.run_stage(i))
            tasks.append(task)

        await asyncio.gather(*tasks)
```

#### 3.2.2.4 性能特征
- **吞吐量提升**：多个数据项同时在不同阶段处理
- **延迟**：单个数据项的处理时间可能增加
- **资源利用**：各阶段可并行执行，提高资源利用率

### 3.2.3 主从模式（Master-Slave）

#### 3.2.3.1 基本思想
一个主进程协调多个工作进程，分配任务并收集结果。

#### 3.2.3.2 架构特点
```
    Master Process
         ↓
    Task Distribution
    ↓    ↓    ↓    ↓
  Slave  Slave  Slave  Slave
    ↓      ↓      ↓      ↓
  Process Process Process Process
    ↓      ↓      ↓      ↓
  Result Result Result Result
    ↓      ↓      ↓      ↓
    Result Collection (Master)
```

#### 3.2.3.3 典型应用

**Web服务器主从模式**：
```python
import socket
import multiprocessing as mp
import os

def worker_process(worker_id, task_queue, result_queue):
    """工作进程：处理HTTP请求"""
    while True:
        try:
            # 从队列获取任务
            client_socket, client_address = task_queue.get(timeout=1)

            if client_socket is None:  # 结束信号
                break

            # 处理请求
            request = client_socket.recv(1024).decode()
            response = process_request(request)

            # 发送响应
            client_socket.send(response.encode())
            client_socket.close()

            # 记录结果
            result_queue.put(f"Worker {worker_id}: Processed request from {client_address}")

        except:
            continue

def master_process():
    """主进程：接收连接并分发给工作进程"""
    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    server_socket.bind(('localhost', 8080))
    server_socket.listen(5)

    # 创建任务队列和结果队列
    task_queue = mp.Queue()
    result_queue = mp.Queue()

    # 启动工作进程
    num_workers = 4
    workers = []
    for i in range(num_workers):
        p = mp.Process(target=worker_process, args=(i, task_queue, result_queue))
        p.start()
        workers.append(p)

    try:
        while True:
            # 接受新连接
            client_socket, client_address = server_socket.accept()
            print(f"New connection from {client_address}")

            # 分发任务给工作进程
            task_queue.put((client_socket, client_address))

            # 检查结果
            try:
                result = result_queue.get_nowait()
                print(result)
            except:
                pass

    except KeyboardInterrupt:
        print("Shutting down server...")

    finally:
        # 发送结束信号
        for _ in range(num_workers):
            task_queue.put((None, None))

        # 等待工作进程结束
        for p in workers:
            p.join()

        server_socket.close()
```

**分布式计算主从模式**：
```c
// MPI主从模式示例：计算π的近似值
#define MASTER 0
#define SLAVE 1

void master_process(int num_slaves, int num_intervals) {
    int intervals_per_slave = num_intervals / num_slaves;
    double pi = 0.0;
    double local_pi;

    // 分发任务给从进程
    for (int slave = 1; slave <= num_slaves; slave++) {
        int start = (slave - 1) * intervals_per_slave;
        int end = (slave == num_slaves) ? num_intervals : slave * intervals_per_slave;

        MPI_Send(&start, 1, MPI_INT, slave, 1, MPI_COMM_WORLD);
        MPI_Send(&end, 1, MPI_INT, slave, 2, MPI_COMM_WORLD);
    }

    // 收集结果
    for (int slave = 1; slave <= num_slaves; slave++) {
        MPI_Recv(&local_pi, 1, MPI_DOUBLE, slave, 3, MPI_COMM_WORLD, MPI_STATUS_IGNORE);
        pi += local_pi;
    }

    printf("Estimated value of π: %f\n", pi * 4.0);
}

void slave_process() {
    int start, end;
    double local_pi = 0.0;

    // 接收任务
    MPI_Recv(&start, 1, MPI_INT, MASTER, 1, MPI_COMM_WORLD, MPI_STATUS_IGNORE);
    MPI_Recv(&end, 1, MPI_INT, MASTER, 2, MPI_COMM_WORLD, MPI_STATUS_IGNORE);

    // 计算局部π值（使用数值积分）
    double step = 1.0 / 1000000.0;  // 步长
    for (int i = start; i < end; i++) {
        double x = (i + 0.5) * step;
        local_pi += 4.0 / (1.0 + x * x);
    }
    local_pi *= step;

    // 发送结果给主进程
    MPI_Send(&local_pi, 1, MPI_DOUBLE, MASTER, 3, MPI_COMM_WORLD);
}
```

**任务调度系统**：
```python
import threading
import queue
import time
from concurrent.futures import ThreadPoolExecutor

class TaskScheduler:
    def __init__(self, num_workers=4):
        self.task_queue = queue.Queue()
        self.result_queue = queue.Queue()
        self.workers = []
        self.num_workers = num_workers
        self.stop_event = threading.Event()

    def worker(self, worker_id):
        """工作线程：执行任务"""
        while not self.stop_event.is_set():
            try:
                # 获取任务
                task = self.task_queue.get(timeout=1)
                if task is None:  # 结束信号
                    break

                # 执行任务
                result = self.execute_task(task)

                # 存储结果
                self.result_queue.put((worker_id, result))
                self.task_queue.task_done()

            except queue.Empty:
                continue

    def execute_task(self, task):
        """执行具体任务"""
        # 模拟任务执行
        time.sleep(0.1)
        return f"Result of {task}"

    def submit_task(self, task):
        """提交任务"""
        self.task_queue.put(task)

    def start(self):
        """启动调度器"""
        # 启动工作线程
        for i in range(self.num_workers):
            t = threading.Thread(target=self.worker, args=(i,))
            t.start()
            self.workers.append(t)

    def stop(self):
        """停止调度器"""
        # 发送结束信号
        for _ in range(self.num_workers):
            self.task_queue.put(None)

        # 等待工作线程结束
        for t in self.workers:
            t.join()

    def get_results(self):
        """获取所有结果"""
        results = []
        while not self.result_queue.empty():
            results.append(self.result_queue.get())
        return results
```

#### 3.2.3.4 优缺点分析
**优点**：
- 简单直观，易于实现
- 负载分配灵活
- 容错性好

**缺点**：
- 主进程可能成为瓶颈
- 通信开销较大
- 扩展性受限

### 3.2.4 工作窃取（Work Stealing）

#### 3.2.4.1 基本思想
空闲的处理器从忙碌的处理器"窃取"任务来执行。

#### 3.2.4.2 工作原理
```
Processor 1: [Task1, Task2, Task3, Task4]  ← 忙碌
Processor 2: []                            ← 空闲
Processor 3: [Task5, Task6]                ← 忙碌

Processor 2 窃取 Processor 1 的一半任务：
Processor 1: [Task1, Task2]
Processor 2: [Task3, Task4]
Processor 3: [Task5, Task6]
```

#### 3.2.4.3 实现机制

**双端队列（Deque）实现**：
```python
import threading
import queue
from collections import deque

class WorkStealingScheduler:
    def __init__(self, num_processors):
        self.num_processors = num_processors
        self.deques = [deque() for _ in range(num_processors)]
        self.locks = [threading.Lock() for _ in range(num_processors)]
        self.stop_event = threading.Event()

    def submit_task(self, task, processor_id=None):
        """提交任务到指定处理器或随机处理器"""
        if processor_id is None:
            processor_id = hash(task) % self.num_processors

        with self.locks[processor_id]:
            self.deques[processor_id].append(task)

    def get_task(self, processor_id):
        """获取任务：优先从本地队列获取，然后尝试窃取"""
        # 1. 从本地队列获取（LIFO）
        with self.locks[processor_id]:
            if self.deques[processor_id]:
                return self.deques[processor_id].pop()

        # 2. 尝试窃取其他处理器的任务（FIFO）
        for i in range(self.num_processors):
            if i != processor_id:
                with self.locks[i]:
                    if self.deques[i]:
                        # 窃取队列头部的任务
                        return self.deques[i].popleft()

        return None

    def worker(self, processor_id):
        """工作线程"""
        while not self.stop_event.is_set():
            # 获取任务
            task = self.get_task(processor_id)

            if task is None:
                # 没有任务，短暂休眠
                time.sleep(0.01)
                continue

            # 执行任务
            try:
                result = self.execute_task(task)
                self.process_result(result)
            except Exception as e:
                print(f"Error executing task: {e}")

    def execute_task(self, task):
        """执行任务"""
        # 模拟任务执行
        time.sleep(0.1)
        return f"Result of {task}"

    def process_result(self, result):
        """处理结果"""
        pass

    def start(self):
        """启动调度器"""
        self.workers = []
        for i in range(self.num_processors):
            t = threading.Thread(target=self.worker, args=(i,))
            t.start()
            self.workers.append(t)

    def stop(self):
        """停止调度器"""
        self.stop_event.set()
        for t in self.workers:
            t.join()
```

**递归工作窃取**：
```python
import threading
import random

class RecursiveWorkStealing:
    def __init__(self, num_processors=4):
        self.num_processors = num_processors
        self.queues = [[] for _ in range(num_processors)]
        self.locks = [threading.Lock() for _ in range(num_processors)]
        self.stop_event = threading.Event()

    def divide_and_conquer(self, problem, processor_id):
        """递归分治算法"""
        if self.is_base_case(problem):
            return self.solve_base_case(problem)

        # 分解问题
        subproblems = self.decompose_problem(problem)

        results = []
        for i, subproblem in enumerate(subproblems):
            if i == len(subproblems) - 1:
                # 最后一个子问题在当前线程处理
                result = self.divide_and_conquer(subproblem, processor_id)
                results.append(result)
            else:
                # 其他子问题放入队列等待处理
                target_processor = (processor_id + 1) % self.num_processors
                with self.locks[target_processor]:
                    self.queues[target_processor].append(subproblem)

        # 处理队列中的任务
        while True:
            task = self.get_task(processor_id)
            if task is None:
                break
            result = self.divide_and_conquer(task, processor_id)
            results.append(result)

        return self.combine_results(results)

    def get_task(self, processor_id):
        """获取任务（工作窃取）"""
        # 1. 从本地队列获取
        with self.locks[processor_id]:
            if self.queues[processor_id]:
                return self.queues[processor_id].pop(0)

        # 2. 尝试窃取
        for _ in range(self.num_processors):
            victim = random.randint(0, self.num_processors - 1)
            if victim != processor_id:
                with self.locks[victim]:
                    if self.queues[victim]:
                        return self.queues[victim].pop(0)

        return None

    def is_base_case(self, problem):
        """判断是否为基础情况"""
        return len(problem) <= 10

    def solve_base_case(self, problem):
        """解决基础情况"""
        return sum(problem)

    def decompose_problem(self, problem):
        """分解问题"""
        mid = len(problem) // 2
        return [problem[:mid], problem[mid:]]

    def combine_results(self, results):
        """合并结果"""
        return sum(results)
```

#### 3.2.4.4 应用场景
- **递归算法**：快速排序、归并排序、分治算法
- **动态负载均衡**：任务执行时间不确定的场景
- **任务图执行**：DAG（有向无环图）中的任务调度

#### 3.2.4.5 性能特征
- **负载均衡**：自动平衡各处理器负载
- **容错性**：单个处理器故障不影响整体
- **扩展性**：易于扩展到更多处理器

## 3.3 并行算法性能分析

### 3.3.1 性能度量指标

#### 3.3.1.1 加速比（Speedup）
```math
S_p = T_1 / T_p
```
其中：
- S_p：使用p个处理器的加速比
- T_1：串行执行时间
- T_p：并行执行时间

#### 3.3.1.2 效率（Efficiency）
```math
E_p = S_p / p = T_1 / (p * T_p)
```

#### 3.3.1.3 执行时间分解
```math
T_p = T_{comp} + T_{comm} + T_{sync} + T_{idle}
```
其中：
- T_comp：计算时间
- T_comm：通信时间
- T_sync：同步时间
- T_idle：空闲时间

### 3.3.2 理论模型

#### 3.3.2.1 Amdahl定律
```math
S_p = 1 / (s + p / p)
```
其中s是串行部分的比例。

**含义**：并行加速比受限于串行部分。

```python
def amdhals_law(serial_fraction, num_processors):
    """计算Amdahl定律的理论加速比"""
    return 1 / (serial_fraction + (1 - serial_fraction) / num_processors)

# 示例：90%并行化，10%串行
serial_fraction = 0.1
processors = [1, 2, 4, 8, 16, 32, 64]
speedups = [amdhals_law(serial_fraction, p) for p in processors]

for p, s in zip(processors, speedups):
    print(f"Processors: {p}, Speedup: {s:.2f}, Efficiency: {s/p:.2%}")
```

#### 3.3.2.2 Gustafson定律
```math
S_p = p + (1 - p) * s
```
其中s是串行部分的比例。

**含义**：问题规模随处理器数量增加时的加速比。

```python
def gustafsons_law(serial_fraction, num_processors):
    """计算Gustafson定律的理论加速比"""
    return num_processors + (1 - num_processors) * serial_fraction

# 示例：固定问题规模 vs 可扩展问题规模
serial_fraction = 0.1
processors = [1, 2, 4, 8, 16, 32, 64]

print("Amdahl vs Gustafson Speedup Comparison:")
for p in processors:
    amdhals = amdhals_law(serial_fraction, p)
    gustafsons = gustafsons_law(serial_fraction, p)
    print(f"P={p}: Amdahl={amdhals:.2f}, Gustafson={gustafsons:.2f}")
```

### 3.3.3 性能分析工具

#### 3.3.3.1 Python性能分析
```python
import time
import psutil
import threading
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor

class PerformanceAnalyzer:
    def __init__(self):
        self.start_time = 0
        self.end_time = 0
        self.cpu_usage = []
        self.memory_usage = []

    def start_monitoring(self):
        """开始性能监控"""
        self.start_time = time.time()
        self.monitoring = True

        def monitor():
            while self.monitoring:
                self.cpu_usage.append(psutil.cpu_percent())
                self.memory_usage.append(psutil.virtual_memory().percent)
                time.sleep(0.1)

        self.monitor_thread = threading.Thread(target=monitor)
        self.monitor_thread.start()

    def stop_monitoring(self):
        """停止性能监控"""
        self.monitoring = False
        self.monitor_thread.join()
        self.end_time = time.time()

    def get_performance_metrics(self):
        """获取性能指标"""
        execution_time = self.end_time - self.start_time
        avg_cpu = sum(self.cpu_usage) / len(self.cpu_usage) if self.cpu_usage else 0
        max_memory = max(self.memory_usage) if self.memory_usage else 0

        return {
            'execution_time': execution_time,
            'avg_cpu_usage': avg_cpu,
            'max_memory_usage': max_memory,
            'cpu_samples': self.cpu_usage,
            'memory_samples': self.memory_usage
        }

# 使用示例
def parallel_task(n):
    """模拟并行任务"""
    result = 0
    for i in range(n):
        result += i * i
    return result

# 分析并行性能
analyzer = PerformanceAnalyzer()
analyzer.start_monitoring()

with ThreadPoolExecutor(max_workers=4) as executor:
    futures = [executor.submit(parallel_task, 1000000) for _ in range(4)]
    results = [f.result() for f in futures]

analyzer.stop_monitoring()
metrics = analyzer.get_performance_metrics()

print(f"Execution Time: {metrics['execution_time']:.2f}s")
print(f"Average CPU Usage: {metrics['avg_cpu_usage']:.1f}%")
print(f"Maximum Memory Usage: {metrics['max_memory_usage']:.1f}%")
```

#### 3.3.3.2 MPI性能分析
```c
#include <mpi.h>
#include <stdio.h>
#include <time.h>

void analyze_mpi_performance() {
    int rank, size;
    double start_time, end_time, total_time;
    double local_compute_time, communication_time;

    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    // 记录开始时间
    MPI_Barrier(MPI_COMM_WORLD);
    start_time = MPI_Wtime();

    // 模拟计算
    local_compute_time = 0.0;
    for (int i = 0; i < 1000000; i++) {
        local_compute_time += i * i;
    }

    // 通信操作
    double global_result;
    MPI_Allreduce(&local_compute_time, &global_result, 1, MPI_DOUBLE, MPI_SUM, MPI_COMM_WORLD);

    // 记录结束时间
    end_time = MPI_Wtime();
    total_time = end_time - start_time;

    // 输出性能数据
    if (rank == 0) {
        printf("MPI Performance Analysis:\n");
        printf("Total time: %f seconds\n", total_time);
        printf("Number of processes: %d\n", size);
        printf("Global result: %f\n", global_result);
    }
}
```

### 3.3.4 性能瓶颈识别

#### 3.3.4.1 通信瓶颈
```python
import time
import numpy as np
from mpi4py import MPI

def analyze_communication_bottleneck():
    """分析通信瓶颈"""
    comm = MPI.COMM_WORLD
    rank = comm.Get_rank()
    size = comm.Get_size()

    # 测试不同数据大小的通信时间
    data_sizes = [1024, 10240, 102400, 1024000]
    communication_times = []

    for size_bytes in data_sizes:
        data = np.random.rand(size_bytes // 8)  # 假设double类型

        # 同步所有进程
        comm.Barrier()

        # 测量通信时间
        start_time = time.time()
        if rank == 0:
            # 主进程发送数据给所有其他进程
            for i in range(1, size):
                comm.Send(data, dest=i, tag=1)
        else:
            # 其他进程接收数据
            received_data = np.empty_like(data)
            comm.Recv(received_data, source=0, tag=1)

        comm.Barrier()
        end_time = time.time()

        communication_times.append(end_time - start_time)

        if rank == 0:
            print(f"Data size: {size_bytes} bytes, Communication time: {end_time - start_time:.4f}s")

    return communication_times
```

#### 3.3.4.2 负载不均衡分析
```python
import time
import threading
from concurrent.futures import ThreadPoolExecutor

def analyze_load_imbalance():
    """分析负载不均衡"""
    def task_with_variable_work(task_id):
        """模拟工作量不均衡的任务"""
        # 任务工作量随机，模拟真实场景
        work_amount = (task_id % 10) * 100000
        start_time = time.time()

        result = 0
        for i in range(work_amount):
            result += i * i

        end_time = time.time()
        return {
            'task_id': task_id,
            'work_amount': work_amount,
            'execution_time': end_time - start_time
        }

    # 使用不同数量的线程执行任务
    thread_counts = [2, 4, 8]
    results = {}

    for num_threads in thread_counts:
        start_time = time.time()

        with ThreadPoolExecutor(max_workers=num_threads) as executor:
            futures = [executor.submit(task_with_variable_work, i) for i in range(20)]
            task_results = [f.result() for f in futures]

        end_time = time.time()
        total_time = end_time - start_time

        # 分析负载分布
        execution_times = [r['execution_time'] for r in task_results]
        min_time = min(execution_times)
        max_time = max(execution_times)
        avg_time = sum(execution_times) / len(execution_times)

        load_imbalance = (max_time - min_time) / avg_time

        results[num_threads] = {
            'total_time': total_time,
            'min_execution_time': min_time,
            'max_execution_time': max_time,
            'avg_execution_time': avg_time,
            'load_imbalance': load_imbalance
        }

        print(f"Threads: {num_threads}")
        print(f"  Total time: {total_time:.4f}s")
        print(f"  Load imbalance: {load_imbalance:.2%}")
        print()

    return results
```

## 3.4 并行算法设计实例

### 3.4.1 并行排序算法

#### 3.4.1.1 并行归并排序
```python
import multiprocessing as mp
from functools import partial

def merge(left, right):
    """合并两个有序数组"""
    result = []
    i = j = 0

    while i < len(left) and j < len(right):
        if left[i] <= right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1

    result.extend(left[i:])
    result.extend(right[j:])
    return result

def parallel_merge_sort(arr, max_depth=3):
    """并行归并排序"""
    if len(arr) <= 1:
        return arr

    if max_depth <= 0:
        return sorted(arr)

    # 分解
    mid = len(arr) // 2
    left_half = arr[:mid]
    right_half = arr[mid:]

    # 并行排序子数组
    with mp.Pool(processes=2) as pool:
        left_sorted = pool.apply_async(parallel_merge_sort, (left_half, max_depth - 1))
        right_sorted = pool.apply_async(parallel_merge_sort, (right_half, max_depth - 1))

        left_result = left_sorted.get()
        right_result = right_sorted.get()

    # 合并
    return merge(left_result, right_result)
```

#### 3.4.1.2 并行快速排序
```c
#include <omp.h>
#include <stdio.h>

void parallel_quicksort(int arr[], int low, int high) {
    if (low < high) {
        int pivot = partition(arr, low, high);

        #pragma omp parallel sections
        {
            #pragma omp section
            {
                parallel_quicksort(arr, low, pivot - 1);
            }
            #pragma omp section
            {
                parallel_quicksort(arr, pivot + 1, high);
            }
        }
    }
}

int partition(int arr[], int low, int high) {
    int pivot = arr[high];
    int i = low - 1;

    for (int j = low; j < high; j++) {
        if (arr[j] <= pivot) {
            i++;
            swap(&arr[i], &arr[j]);
        }
    }
    swap(&arr[i + 1], &arr[high]);
    return i + 1;
}
```

### 3.4.2 并行搜索算法

#### 3.4.2.1 并行二分搜索
```python
import multiprocessing as mp
import math

def parallel_binary_search(arr, target, start_idx, end_idx):
    """在指定范围内进行二分搜索"""
    left, right = start_idx, end_idx - 1

    while left <= right:
        mid = (left + right) // 2
        if arr[mid] == target:
            return mid
        elif arr[mid] < target:
            left = mid + 1
        else:
            right = mid - 1

    return -1

def parallel_search(arr, target, num_processes=None):
    """并行搜索数组中的目标值"""
    if num_processes is None:
        num_processes = mp.cpu_count()

    n = len(arr)
    chunk_size = math.ceil(n / num_processes)

    # 创建进程池
    with mp.Pool(processes=num_processes) as pool:
        # 分配搜索任务
        tasks = []
        for i in range(num_processes):
            start = i * chunk_size
            end = min((i + 1) * chunk_size, n)
            if start < n:
                tasks.append((arr, target, start, end))

        # 并行执行搜索
        results = pool.starmap(parallel_binary_search, tasks)

        # 检查结果
        for result in results:
            if result != -1:
                return result

    return -1
```

#### 3.4.2.2 并行图搜索
```python
from collections import deque
import multiprocessing as mp
import threading

class ParallelBFS:
    def __init__(self, graph):
        self.graph = graph
        self.num_processors = mp.cpu_count()
        self.visited = set()
        self.lock = threading.Lock()

    def parallel_bfs(self, start_node, target_node):
        """并行广度优先搜索"""
        if start_node == target_node:
            return [start_node]

        # 初始化队列
        queues = [deque() for _ in range(self.num_processors)]
        queues[0].append((start_node, [start_node]))

        with self.lock:
            self.visited.add(start_node)

        # 并行搜索
        with mp.Pool(processes=self.num_processors) as pool:
            while any(queue for queue in queues):
                # 收集当前层的所有节点
                current_level = []
                for queue in queues:
                    while queue:
                        node, path = queue.popleft()
                        current_level.append((node, path))

                if not current_level:
                    break

                # 并行处理当前层
                results = pool.map(self.process_level, current_level)

                # 处理结果
                for result in results:
                    if result is not None:
                        return result

        return None

    def process_level(self, node_path):
        """处理一层的节点"""
        node, path = node_path

        for neighbor in self.graph[node]:
            with self.lock:
                if neighbor not in self.visited:
                    self.visited.add(neighbor)

                    if neighbor == target_node:
                        return path + [neighbor]

        return None
```

### 3.4.3 并行数值计算

#### 3.4.3.1 并行矩阵乘法
```python
import numpy as np
import multiprocessing as mp
from concurrent.futures import ProcessPoolExecutor

def multiply_block(args):
    """计算矩阵块乘法"""
    A_block, B_block = args
    return np.dot(A_block, B_block)

def parallel_matrix_multiply(A, B, block_size=100):
    """并行矩阵乘法"""
    m, n = A.shape
    n, p = B.shape

    # 分块
    blocks = []
    for i in range(0, m, block_size):
        for j in range(0, p, block_size):
            for k in range(0, n, block_size):
                A_block = A[i:i+block_size, k:k+block_size]
                B_block = B[k:k+block_size, j:j+block_size]
                blocks.append((A_block, B_block))

    # 并行计算
    with ProcessPoolExecutor() as executor:
        results = list(executor.map(multiply_block, blocks))

    # 合并结果
    C = np.zeros((m, p))
    result_idx = 0

    for i in range(0, m, block_size):
        for j in range(0, p, block_size):
            for k in range(0, n, block_size):
                C_block = results[result_idx]
                C[i:i+block_size, j:j+block_size] += C_block
                result_idx += 1

    return C
```

#### 3.4.3.2 并行数值积分
```python
import multiprocessing as mp
import math

def integrate_function(args):
    """数值积分函数"""
    func, a, b, num_intervals = args
    h = (b - a) / num_intervals
    result = 0.0

    for i in range(num_intervals):
        x = a + i * h
        result += func(x)

    return result * h

def parallel_integration(func, a, b, num_intervals=1000000, num_processes=None):
    """并行数值积分"""
    if num_processes is None:
        num_processes = mp.cpu_count()

    # 分割积分区间
    intervals_per_process = num_intervals // num_processes
    tasks = []

    for i in range(num_processes):
        start = a + i * intervals_per_process * (b - a) / num_intervals
        end = a + (i + 1) * intervals_per_process * (b - a) / num_intervals
        actual_intervals = intervals_per_process

        if i == num_processes - 1:
            # 最后一个进程处理剩余的区间
            actual_intervals = num_intervals - i * intervals_per_process

        tasks.append((func, start, end, actual_intervals))

    # 并行计算
    with mp.Pool(processes=num_processes) as pool:
        results = pool.map(integrate_function, tasks)

    return sum(results)

# 使用示例
def f(x):
    return math.sin(x)

result = parallel_integration(f, 0, math.pi, 1000000)
print(f"Integral of sin(x) from 0 to π: {result}")
```

#### 3.4.3.3 并行蒙特卡洛模拟
```python
import random
import multiprocessing as mp
import math

def monte_carlo_pi(args):
    """蒙特卡洛π计算"""
    num_samples, seed = args
    random.seed(seed)

    inside_circle = 0
    for _ in range(num_samples):
        x, y = random.random(), random.random()
        if x*x + y*y <= 1:
            inside_circle += 1

    return inside_circle

def parallel_monte_carlo_pi(num_samples=10000000, num_processes=None):
    """并行蒙特卡洛π计算"""
    if num_processes is None:
        num_processes = mp.cpu_count()

    samples_per_process = num_samples // num_processes
    tasks = [(samples_per_process, i) for i in range(num_processes)]

    # 并行计算
    with mp.Pool(processes=num_processes) as pool:
        results = pool.map(monte_carlo_pi, tasks)

    total_inside = sum(results)
    pi_estimate = 4.0 * total_inside / num_samples

    return pi_estimate

# 使用示例
pi = parallel_monte_carlo_pi(10000000)
print(f"Estimated π: {pi}")
```

### 3.4.4 并行图算法

#### 3.4.4.1 并行Dijkstra算法
```python
import heapq
import multiprocessing as mp
from concurrent.futures import ProcessPoolExecutor

def parallel_dijkstra(graph, start):
    """并行Dijkstra算法"""
    n = len(graph)
    distances = [float('inf')] * n
    distances[start] = 0
    visited = [False] * n

    # 使用优先队列
    pq = [(0, start)]

    while pq:
        current_dist, u = heapq.heappop(pq)

        if visited[u]:
            continue

        visited[u] = True

        # 并行处理邻居节点
        neighbors = [(v, weight) for v, weight in graph[u] if not visited[v]]

        if neighbors:
            with ProcessPoolExecutor() as executor:
                # 并行更新距离
                tasks = [(u, v, weight, distances[u]) for v, weight in neighbors]
                results = list(executor.map(update_distance, tasks))

                for v, new_dist in results:
                    if new_dist < distances[v]:
                        distances[v] = new_dist
                        heapq.heappush(pq, (new_dist, v))

    return distances

def update_distance(args):
    """更新距离"""
    u, v, weight, dist_u = args
    return v, dist_u + weight
```

#### 3.4.4.2 并行图着色
```python
import multiprocessing as mp
from concurrent.futures import ProcessPoolExecutor

def parallel_graph_coloring(graph, num_colors):
    """并行图着色算法"""
    n = len(graph)
    colors = [-1] * n

    # 并行处理每个顶点
    vertices = list(range(n))

    with ProcessPoolExecutor() as executor:
        # 使用贪心算法为每个顶点分配颜色
        tasks = [(vertex, graph, colors, num_colors) for vertex in vertices]
        results = list(executor.map(assign_color, tasks))

    for vertex, color in results:
        colors[vertex] = color

    return colors

def assign_color(args):
    """为顶点分配颜色"""
    vertex, graph, colors, num_colors = args

    # 检查邻居使用的颜色
    used_colors = set()
    for neighbor in graph[vertex]:
        if colors[neighbor] != -1:
            used_colors.add(colors[neighbor])

    # 选择最小的可用颜色
    for color in range(num_colors):
        if color not in used_colors:
            return vertex, color

    return vertex, -1  # 无法着色
```

## 3.5 并行算法优化策略

### 3.5.1 负载均衡优化

#### 3.5.1.1 动态负载均衡
```python
import threading
import queue
import time
from concurrent.futures import ThreadPoolExecutor

class DynamicLoadBalancer:
    def __init__(self, num_workers):
        self.num_workers = num_workers
        self.task_queue = queue.Queue()
        self.worker_loads = [0] * num_workers
        self.workers = []
        self.stop_event = threading.Event()

    def worker(self, worker_id):
        """工作线程"""
        while not self.stop_event.is_set():
            try:
                # 获取任务
                task = self.task_queue.get(timeout=1)

                if task is None:
                    break

                # 更新负载
                self.worker_loads[worker_id] += task.weight

                # 执行任务
                result = self.execute_task(task)

                # 完成任务
                self.task_queue.task_done()
                self.worker_loads[worker_id] -= task.weight

            except queue.Empty:
                # 检查是否需要转移任务
                self.balance_load(worker_id)

    def balance_load(self, worker_id):
        """负载均衡"""
        current_load = self.worker_loads[worker_id]

        # 寻找负载最轻的worker
        min_load = min(self.worker_loads)
        if current_load > min_load * 1.5:  # 负载差异超过50%
            # 从队列中取回一些任务
            tasks_to_steal = []
            temp_queue = queue.Queue()

            while not self.task_queue.empty():
                task = self.task_queue.get()
                if task.weight < (current_load - min_load) / 2:
                    tasks_to_steal.append(task)
                else:
                    temp_queue.put(task)

            # 将剩余任务放回队列
            while not temp_queue.empty():
                self.task_queue.put(temp_queue.get())

            # 将窃取的任务放回队列（让其他worker处理）
            for task in tasks_to_steal:
                self.task_queue.put(task)

    def execute_task(self, task):
        """执行任务"""
        time.sleep(task.duration)
        return f"Result of {task.name}"

    def submit_task(self, task):
        """提交任务"""
        self.task_queue.put(task)

    def start(self):
        """启动负载均衡器"""
        for i in range(self.num_workers):
            t = threading.Thread(target=self.worker, args=(i,))
            t.start()
            self.workers.append(t)

    def stop(self):
        """停止负载均衡器"""
        for _ in range(self.num_workers):
            self.task_queue.put(None)

        self.stop_event.set()
        for t in self.workers:
            t.join()
```

#### 3.5.1.2 工作窃取优化
```python
import threading
import random
from collections import deque

class WorkStealingOptimizer:
    def __init__(self, num_processors):
        self.num_processors = num_processors
        self.deques = [deque() for _ in range(num_processors)]
        self.locks = [threading.Lock() for _ in range(num_processors)]
        self.processor_stats = [{'tasks_completed': 0, 'steals_attempted': 0, 'steals_successful': 0}
                               for _ in range(num_processors)]

    def optimized_work_steal(self, processor_id):
        """优化的工作窃取策略"""
        # 1. 首先从本地队列获取任务（LIFO）
        with self.locks[processor_id]:
            if self.deques[processor_id]:
                return self.deques[processor_id].pop()

        # 2. 智能窃取：选择最可能有任务的处理器
        candidates = self.select_victim_candidates(processor_id)

        for victim_id in candidates:
            with self.locks[victim_id]:
                if self.deques[victim_id]:
                    # 窃取一半的任务以保持负载均衡
                    tasks_to_steal = list(self.deques[victim_id])
                    half = len(tasks_to_steal) // 2
                    stolen_tasks = tasks_to_steal[:half]

                    # 更新队列
                    self.deques[victim_id] = deque(tasks_to_steal[half:])
                    self.deques[processor_id].extend(stolen_tasks)

                    # 更新统计信息
                    self.processor_stats[processor_id]['steals_attempted'] += 1
                    self.processor_stats[processor_id]['steals_successful'] += 1
                    self.processor_stats[victim_id]['tasks_completed'] -= len(stolen_tasks)

                    if stolen_tasks:
                        return stolen_tasks[0]

        return None

    def select_victim_candidates(self, processor_id):
        """选择窃取目标候选者"""
        # 策略1：随机选择
        candidates = list(range(self.num_processors))
        random.shuffle(candidates)

        # 策略2：基于历史统计信息
        # 优先选择任务完成率高的处理器
        candidates.sort(key=lambda x: self.processor_stats[x]['tasks_completed'], reverse=True)

        return candidates

    def adaptive_stealing_strategy(self, processor_id):
        """自适应窃取策略"""
        stats = self.processor_stats[processor_id]

        # 根据窃取成功率调整策略
        if stats['steals_attempted'] > 0:
            success_rate = stats['steals_successful'] / stats['steals_attempted']

            if success_rate < 0.3:
                # 窃取成功率低，减少窃取频率
                return self.reactive_work_stealing(processor_id)
            elif success_rate > 0.7:
                # 窃取成功率高，增加窃取频率
                return self.aggressive_work_stealing(processor_id)

        # 默认策略
        return self.optimized_work_steal(processor_id)

    def reactive_work_stealing(self, processor_id):
        """反应式工作窃取：只在必要时窃取"""
        # 检查是否有其他空闲处理器
        idle_processors = [i for i in range(self.num_processors)
                          if i != processor_id and len(self.deques[i]) == 0]

        if len(idle_processors) > self.num_processors * 0.5:
            # 大部分处理器空闲，不需要窃取
            return None

        return self.optimized_work_steal(processor_id)

    def aggressive_work_stealing(self, processor_id):
        """激进工作窃取：主动寻找任务"""
        # 尝试窃取更多任务
        for _ in range(3):  # 最多尝试3次
            task = self.optimized_work_steal(processor_id)
            if task:
                return task

        return None
```

### 3.5.2 通信优化

#### 3.5.2.1 通信聚合
```python
import numpy as np
from mpi4py import MPI

def communication_aggregation_example():
    """通信聚合示例"""
    comm = MPI.COMM_WORLD
    rank = comm.Get_rank()
    size = comm.Get_size()

    # 模拟需要通信的数据
    local_data = np.random.rand(1000)

    # 方法1：多次小消息通信（低效）
    def multiple_small_messages():
        start_time = MPI.Wtime()

        if rank == 0:
            # 接收来自所有其他进程的数据
            for i in range(1, size):
                data = np.empty(1000)
                comm.Recv(data, source=i, tag=1)
        else:
            # 发送数据到主进程
            comm.Send(local_data, dest=0, tag=1)

        end_time = MPI.Wtime()
        return end_time - start_time

    # 方法2：聚合通信（高效）
    def aggregated_communication():
        start_time = MPI.Wtime()

        # 使用Allgather聚合所有数据
        all_data = np.empty(size * 1000)
        comm.Allgather(local_data, all_data)

        end_time = MPI.Wtime()
        return end_time - start_time

    # 方法3：Reduce操作（特定场景）
    def reduce_operation():
        start_time = MPI.Wtime()

        # 计算所有数据的和
        local_sum = np.sum(local_data)
        global_sum = comm.allreduce(local_sum, op=MPI.SUM)

        end_time = MPI.Wtime()
        return end_time - start_time

    # 比较不同方法的性能
    if rank == 0:
        print("Communication Performance Comparison:")

    time1 = multiple_small_messages()
    time2 = aggregated_communication()
    time3 = reduce_operation()

    if rank == 0:
        print(f"Multiple small messages: {time1:.4f}s")
        print(f"Aggregated communication: {time2:.4f}s")
        print(f"Reduce operation: {time3:.4f}s")
        print(f"Aggregation speedup: {time1/time2:.2f}x")
```

#### 3.5.2.2 异步通信
```python
import numpy as np
from mpi4py import MPI
import time

def asynchronous_communication_example():
    """异步通信示例"""
    comm = MPI.COMM_WORLD
    rank = comm.Get_rank()
    size = comm.Get_size()

    # 模拟计算和通信重叠
    def compute_and_communicate():
        compute_time = 1.0  # 计算时间（秒）
        data_size = 10000   # 数据大小

        # 准备数据
        send_data = np.random.rand(data_size)
        recv_data = np.empty(data_size)

        # 开始异步发送
        start_time = time.time()
        request = comm.Isend(send_data, dest=(rank + 1) % size, tag=1)

        # 同时进行计算
        # 模拟计算工作
        result = 0.0
        for i in range(int(compute_time * 1000000)):
            result += i * 0.000001

        # 等待通信完成
        MPI.Request.Wait(request)

        # 接收数据
        comm.Recv(recv_data, source=(rank - 1) % size, tag=1)

        end_time = time.time()
        return end_time - start_time

    # 同步通信作为对比
    def synchronous_communication():
        compute_time = 1.0
        data_size = 10000

        send_data = np.random.rand(data_size)
        recv_data = np.empty(data_size)

        start_time = time.time()

        # 先计算
        result = 0.0
        for i in range(int(compute_time * 1000000)):
            result += i * 0.000001

        # 然后通信
        comm.Send(send_data, dest=(rank + 1) % size, tag=1)
        comm.Recv(recv_data, source=(rank - 1) % size, tag=1)

        end_time = time.time()
        return end_time - start_time

    # 执行并比较
    async_time = compute_and_communicate()
    sync_time = synchronous_communication()

    if rank == 0:
        print(f"Asynchronous communication time: {async_time:.4f}s")
        print(f"Synchronous communication time: {sync_time:.4f}s")
        print(f"Speedup: {sync_time/async_time:.2f}x")
```

### 3.5.3 内存访问优化

#### 3.5.3.1 缓存友好的数据访问
```python
import numpy as np
import time

def cache_friendly_access():
    """缓存友好的数据访问模式"""
    size = 4096
    matrix = np.random.rand(size, size)

    # 不友好的访问模式（列优先访问行）
    def bad_access_pattern():
        start_time = time.time()
        result = 0.0
        for j in range(size):  # 外层循环是列
            for i in range(size):  # 内层循环是行
                result += matrix[i][j]
        end_time = time.time()
        return end_time - start_time

    # 友好的访问模式（行优先访问）
    def good_access_pattern():
        start_time = time.time()
        result = 0.0
        for i in range(size):  # 外层循环是行
            for j in range(size):  # 内层循环是列
                result += matrix[i][j]
        end_time = time.time()
        return end_time - start_time

    # 分块访问模式（更好的缓存利用）
    def blocked_access_pattern(block_size=64):
        start_time = time.time()
        result = 0.0
        for ii in range(0, size, block_size):
            for jj in range(0, size, block_size):
                for i in range(ii, min(ii + block_size, size)):
                    for j in range(jj, min(jj + block_size, size)):
                        result += matrix[i][j]
        end_time = time.time()
        return end_time - start_time

    # 比较不同访问模式的性能
    time_bad = bad_access_pattern()
    time_good = good_access_pattern()
    time_blocked = blocked_access_pattern()

    print(f"Bad access pattern: {time_bad:.4f}s")
    print(f"Good access pattern: {time_good:.4f}s")
    print(f"Blocked access pattern: {time_blocked:.4f}s")
    print(f"Improvement: {time_bad/time_good:.2f}x, {time_bad/time_blocked:.2f}x")
```

#### 3.5.3.2 数据对齐优化
```c
#include <stdio.h>
#include <stdlib.h>
#include <time.h>
#include <xmmintrin.h>  // SSE

#define ALIGNMENT 16
#define SIZE 1000000

// 对齐内存分配
float* aligned_malloc(size_t size) {
    void* ptr;
    if (posix_memalign(&ptr, ALIGNMENT, size) != 0) {
        return NULL;
    }
    return (float*)ptr;
}

// 不对齐的内存访问
void unaligned_access(float* data, int n) {
    float sum = 0.0f;
    for (int i = 0; i < n; i++) {
        sum += data[i];
    }
}

// 对齐的SSE向量化访问
void aligned_sse_access(float* data, int n) {
    __m128 sum_vec = _mm_setzero_ps();

    // 处理对齐部分
    int aligned_n = (n / 4) * 4;
    for (int i = 0; i < aligned_n; i += 4) {
        __m128 vec = _mm_load_ps(&data[i]);  // 对齐加载
        sum_vec = _mm_add_ps(sum_vec, vec);
    }

    // 处理剩余部分
    float sum_array[4];
    _mm_store_ps(sum_array, sum_vec);
    float total = sum_array[0] + sum_array[1] + sum_array[2] + sum_array[3];

    for (int i = aligned_n; i < n; i++) {
        total += data[i];
    }
}

int main() {
    float* data = aligned_malloc(SIZE * sizeof(float));

    // 初始化数据
    for (int i = 0; i < SIZE; i++) {
        data[i] = (float)(i % 100) / 10.0f;
    }

    // 测试不对齐访问
    clock_t start = clock();
    unaligned_access(data, SIZE);
    clock_t end = clock();
    double time_unaligned = ((double)(end - start)) / CLOCKS_PER_SEC;

    // 测试对齐SSE访问
    start = clock();
    aligned_sse_access(data, SIZE);
    end = clock();
    double time_aligned = ((double)(end - start)) / CLOCKS_PER_SEC;

    printf("Unaligned access time: %f seconds\n", time_unaligned);
    printf("Aligned SSE access time: %f seconds\n", time_aligned);
    printf("Speedup: %f x\n", time_unaligned / time_aligned);

    free(data);
    return 0;
}
```

### 3.5.4 算法级优化

#### 3.5.4.1 算法选择优化
```python
import time
import numpy as np
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import multiprocessing as mp

def algorithm_selection_optimizer():
    """算法选择优化器"""
    class AlgorithmSelector:
        def __init__(self):
            self.performance_history = {}

        def select_algorithm(self, problem_size, available_algorithms):
            """根据问题规模和历史性能选择最佳算法"""
            if problem_size in self.performance_history:
                # 使用历史最佳算法
                best_algorithm = min(self.performance_history[problem_size].items(),
                                   key=lambda x: x[1])['algorithm']
                return best_algorithm

            # 如果没有历史数据，测试所有算法
            results = {}
            test_data = self.generate_test_data(problem_size)

            for algorithm in available_algorithms:
                start_time = time.time()
                result = algorithm(test_data)
                end_time = time.time()

                execution_time = end_time - start_time
                results[algorithm.__name__] = execution_time

            # 选择最佳算法
            best_algorithm = min(results.items(), key=lambda x: x[1])[0]

            # 记录性能历史
            if problem_size not in self.performance_history:
                self.performance_history[problem_size] = {}

            self.performance_history[problem_size] = results

            return best_algorithm

        def generate_test_data(self, size):
            """生成测试数据"""
            return np.random.rand(size)

    # 不同的排序算法
    def quicksort(arr):
        if len(arr) <= 1:
            return arr
        pivot = arr[len(arr) // 2]
        left = [x for x in arr if x < pivot]
        middle = [x for x in arr if x == pivot]
        right = [x for x in arr if x > pivot]
        return quicksort(left) + middle + quicksort(right)

    def mergesort(arr):
        if len(arr) <= 1:
            return arr
        mid = len(arr) // 2
        left = mergesort(arr[:mid])
        right = mergesort(arr[mid:])
        return merge(left, right)

    def parallel_quicksort(arr):
        if len(arr) <= 1000:  # 小数组使用串行快速排序
            return quicksort(arr)

        pivot = arr[len(arr) // 2]
        left = [x for x in arr if x < pivot]
        middle = [x for x in arr if x == pivot]
        right = [x for x in arr if x > pivot]

        # 并行排序左右子数组
        with ThreadPoolExecutor(max_workers=2) as executor:
            left_future = executor.submit(parallel_quicksort, left)
            right_future = executor.submit(parallel_quicksort, right)

            left_sorted = left_future.result()
            right_sorted = right_future.result()

        return left_sorted + middle + right_sorted

    def merge(left, right):
        result = []
        i = j = 0
        while i < len(left) and j < len(right):
            if left[i] <= right[j]:
                result.append(left[i])
                i += 1
            else:
                result.append(right[j])
                j += 1
        result.extend(left[i:])
        result.extend(right[j:])
        return result

    # 测试算法选择
    selector = AlgorithmSelector()
    algorithms = [quicksort, mergesort, parallel_quicksort]

    test_sizes = [1000, 10000, 100000, 1000000]

    for size in test_sizes:
        print(f"\nTesting with problem size: {size}")

        # 选择最佳算法
        best_algorithm = selector.select_algorithm(size, algorithms)
        print(f"Selected algorithm: {best_algorithm}")

        # 验证选择
        test_data = selector.generate_test_data(size)
        start_time = time.time()
        result = best_algorithm(test_data)
        end_time = time.time()

        print(f"Execution time: {end_time - start_time:.4f}s")

    return selector.performance_history
```

#### 3.5.4.2 自适应算法参数调整
```python
import time
import numpy as np
from concurrent.futures import ThreadPoolExecutor

class AdaptiveAlgorithmOptimizer:
    """自适应算法优化器"""

    def __init__(self):
        self.parameter_history = {}
        self.exploration_rate = 0.1  # 探索率

    def adaptive_parallel_sort(self, arr, target_time=None):
        """自适应并行排序"""
        n = len(arr)

        # 获取或初始化参数
        if n not in self.parameter_history:
            # 初始化参数
            params = {
                'chunk_size': max(100, n // 10),
                'num_threads': min(8, n // 1000),
                'algorithm': 'quicksort'
            }
            self.parameter_history[n] = {
                'params': params,
                'best_time': float('inf'),
                'history': []
            }

        params = self.parameter_history[n]['params']

        # 随机探索新参数（epsilon-greedy策略）
        if np.random.random() < self.exploration_rate:
            params = self.explore_new_parameters(n, params)

        # 执行排序
        start_time = time.time()
        result = self.execute_parallel_sort(arr, params)
        end_time = time.time()

        execution_time = end_time - start_time

        # 更新历史记录
        self.parameter_history[n]['history'].append({
            'params': params.copy(),
            'time': execution_time
        })

        # 更新最佳参数
        if execution_time < self.parameter_history[n]['best_time']:
            self.parameter_history[n]['best_time'] = execution_time
            self.parameter_history[n]['params'] = params.copy()

        return result, execution_time

    def explore_new_parameters(self, n, current_params):
        """探索新参数"""
        new_params = current_params.copy()

        # 随机调整chunk_size
        if np.random.random() < 0.5:
            new_params['chunk_size'] = max(10, int(new_params['chunk_size'] * np.random.uniform(0.8, 1.2)))

        # 随机调整线程数
        if np.random.random() < 0.5:
            new_params['num_threads'] = max(1, min(16, new_params['num_threads'] + np.random.randint(-2, 3)))

        # 随机切换算法
        if np.random.random() < 0.1:
            algorithms = ['quicksort', 'mergesort', 'heapsort']
            new_params['algorithm'] = np.random.choice(algorithms)

        return new_params

    def execute_parallel_sort(self, arr, params):
        """执行并行排序"""
        n = len(arr)
        chunk_size = params['chunk_size']
        num_threads = params['num_threads']

        # 分块
        chunks = [arr[i:i+chunk_size] for i in range(0, n, chunk_size)]

        # 并行排序各块
        with ThreadPoolExecutor(max_workers=num_threads) as executor:
            sorted_chunks = list(executor.map(self.local_sort, chunks))

        # 合并结果
        result = self.merge_sorted_chunks(sorted_chunks)
        return result

    def local_sort(self, chunk):
        """本地排序"""
        return sorted(chunk)

    def merge_sorted_chunks(self, chunks):
        """合并已排序的块"""
        result = []
        heap = []

        # 初始化堆
        for i, chunk in enumerate(chunks):
            if chunk:
                heap.append((chunk[0], i, 0))

        # 堆化
        heap.sort()

        while heap:
            val, chunk_idx, pos = heap.pop(0)
            result.append(val)

            # 添加下一个元素
            if pos + 1 < len(chunks[chunk_idx]):
                next_val = chunks[chunk_idx][pos + 1]
                heap.append((next_val, chunk_idx, pos + 1))
                heap.sort()

        return result

# 使用示例
optimizer = AdaptiveAlgorithmOptimizer()

# 测试不同大小的数组
test_sizes = [10000, 50000, 100000, 500000]

for size in test_sizes:
    print(f"\nTesting adaptive sorting with size: {size}")

    # 生成测试数据
    test_data = np.random.rand(size).tolist()

    # 执行自适应排序
    result, time_taken = optimizer.adaptive_parallel_sort(test_data)

    print(f"Execution time: {time_taken:.4f}s")

    # 显示最佳参数
    best_params = optimizer.parameter_history[size]['params']
    print(f"Best parameters: {best_params}")
```

### 3.5.5 系统级优化

#### 3.5.5.1 NUMA感知优化
```python
import os
import multiprocessing as mp
import psutil

def numa_aware_optimization():
    """NUMA感知优化"""
    # 检测NUMA拓扑
    def detect_numa_topology():
        """检测NUMA拓扑结构"""
        numa_nodes = {}

        # 获取CPU信息
        cpu_info = psutil.cpu_info()
        num_cpus = psutil.cpu_count()

        # 简化的NUMA检测（实际应用中需要更复杂的检测）
        try:
            # 尝试读取NUMA信息
            with open('/proc/numa_maps', 'r') as f:
                numa_data = f.read()
                # 解析NUMA映射信息
        except:
            pass

        return numa_nodes

    # NUMA感知的任务分配
    def numa_aware_task_distribution(tasks, num_processes=None):
        """NUMA感知的任务分配"""
        if num_processes is None:
            num_processes = mp.cpu_count()

        # 检测NUMA节点
        numa_topology = detect_numa_topology()

        # 创建进程池，将进程绑定到特定的NUMA节点
        processes = []
        tasks_per_node = len(tasks) // len(numa_topology) if numa_topology else len(tasks) // num_processes

        for node_id, cpu_list in enumerate(numa_topology.values()):
            # 为每个NUMA节点创建进程
            for i in range(num_processes // len(numa_topology)):
                p = mp.Process(target=numa_worker, args=(tasks[node_id * tasks_per_node:(node_id + 1) * tasks_per_node], cpu_list))
                processes.append(p)
                p.start()

        # 等待所有进程完成
        for p in processes:
            p.join()

    def numa_worker(tasks, cpu_list):
        """NUMA工作进程"""
        # 绑定进程到特定CPU
        os.sched_setaffinity(0, cpu_list)

        # 执行任务
        for task in tasks:
            process_task(task)

    def process_task(task):
        """处理单个任务"""
        # 模拟任务执行
        time.sleep(0.1)
        return f"Processed {task}"

    return numa_aware_task_distribution
```

#### 3.5.5.2 内存池优化
```python
import threading
import queue
import weakref

class MemoryPool:
    """内存池实现"""
    def __init__(self, initial_size=100, max_size=1000, block_size=1024):
        self.initial_size = initial_size
        self.max_size = max_size
        self.block_size = block_size
        self.pool = queue.Queue(maxsize=max_size)
        self.lock = threading.Lock()
        self.allocated_blocks = weakref.WeakSet()

        # 预分配内存块
        self._preallocate()

    def _preallocate(self):
        """预分配内存块"""
        for _ in range(self.initial_size):
            block = bytearray(self.block_size)
            self.pool.put(block)

    def allocate(self, size):
        """分配内存块"""
        with self.lock:
            if size > self.block_size:
                # 大于块大小的请求，直接分配
                return bytearray(size)

            try:
                # 从池中获取块
                block = self.pool.get_nowait()
                self.allocated_blocks.add(block)
                return block
            except queue.Empty:
                # 池为空，创建新块
                if self.pool.qsize() < self.max_size:
                    block = bytearray(self.block_size)
                    self.allocated_blocks.add(block)
                    return block
                else:
                    # 池已满，等待或直接分配
                    block = self.pool.get()
                    self.allocated_blocks.add(block)
                    return block

    def deallocate(self, block):
        """释放内存块"""
        with self.lock:
            if len(block) == self.block_size and block in self.allocated_blocks:
                # 小块放回池中
                try:
                    self.pool.put_nowait(block)
                    self.allocated_blocks.discard(block)
                except queue.Full:
                    # 池已满，丢弃块
                    pass
            # 大块会自动被垃圾回收

    def get_stats(self):
        """获取内存池统计信息"""
        with self.lock:
            return {
                'pool_size': self.pool.qsize(),
                'allocated_blocks': len(self.allocated_blocks),
                'max_size': self.max_size,
                'block_size': self.block_size
            }

# 使用示例：并行计算中的内存池
import multiprocessing as mp

def parallel_computation_with_memory_pool():
    """使用内存池的并行计算"""
    pool = MemoryPool()

    def worker(task_id, result_queue):
        # 从内存池分配内存
        data = pool.allocate(1024)

        # 执行计算
        result = sum(data) + task_id

        # 释放内存
        pool.deallocate(data)

        # 返回结果
        result_queue.put(result)

    # 创建结果队列
    result_queue = mp.Queue()
    processes = []

    # 启动多个进程
    for i in range(10):
        p = mp.Process(target=worker, args=(i, result_queue))
        p.start()
        processes.append(p)

    # 等待所有进程完成
    for p in processes:
        p.join()

    # 收集结果
    results = []
    while not result_queue.empty():
        results.append(result_queue.get())

    print(f"Results: {results}")
    print(f"Memory pool stats: {pool.get_stats()}")

    return results
```

## 本章小结

本章深入探讨了并行算法设计的核心原则、常见模式和优化策略。主要内容包括：

### 核心设计原则
1. **分解**：将复杂问题分解为可独立处理的子问题
2. **通信**：确定子问题间的数据交换需求
3. **同步**：协调多个并行任务的执行时序
4. **映射**：将子问题分配给处理器

### 常见并行算法模式
1. **分治法**：递归分解问题，适用于排序、矩阵乘法等
2. **流水线**：数据流经多个处理阶段，提高吞吐量
3. **主从模式**：一个主进程协调多个工作进程
4. **工作窃取**：动态负载均衡，空闲处理器窃取任务

### 性能分析
- **理论模型**：Amdahl定律、Gustafson定律
- **性能指标**：加速比、效率、执行时间分解
- **瓶颈识别**：通信瓶颈、负载不均衡分析

### 实际应用实例
- **排序算法**：并行归并排序、快速排序
- **搜索算法**：并行二分搜索、图搜索
- **数值计算**：矩阵乘法、数值积分、蒙特卡洛模拟
- **图算法**：Dijkstra算法、图着色

### 优化策略
1. **负载均衡**：动态负载均衡、工作窃取优化
2. **通信优化**：通信聚合、异步通信
3. **内存访问**：缓存友好、数据对齐
4. **算法级优化**：算法选择、参数自适应调整
5. **系统级优化**：NUMA感知、内存池

### 关键要点
- **权衡取舍**：并行化带来性能提升的同时也引入了复杂性
- **问题特性**：选择合适的并行模式取决于问题的特性
- **性能分析**：持续的性能监控和分析是优化的基础
- **系统意识**：了解底层硬件架构有助于更好的优化

通过本章的学习，读者应该能够：
1. 理解并行算法设计的基本原则
2. 选择合适的并行算法模式
3. 分析并行算法的性能特征
4. 应用各种优化策略提升性能
5. 根据具体问题设计高效的并行算法

并行算法设计是一门艺术，需要在理论分析、实践经验和技术洞察之间找到平衡。随着硬件架构的不断发展，并行算法设计也将持续演进，为解决更大规模的计算问题提供支持。