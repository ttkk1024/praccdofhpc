# 第十一章：OpenMP并行编程

## 11.1 OpenMP概述

### 11.1.1 OpenMP简介

OpenMP（Open Multi-Processing）是一种用于共享内存并行编程的API标准，支持C/C++和Fortran语言。它通过编译指令（pragma）实现并行化，具有以下特点：

**核心特性：**
- **共享内存模型**：所有线程共享同一内存空间
- **Fork-Join模型**：程序在主线程和并行区域之间切换
- **编译器指令**：通过`#pragma`指令控制并行化
- **可移植性**：跨平台支持（Linux、Windows、macOS）

**适用场景：**
- 多核CPU并行计算
- 循环并行化
- 任务并行
- 数据并行

### 11.1.2 OpenMP架构模型

```
主线程 (Master Thread)
    ↓
创建线程团队 (Team of Threads)
    ↓
并行区域执行 (Parallel Region)
    ↓
线程同步 (Synchronization)
    ↓
合并到主线程 (Join)
```

**线程层次结构：**
- **主线程（Master Thread）**：ID为0的线程
- **工作线程（Worker Threads）**：ID从1开始的并行线程
- **线程团队（Thread Team）**：执行并行区域的所有线程

## 11.2 OpenMP安装与配置

### 11.2.1 系统包管理器安装

#### Ubuntu/Debian系统
```bash
# 更新包管理器
sudo apt-get update

# 安装GCC OpenMP支持
sudo apt-get install gcc g++ gfortran

# 验证OpenMP支持
gcc -v

# 检查OpenMP版本
cat > test_omp.c << 'EOF'
#include <omp.h>
#include <stdio.h>

int main() {
    printf("OpenMP版本: %d\n", _OPENMP);
    return 0;
}
EOF

gcc -fopenmp test_omp.c -o test_omp
./test_omp
```

#### CentOS/RHEL系统
```bash
# 使用yum安装
sudo yum groupinstall "Development Tools"
sudo yum install gcc gcc-c++ gcc-gfortran

# 或使用dnf（较新版本）
sudo dnf groupinstall "Development Tools"
sudo dnf install gcc gcc-c++ gcc-gfortran

# 验证安装
gcc --version
```

#### macOS系统
```bash
# 使用Homebrew安装LLVM（包含OpenMP支持）
brew install llvm

# 设置环境变量
echo 'export PATH="/usr/local/opt/llvm/bin:$PATH"' >> ~/.zshrc
source ~/.zshrc

# 验证OpenMP支持
clang --version

# 或安装GCC
brew install gcc

# 验证GCC OpenMP支持
gcc-11 --version
```

#### Arch Linux
```bash
# 安装GCC
sudo pacman -S gcc

# 验证安装
gcc --version
```

### 11.2.2 源码编译安装

#### LLVM/Clang OpenMP安装
```bash
# 下载LLVM源码
wget https://github.com/llvm/llvm-project/releases/download/llvmorg-16.0.6/llvm-16.0.6.src.tar.xz
tar -xf llvm-16.0.6.src.tar.xz
cd llvm-16.0.6.src

# 创建构建目录
mkdir build && cd build

# 配置编译选项
cmake -DCMAKE_BUILD_TYPE=Release \
      -DCMAKE_C_COMPILER=gcc \
      -DCMAKE_CXX_COMPILER=g++ \
      -DLLVM_ENABLE_PROJECTS="clang;clang-tools-extra;openmp" \
      -DLLVM_TARGETS_TO_BUILD="X86;NVPTX" \
      -DLLVM_ENABLE_RTTI=ON \
      -DLLVM_ENABLE_EH=ON \
      ../llvm

# 编译和安装
make -j$(nproc)
sudo make install

# 设置环境变量
export PATH=/usr/local/bin:$PATH
export LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH
```

#### GCC OpenMP安装
```bash
# 下载GCC源码
wget https://ftp.gnu.org/gnu/gcc/gcc-13.2.0/gcc-13.2.0.tar.gz
tar -xf gcc-13.2.0.tar.gz
cd gcc-13.2.0

# 下载依赖
./contrib/download_prerequisites

# 创建构建目录
mkdir build && cd build

# 配置编译选项
../configure --prefix=/usr/local \
             --enable-languages=c,c++,fortran \
             --enable-shared \
             --enable-threads=posix \
             --enable-libmpx \
             --with-system-zlib \
             --with-isl \
             --enable-__cxa_atexit \
             --disable-libunwind-exceptions \
             --enable-clocale=gnu \
             --disable-libstdcxx-pch \
             --disable-libssp \
             --enable-plugin \
             --enable-linker-build-id \
             --enable-lto \
             --enable-install-libiberty \
             --with-linker-hash-style=gnu \
             --enable-gnu-indirect-function \
             --disable-multilib \
             --enable-checking=release \
             --enable-default-pie \
             --enable-default-ssp

# 编译和安装
make -j$(nproc)
sudo make install

# 更新环境变量
echo 'export PATH=/usr/local/bin:$PATH' >> ~/.bashrc
echo 'export LD_LIBRARY_PATH=/usr/local/lib64:/usr/local/lib:$LD_LIBRARY_PATH' >> ~/.bashrc
source ~/.bashrc
```

### 11.2.3 Intel编译器OpenMP

#### Intel OneAPI安装
```bash
# 下载Intel OneAPI
wget https://apt.repos.intel.com/intel-gpg-keys/GPG-PUB-KEY-INTEL-SW-PRODUCTS.PUB
sudo apt-key add GPG-PUB-KEY-INTEL-SW-PRODUCTS.PUB

# 添加仓库
echo "deb https://apt.repos.intel.com/oneapi all main" | sudo tee /etc/apt/sources.list.d/oneAPI.list

# 安装Intel编译器
sudo apt-get update
sudo apt-get install intel-oneapi-compiler-dpcpp-cpp-and-cpp-classic

# 设置环境变量
source /opt/intel/oneapi/setvars.sh

# 验证安装
icx --version
```

#### Intel编译器使用
```bash
# 编译OpenMP程序
icx -qopenmp program.c -o program
# 或
icc -openmp program.c -o program

# 设置运行时环境
export KMP_AFFINITY=granularity=fine,compact,1,0
export KMP_NUM_THREADS=8
```

### 11.2.4 容器化安装

#### Docker安装
```dockerfile
# Dockerfile
FROM ubuntu:22.04

# 安装基础工具
RUN apt-get update && apt-get install -y \
    build-essential \
    gcc \
    g++ \
    gfortran \
    cmake \
    wget \
    curl \
    && rm -rf /var/lib/apt/lists/*

# 设置环境变量
ENV PATH="/usr/local/bin:${PATH}"
ENV LD_LIBRARY_PATH="/usr/local/lib:${LD_LIBRARY_PATH}"

WORKDIR /app

# 验证OpenMP支持
RUN echo '#include <omp.h>\n#include <stdio.h>\nint main(){printf("OpenMP: %d\\n", _OPENMP); return 0;}' > test.c
RUN gcc -fopenmp test.c -o test && ./test

CMD ["bash"]
```

```bash
# 构建和运行
docker build -t openmp-env .
docker run -it openmp-env
```

#### Singularity安装
```singularity
Bootstrap: docker
From: ubuntu:22.04

%post
    apt-get update
    apt-get install -y build-essential gcc g++ gfortran
    apt-get clean

%environment
    export PATH="/usr/local/bin:${PATH}"
    export LD_LIBRARY_PATH="/usr/local/lib:${LD_LIBRARY_PATH}"

%runscript
    echo "OpenMP环境已配置"
```

### 11.2.5 验证安装

#### 基本验证测试
```c
#include <omp.h>
#include <stdio.h>

int main() {
    printf("OpenMP版本: %d\n", _OPENMP);
    printf("最大线程数: %d\n", omp_get_max_threads());
    printf("当前线程数: %d\n", omp_get_num_threads());
    printf("线程ID: %d\n", omp_get_thread_num());
    printf("是否在并行区域: %s\n", omp_in_parallel() ? "是" : "否");
    printf("嵌套并行支持: %s\n", omp_get_nested() ? "是" : "否");
    printf("动态线程支持: %s\n", omp_get_dynamic() ? "是" : "否");
    return 0;
}
```

```bash
# 编译和运行
gcc -fopenmp test_openmp.c -o test_openmp
./test_openmp
```

#### 并行程序测试
```c
#include <omp.h>
#include <stdio.h>

int main() {
    #pragma omp parallel
    {
        int thread_id = omp_get_thread_num();
        int num_threads = omp_get_num_threads();
        printf("Hello from thread %d of %d\n", thread_id, num_threads);
    }
    return 0;
}
```

```bash
# 编译和运行
gcc -fopenmp hello_openmp.c -o hello_openmp
./hello_openmp
```

### 11.2.6 环境变量配置

#### 常用环境变量
```bash
# 设置线程数量
export OMP_NUM_THREADS=8

# 设置调度策略
export OMP_SCHEDULE="dynamic,10"

# 启用嵌套并行
export OMP_NESTED=TRUE

# 设置堆栈大小
export OMP_STACKSIZE=4M

# 启用动态线程
export OMP_DYNAMIC=TRUE

# 设置并行区域数量限制
export OMP_MAX_ACTIVE_LEVELS=2
```

#### Intel特定环境变量
```bash
# 线程绑定策略
export KMP_AFFINITY=granularity=fine,compact,1,0

# 线程数量
export KMP_NUM_THREADS=8

# 堆栈大小
export KMP_STACKSIZE=4M

# 调度算法
export KMP_SCHEDULE=static,balanced

# 嵌套并行
export KMP_NESTED=TRUE
```

#### GCC特定环境变量
```bash
# 线程绑定
export GOMP_CPU_AFFINITY="0-7"

# 线程数量
export OMP_NUM_THREADS=8

# 调度策略
export GOMP_SCHEDULE="dynamic,10"

# 嵌套并行
export OMP_NESTED=TRUE
```

### 11.2.7 故障排除

#### 常见问题及解决方案

1. **编译错误：undefined reference to `omp_get_num_threads`**
```bash
# 确保使用-fopenmp标志编译
gcc -fopenmp program.c -o program

# 检查链接器标志
gcc -fopenmp -Wl,--verbose program.c -o program
```

2. **运行时错误：libgomp.so.1: cannot open shared object file**
```bash
# 检查库路径
ldd ./program

# 添加库路径
export LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH

# 或者重新编译时指定库路径
gcc -fopenmp -L/usr/local/lib program.c -o program
```

3. **性能问题：线程数量不正确**
```bash
# 检查系统CPU核心数
nproc

# 设置正确的线程数量
export OMP_NUM_THREADS=4  # 根据实际CPU核心数设置

# 检查NUMA拓扑
numactl --hardware
```

4. **内存问题：堆栈溢出**
```bash
# 增加堆栈大小
export OMP_STACKSIZE=8M

# 检查默认堆栈大小
ulimit -s

# 增加系统堆栈限制
ulimit -s unlimited
```

5. **绑定问题：线程绑定不正确**
```bash
# 检查线程绑定
export KMP_AFFINITY=verbose

# 设置合适的绑定策略
export KMP_AFFINITY=granularity=fine,compact,1,0

# 检查CPU拓扑
lscpu
```

### 11.2.8 性能优化配置

#### 编译器优化选项
```bash
# GCC优化选项
gcc -fopenmp -O3 -march=native -ffast-math -funroll-loops program.c -o program

# Intel编译器优化选项
icc -qopenmp -O3 -xHost -ipo program.c -o program

# Clang优化选项
clang -fopenmp -O3 -march=native program.c -o program
```

#### 运行时优化
```bash
# NUMA感知配置
export KMP_AFFINITY=granularity=fine,scatter
export KMP_PLACE_THREADS=4c,2t

# 内存分配优化
export MALLOC_ARENA_MAX=1
export KMP_MALLOC_POOL_INCR=1M

# 线程池优化
export KMP_BLOCKTIME=200
export KMP_SETTINGS=1
```

#### 多级并行配置
```bash
# 启用嵌套并行
export OMP_NESTED=TRUE
export OMP_NUM_THREADS="4,2"  # 外层4线程，内层2线程

# 设置最大活动层级
export OMP_MAX_ACTIVE_LEVELS=2
```

### 11.2.9 不同平台的特殊配置

#### Windows系统（使用MinGW）
```bash
# 安装MSYS2
# https://www.msys2.org/

# 安装GCC和OpenMP
pacman -S mingw-w64-x86_64-gcc
pacman -S mingw-w64-x86_64-openmp

# 验证安装
gcc -v
```

#### macOS系统（使用Homebrew）
```bash
# 安装GCC
brew install gcc

# 验证OpenMP支持
gcc-11 -v

# 编译程序
gcc-11 -fopenmp program.c -o program
```

#### HPC集群配置
```bash
# 使用模块系统
module load gcc/11.2.0
module load openmpi/4.1.4

# 编译
mpicc -fopenmp program.c -o program

# 运行
srun -n 1 -c 8 ./program
```

### 11.2.10 版本兼容性

#### OpenMP版本检查
```c
#include <omp.h>
#include <stdio.h>

int main() {
    #ifdef _OPENMP
        printf("OpenMP支持已启用\n");
        printf("OpenMP版本: %d\n", _OPENMP);
    #else
        printf("OpenMP支持未启用\n");
    #endif

    return 0;
}
```

#### 编译器兼容性
```bash
# GCC支持的OpenMP版本
gcc -dM -E - < /dev/null | grep -i openmp

# Clang支持的OpenMP版本
clang -dM -E - < /dev/null | grep -i openmp

# Intel编译器支持的OpenMP版本
icc -dM -E - < /dev/null | grep -i openmp
```

#### 特定功能检查
```c
#include <omp.h>
#include <stdio.h>

int main() {
    // 检查tasking支持
    #ifdef _OPENMP_TASK_REDUCTION
        printf("支持task reduction\n");
    #endif

    // 检查SIMD支持
    #ifdef _OPENMP_SIMD
        printf("支持SIMD指令\n");
    #endif

    return 0;
}
```

通过以上详细的安装和配置指南，你可以根据不同的操作系统和需求选择合适的OpenMP安装方式，并进行相应的性能优化配置。

## 11.3 基本指令详解

### 11.3.1 并行区域指令

#### 基本并行区域
```c
#include <omp.h>
#include <stdio.h>

int main() {
    printf("主线程开始执行\n");

    #pragma omp parallel
    {
        int thread_id = omp_get_thread_num();
        int num_threads = omp_get_num_threads();
        printf("线程 %d/%d 正在执行并行代码\n", thread_id, num_threads);
    }

    printf("主线程继续执行\n");
    return 0;
}
```

**输出示例：**
```
主线程开始执行
线程 0/4 正在执行并行代码
线程 1/4 正在执行并行代码
线程 2/4 正在执行并行代码
线程 3/4 正在执行并行代码
主线程继续执行
```

#### 设置线程数量
```c
#include <omp.h>

int main() {
    // 方法1：通过环境变量设置
    // export OMP_NUM_THREADS=8

    // 方法2：通过函数设置
    omp_set_num_threads(6);

    #pragma omp parallel
    {
        printf("线程 %d 正在执行\n", omp_get_thread_num());
    }

    return 0;
}
```

### 11.3.2 循环并行化指令

#### 基本并行循环
```c
#include <omp.h>
#include <stdio.h>

#define N 1000

int main() {
    double start_time, end_time;
    double sum = 0.0;

    // 串行版本
    start_time = omp_get_wtime();
    for (int i = 0; i < N; i++) {
        sum += i * i;
    }
    end_time = omp_get_wtime();
    printf("串行计算结果: %f, 时间: %f秒\n", sum, end_time - start_time);

    // 并行版本
    sum = 0.0;
    start_time = omp_get_wtime();

    #pragma omp parallel for
    for (int i = 0; i < N; i++) {
        double local_sum = i * i;
        #pragma omp atomic
        sum += local_sum;
    }

    end_time = omp_get_wtime();
    printf("并行计算结果: %f, 时间: %f秒\n", sum, end_time - start_time);

    return 0;
}
```

#### 循环调度策略
```c
#include <omp.h>
#include <stdio.h>

#define N 100

int main() {
    int work[N];

    // 静态调度
    #pragma omp parallel for schedule(static, 10)
    for (int i = 0; i < N; i++) {
        work[i] = i * i;
        printf("线程 %d 处理任务 %d\n", omp_get_thread_num(), i);
    }

    // 动态调度
    #pragma omp parallel for schedule(dynamic, 5)
    for (int i = 0; i < N; i++) {
        work[i] += i;
        printf("线程 %d 动态处理任务 %d\n", omp_get_thread_num(), i);
    }

    // 运行时调度
    #pragma omp parallel for schedule(runtime)
    for (int i = 0; i < N; i++) {
        work[i] *= 2;
        printf("线程 %d 运行时调度处理任务 %d\n", omp_get_thread_num(), i);
    }

    return 0;
}
```

**调度策略详解：**
- **static**：编译时分配，负载均衡但可能不灵活
- **dynamic**：运行时分配，负载均衡但有调度开销
- **guided**：动态调整块大小，平衡负载和开销
- **runtime**：通过环境变量`OMP_SCHEDULE`控制

### 11.3.3 Reduction操作

#### 基本Reduction
```c
#include <omp.h>
#include <stdio.h>
#include <math.h>

#define N 1000000

int main() {
    double pi = 0.0;
    double start_time, end_time;

    // 串行计算π
    start_time = omp_get_wtime();
    for (int i = 0; i < N; i++) {
        double x = (i + 0.5) / N;
        pi += 4.0 / (1.0 + x * x);
    }
    pi /= N;
    end_time = omp_get_wtime();
    printf("串行π计算: %f, 时间: %f秒\n", pi, end_time - start_time);

    // 并行Reduction计算π
    pi = 0.0;
    start_time = omp_get_wtime();

    #pragma omp parallel for reduction(+:pi)
    for (int i = 0; i < N; i++) {
        double x = (i + 0.5) / N;
        pi += 4.0 / (1.0 + x * x);
    }
    pi /= N;

    end_time = omp_get_wtime();
    printf("并行π计算: %f, 时间: %f秒\n", pi, end_time - start_time);

    return 0;
}
```

#### 复杂Reduction操作
```c
#include <omp.h>
#include <stdio.h>
#include <limits.h>

#define N 1000000

int main() {
    int array[N];
    int min_val = INT_MAX;
    int max_val = INT_MIN;
    long long sum = 0;

    // 初始化数组
    for (int i = 0; i < N; i++) {
        array[i] = rand() % 1000;
    }

    // 并行Reduction
    #pragma omp parallel for reduction(min:min_val) reduction(max:max_val) reduction(+:sum)
    for (int i = 0; i < N; i++) {
        if (array[i] < min_val) min_val = array[i];
        if (array[i] > max_val) max_val = array[i];
        sum += array[i];
    }

    printf("最小值: %d, 最大值: %d, 总和: %lld\n", min_val, max_val, sum);
    printf("平均值: %f\n", (double)sum / N);

    return 0;
}
```

## 11.4 数据共享属性

### 11.3.1 数据共享分类

#### Shared（共享变量）
```c
#include <omp.h>
#include <stdio.h>

#define N 100

int main() {
    int shared_array[N];
    int shared_counter = 0;

    // 初始化数组
    for (int i = 0; i < N; i++) {
        shared_array[i] = i;
    }

    #pragma omp parallel for shared(shared_array, shared_counter)
    for (int i = 0; i < N; i++) {
        shared_array[i] *= 2;
        #pragma omp atomic
        shared_counter++;
    }

    printf("共享计数器: %d\n", shared_counter);
    printf("数组前5个元素: ");
    for (int i = 0; i < 5; i++) {
        printf("%d ", shared_array[i]);
    }
    printf("\n");

    return 0;
}
```

#### Private（私有变量）
```c
#include <omp.h>
#include <stdio.h>

#define N 10

int main() {
    int private_var = 100;
    int shared_result = 0;

    printf("主线程中 private_var = %d\n", private_var);

    #pragma omp parallel for private(private_var) reduction(+:shared_result)
    for (int i = 0; i < N; i++) {
        private_var = i * 10;
        printf("线程 %d: private_var = %d\n", omp_get_thread_num(), private_var);
        shared_result += private_var;
    }

    printf("主线程中 private_var = %d\n", private_var);
    printf("共享结果: %d\n", shared_result);

    return 0;
}
```

#### Firstprivate和Lastprivate
```c
#include <omp.h>
#include <stdio.h>

#define N 10

int main() {
    int first_val = 42;
    int last_val = 0;

    printf("初始值: first_val = %d, last_val = %d\n", first_val, last_val);

    #pragma omp parallel for firstprivate(first_val) lastprivate(last_val)
    for (int i = 0; i < N; i++) {
        first_val += i;
        last_val = first_val * 2;
        printf("线程 %d: first_val = %d, last_val = %d\n",
               omp_get_thread_num(), first_val, last_val);
    }

    printf("循环后: first_val = %d, last_val = %d\n", first_val, last_val);

    return 0;
}
```

### 11.3.2 默认数据属性

#### default(shared)
```c
#include <omp.h>
#include <stdio.h>

int main() {
    int x = 10;
    int y = 20;

    #pragma omp parallel default(shared)
    {
        printf("线程 %d: x = %d, y = %d\n", omp_get_thread_num(), x, y);
        x += omp_get_thread_num();
        y += omp_get_thread_num() * 10;
    }

    printf("最终结果: x = %d, y = %d\n", x, y);
    return 0;
}
```

#### default(none)
```c
#include <omp.h>
#include <stdio.h>

int main() {
    int shared_var = 100;
    int private_var = 200;

    #pragma omp parallel default(none) shared(shared_var) private(private_var)
    {
        printf("线程 %d: shared_var = %d, private_var = %d\n",
               omp_get_thread_num(), shared_var, private_var);

        shared_var += omp_get_thread_num();
        private_var = omp_get_thread_num() * 100;
    }

    printf("最终: shared_var = %d\n", shared_var);
    return 0;
}
```

## 11.5 同步机制详解

### 11.4.1 Critical区域

#### 基本Critical
```c
#include <omp.h>
#include <stdio.h>

#define N 1000

int main() {
    int counter = 0;
    int array[N];

    // 初始化数组
    for (int i = 0; i < N; i++) {
        array[i] = i;
    }

    #pragma omp parallel for
    for (int i = 0; i < N; i++) {
        // 临界区：保护counter
        #pragma omp critical
        {
            counter++;
            if (counter % 100 == 0) {
                printf("已处理 %d 个元素\n", counter);
            }
        }

        array[i] *= 2;
    }

    printf("最终计数: %d\n", counter);
    return 0;
}
```

#### 命名Critical区域
```c
#include <omp.h>
#include <stdio.h>

int main() {
    int bank_balance = 1000;
    int stock_balance = 500;

    #pragma omp parallel for
    for (int i = 0; i < 100; i++) {
        // 银行账户操作
        #pragma omp critical(bank_operation)
        {
            bank_balance += 10;
            printf("线程 %d: 银行余额更新为 %d\n",
                   omp_get_thread_num(), bank_balance);
        }

        // 股票账户操作
        #pragma omp critical(stock_operation)
        {
            stock_balance += 5;
            printf("线程 %d: 股票余额更新为 %d\n",
                   omp_get_thread_num(), stock_balance);
        }
    }

    printf("最终银行余额: %d, 股票余额: %d\n", bank_balance, stock_balance);
    return 0;
}
```

### 11.4.2 Atomic操作

#### 基本Atomic
```c
#include <omp.h>
#include <stdio.h>

#define N 1000000

int main() {
    long long sum = 0;
    long long product = 1;
    int max_val = 0;

    #pragma omp parallel for
    for (int i = 1; i <= N; i++) {
        // 原子加法
        #pragma omp atomic
        sum += i;

        // 原子乘法（不是所有编译器都支持）
        #pragma omp atomic
        product *= i;

        // 原子最大值
        #pragma omp atomic update
        {
            if (i > max_val) max_val = i;
        }
    }

    printf("和: %lld, 最大值: %d\n", sum, max_val);
    return 0;
}
```

#### Atomic与Critical对比
```c
#include <omp.h>
#include <stdio.h>
#include <time.h>

#define N 1000000

int main() {
    clock_t start, end;
    double cpu_time_used;

    // 使用Critical
    int counter1 = 0;
    start = clock();

    #pragma omp parallel for
    for (int i = 0; i < N; i++) {
        #pragma omp critical
        {
            counter1++;
        }
    }

    end = clock();
    cpu_time_used = ((double)(end - start)) / CLOCKS_PER_SEC;
    printf("Critical耗时: %f秒, 结果: %d\n", cpu_time_used, counter1);

    // 使用Atomic
    int counter2 = 0;
    start = clock();

    #pragma omp parallel for
    for (int i = 0; i < N; i++) {
        #pragma omp atomic
        counter2++;
    }

    end = clock();
    cpu_time_used = ((double)(end - start)) / CLOCKS_PER_SEC;
    printf("Atomic耗时: %f秒, 结果: %d\n", cpu_time_used, counter2);

    return 0;
}
```

### 11.4.3 Barrier同步

#### 显式Barrier
```c
#include <omp.h>
#include <stdio.h>
#include <unistd.h>

int main() {
    #pragma omp parallel num_threads(4)
    {
        int thread_id = omp_get_thread_num();

        printf("线程 %d 开始第一阶段工作\n", thread_id);
        // 第一阶段工作
        sleep(1 + thread_id);

        #pragma omp barrier
        printf("线程 %d 完成第一阶段，等待其他线程\n", thread_id);

        printf("线程 %d 开始第二阶段工作\n", thread_id);
        // 第二阶段工作
        sleep(2);

        #pragma omp barrier
        printf("线程 %d 完成第二阶段，等待最终同步\n", thread_id);

        printf("线程 %d 完成所有工作\n", thread_id);
    }

    return 0;
}
```

#### Barrier与Work-sharing对比
```c
#include <omp.h>
#include <stdio.h>

int main() {
    printf("=== 使用Work-sharing（隐式同步）===\n");

    #pragma omp parallel
    {
        int thread_id = omp_get_thread_num();

        #pragma omp for
        for (int i = 0; i < 10; i++) {
            printf("线程 %d 处理任务 %d\n", thread_id, i);
            sleep(1);
        }

        // 隐式barrier：所有线程完成for循环后才继续
        printf("线程 %d 完成所有任务\n", thread_id);
    }

    printf("\n=== 使用显式Barrier ===\n");

    #pragma omp parallel num_threads(3)
    {
        int thread_id = omp_get_thread_num();

        // 第一阶段：不同线程处理不同数量的任务
        if (thread_id == 0) {
            for (int i = 0; i < 5; i++) {
                printf("线程 %d 处理任务 %d\n", thread_id, i);
                sleep(1);
            }
        } else if (thread_id == 1) {
            for (int i = 0; i < 3; i++) {
                printf("线程 %d 处理任务 %d\n", thread_id, i + 10);
                sleep(1);
            }
        } else {
            for (int i = 0; i < 7; i++) {
                printf("线程 %d 处理任务 %d\n", thread_id, i + 20);
                sleep(1);
            }
        }

        #pragma omp barrier
        printf("线程 %d 等待其他线程完成第一阶段\n", thread_id);

        // 第二阶段：所有线程继续工作
        printf("线程 %d 开始第二阶段\n", thread_id);
        sleep(2);
    }

    return 0;
}
```

### 11.4.4 Master和Single

#### Master指令
```c
#include <omp.h>
#include <stdio.h>

int main() {
    #pragma omp parallel num_threads(4)
    {
        // 只有主线程执行
        #pragma omp master
        {
            printf("这是主线程（ID=0）执行的代码\n");
            printf("当前线程数量: %d\n", omp_get_num_threads());
        }

        // 所有线程都执行
        printf("线程 %d 执行普通代码\n", omp_get_thread_num());

        // 主线程执行I/O操作
        #pragma omp master
        {
            printf("线程 %d 负责I/O输出\n", omp_get_thread_num());
        }
    }

    return 0;
}
```

#### Single指令
```c
#include <omp.h>
#include <stdio.h>

int main() {
    #pragma omp parallel num_threads(4)
    {
        printf("线程 %d 进入并行区域\n", omp_get_thread_num());

        #pragma omp single
        {
            printf("线程 %d 执行Single区域\n", omp_get_thread_num());
            printf("其他线程等待...\n");
            sleep(2);
        }

        printf("线程 %d 离开Single区域\n", omp_get_thread_num());

        // 现在所有线程继续执行
        printf("线程 %d 继续执行后续代码\n", omp_get_thread_num());
    }

    return 0;
}
```

#### nowait子句
```c
#include <omp.h>
#include <stdio.h>

int main() {
    printf("=== 使用nowait ===\n");

    #pragma omp parallel num_threads(4)
    {
        #pragma omp single nowait
        {
            printf("线程 %d 开始Single区域\n", omp_get_thread_num());
            sleep(2);
            printf("线程 %d 完成Single区域\n", omp_get_thread_num());
        }

        // 没有隐式同步，线程可以继续执行
        printf("线程 %d 在Single完成后立即执行\n", omp_get_thread_num());
    }

    printf("\n=== 不使用nowait ===\n");

    #pragma omp parallel num_threads(4)
    {
        #pragma omp single
        {
            printf("线程 %d 开始Single区域\n", omp_get_thread_num());
            sleep(2);
            printf("线程 %d 完成Single区域\n", omp_get_thread_num());
        }

        // 有隐式同步
        printf("线程 %d 等待Single完成后执行\n", omp_get_thread_num());
    }

    return 0;
}
```

## 11.6 高级特性

### 11.6.1 任务并行

#### Basic Tasks
```c
#include <omp.h>
#include <stdio.h>
#include <unistd.h>

void task_function(int task_id) {
    printf("任务 %d 由线程 %d 执行\n", task_id, omp_get_thread_num());
    sleep(1);
}

int main() {
    #pragma omp parallel
    {
        #pragma omp single
        {
            printf("主线程创建任务\n");

            for (int i = 0; i < 10; i++) {
                #pragma omp task
                task_function(i);
            }

            printf("任务创建完成，等待所有任务完成\n");
        }
    }

    printf("所有任务完成\n");
    return 0;
}
```

#### Task Dependencies
```c
#include <omp.h>
#include <stdio.h>

int main() {
    int a = 0, b = 0, c = 0;

    #pragma omp parallel
    {
        #pragma omp single
        {
            #pragma omp task depend(out: a)
            {
                a = 1;
                printf("任务1设置a=%d\n", a);
            }

            #pragma omp task depend(out: b)
            {
                b = 2;
                printf("任务2设置b=%d\n", b);
            }

            #pragma omp task depend(in: a, b) depend(out: c)
            {
                c = a + b;
                printf("任务3计算c=a+b=%d\n", c);
            }

            #pragma omp task depend(in: c)
            {
                printf("最终结果c=%d\n", c);
            }
        }
    }

    return 0;
}
```

#### Task Scheduling
```c
#include <omp.h>
#include <stdio.h>

int main() {
    #pragma omp parallel num_threads(4)
    {
        #pragma omp single
        {
            for (int i = 0; i < 20; i++) {
                #pragma omp task firstprivate(i)
                {
                    printf("任务%d由线程%d执行\n", i, omp_get_thread_num());
                    sleep(1);
                }
            }
        }
    }

    return 0;
}
```

### 11.6.2 线程私有存储

#### threadprivate指令
```c
#include <omp.h>
#include <stdio.h>

int counter = 0;

#pragma omp threadprivate(counter)

void increment_counter() {
    counter++;
    printf("线程 %d: counter = %d\n", omp_get_thread_num(), counter);
}

int main() {
    #pragma omp parallel num_threads(4)
    {
        increment_counter();
        increment_counter();
    }

    // 主线程的counter
    printf("主线程: counter = %d\n", counter);

    return 0;
}
```

#### 线程本地存储应用
```c
#include <omp.h>
#include <stdio.h>
#include <stdlib.h>

// 每个线程的随机数生成器状态
#pragma omp threadprivate(rand_state)
unsigned int rand_state;

unsigned int rand_r_custom() {
    rand_state = rand_state * 1103515245 + 12345;
    return rand_state;
}

int main() {
    #pragma omp parallel num_threads(4)
    {
        // 为每个线程初始化不同的随机种子
        #pragma omp single
        {
            #pragma omp task
            {
                rand_state = 12345;
            }
            #pragma omp task
            {
                rand_state = 54321;
            }
            #pragma omp task
            {
                rand_state = 98765;
            }
            #pragma omp task
            {
                rand_state = 13579;
            }
        }

        // 每个线程生成随机数
        for (int i = 0; i < 5; i++) {
            unsigned int r = rand_r_custom();
            printf("线程 %d: 随机数 %u\n", omp_get_thread_num(), r);
        }
    }

    return 0;
}
```

### 11.6.3 SIMD指令

#### 基本SIMD
```c
#include <omp.h>
#include <stdio.h>

#define N 1000

int main() {
    double a[N], b[N], c[N];

    // 初始化数组
    for (int i = 0; i < N; i++) {
        a[i] = i * 1.0;
        b[i] = i * 2.0;
    }

    // SIMD向量化
    #pragma omp simd
    for (int i = 0; i < N; i++) {
        c[i] = a[i] + b[i];
    }

    printf("前5个结果: ");
    for (int i = 0; i < 5; i++) {
        printf("%.1f ", c[i]);
    }
    printf("\n");

    return 0;
}
```

#### SIMD with Reduction
```c
#include <omp.h>
#include <stdio.h>

#define N 1000

int main() {
    double a[N], b[N];
    double dot_product = 0.0;

    // 初始化向量
    for (int i = 0; i < N; i++) {
        a[i] = i * 1.0;
        b[i] = i * 2.0;
    }

    // SIMD点积计算
    #pragma omp simd reduction(+:dot_product)
    for (int i = 0; i < N; i++) {
        dot_product += a[i] * b[i];
    }

    printf("点积结果: %f\n", dot_product);
    return 0;
}
```

## 11.7 性能优化技巧

### 11.7.1 负载均衡

#### 动态调度优化
```c
#include <omp.h>
#include <stdio.h>
#include <stdlib.h>
#include <time.h>

#define N 1000

int main() {
    int work_units[N];

    // 模拟不均匀的工作负载
    for (int i = 0; i < N; i++) {
        work_units[i] = rand() % 100 + 1;  // 1-100的工作量
    }

    clock_t start, end;
    double cpu_time_used;

    // 静态调度
    start = clock();
    #pragma omp parallel for schedule(static) reduction(+:total_work)
    for (int i = 0; i < N; i++) {
        // 模拟工作
        for (int j = 0; j < work_units[i] * 1000; j++) {
            // 空循环模拟工作
        }
    }
    end = clock();
    cpu_time_used = ((double)(end - start)) / CLOCKS_PER_SEC;
    printf("静态调度耗时: %f秒\n", cpu_time_used);

    // 动态调度
    start = clock();
    #pragma omp parallel for schedule(dynamic, 10) reduction(+:total_work)
    for (int i = 0; i < N; i++) {
        // 模拟工作
        for (int j = 0; j < work_units[i] * 1000; j++) {
            // 空循环模拟工作
        }
    }
    end = clock();
    cpu_time_used = ((double)(end - start)) / CLOCKS_PER_SEC;
    printf("动态调度耗时: %f秒\n", cpu_time_used);

    return 0;
}
```

#### 工作窃取
```c
#include <omp.h>
#include <stdio.h>

int fibonacci(int n) {
    if (n <= 1) return n;

    int x, y;

    #pragma omp task shared(x)
    x = fibonacci(n - 1);

    #pragma omp task shared(y)
    y = fibonacci(n - 2);

    #pragma omp taskwait
    return x + y;
}

int main() {
    int n = 30;

    #pragma omp parallel
    {
        #pragma omp single
        {
            printf("计算fibonacci(%d)\n", n);
            int result = fibonacci(n);
            printf("结果: %d\n", result);
        }
    }

    return 0;
}
```

### 11.7.2 内存访问优化

#### 数据对齐
```c
#include <omp.h>
#include <stdio.h>
#include <stdlib.h>

#define N 1000000

// 对齐到缓存行边界
typedef struct {
    double data[8] __attribute__((aligned(64)));
} aligned_data;

int main() {
    aligned_data *array = (aligned_data*)aligned_alloc(64, N * sizeof(aligned_data));

    // 并行初始化
    #pragma omp parallel for
    for (int i = 0; i < N; i++) {
        for (int j = 0; j < 8; j++) {
            array[i].data[j] = i + j;
        }
    }

    // 并行计算
    double sum = 0.0;
    #pragma omp parallel for reduction(+:sum)
    for (int i = 0; i < N; i++) {
        for (int j = 0; j < 8; j++) {
            sum += array[i].data[j];
        }
    }

    printf("总和: %f\n", sum);

    free(array);
    return 0;
}
```

#### 缓存友好的数据访问
```c
#include <omp.h>
#include <stdio.h>

#define N 1000
#define BLOCK_SIZE 32

int main() {
    double a[N][N], b[N][N], c[N][N];

    // 初始化矩阵
    for (int i = 0; i < N; i++) {
        for (int j = 0; j < N; j++) {
            a[i][j] = i + j;
            b[i][j] = i - j;
            c[i][j] = 0.0;
        }
    }

    // 分块矩阵乘法（缓存友好）
    #pragma omp parallel for collapse(2)
    for (int ii = 0; ii < N; ii += BLOCK_SIZE) {
        for (int jj = 0; jj < N; jj += BLOCK_SIZE) {
            for (int kk = 0; kk < N; kk += BLOCK_SIZE) {
                // 处理当前块
                for (int i = ii; i < ii + BLOCK_SIZE && i < N; i++) {
                    for (int j = jj; j < jj + BLOCK_SIZE && j < N; j++) {
                        for (int k = kk; k < kk + BLOCK_SIZE && k < N; k++) {
                            c[i][j] += a[i][k] * b[k][j];
                        }
                    }
                }
            }
        }
    }

    printf("矩阵乘法完成\n");
    printf("c[0][0] = %f\n", c[0][0]);
    printf("c[%d][%d] = %f\n", N-1, N-1, c[N-1][N-1]);

    return 0;
}
```

### 11.7.3 减少同步开销

#### 减少Barrier使用
```c
#include <omp.h>
#include <stdio.h>

#define N 1000

int main() {
    int array[N];
    int partial_sums[100];

    // 初始化数组
    for (int i = 0; i < N; i++) {
        array[i] = i % 100;
    }

    // 方法1：使用reduction（隐式同步）
    int total_sum1 = 0;
    #pragma omp parallel for reduction(+:total_sum1)
    for (int i = 0; i < N; i++) {
        total_sum1 += array[i];
    }
    printf("Reduction方法: %d\n", total_sum1);

    // 方法2：减少同步的分段求和
    #pragma omp parallel
    {
        int thread_id = omp_get_thread_num();
        int num_threads = omp_get_num_threads();

        // 每个线程计算部分和
        int local_sum = 0;
        for (int i = thread_id; i < N; i += num_threads) {
            local_sum += array[i];
        }

        partial_sums[thread_id] = local_sum;
    }

    // 最后一次性求和（减少同步）
    int total_sum2 = 0;
    for (int i = 0; i < omp_get_max_threads(); i++) {
        total_sum2 += partial_sums[i];
    }
    printf("分段求和方法: %d\n", total_sum2);

    return 0;
}
```

## 11.8 OpenMP在生物信息学中的应用

### 11.8.1 序列比对并行化

#### 并行Smith-Waterman算法
```c
#include <omp.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

#define MATCH_SCORE 2
#define MISMATCH_SCORE -1
#define GAP_PENALTY -1

int max(int a, int b, int c) {
    return (a > b) ? ((a > c) ? a : c) : ((b > c) ? b : c);
}

void parallel_smith_waterman(const char* seq1, const char* seq2,
                           int len1, int len2) {
    int** score_matrix = (int**)malloc((len1 + 1) * sizeof(int*));
    for (int i = 0; i <= len1; i++) {
        score_matrix[i] = (int*)malloc((len2 + 1) * sizeof(int));
    }

    // 初始化第一行和第一列
    for (int i = 0; i <= len1; i++) score_matrix[i][0] = 0;
    for (int j = 0; j <= len2; j++) score_matrix[0][j] = 0;

    // 并行计算得分矩阵
    #pragma omp parallel for collapse(2)
    for (int i = 1; i <= len1; i++) {
        for (int j = 1; j <= len2; j++) {
            int match = score_matrix[i-1][j-1] +
                       ((seq1[i-1] == seq2[j-1]) ? MATCH_SCORE : MISMATCH_SCORE);
            int delete = score_matrix[i-1][j] + GAP_PENALTY;
            int insert = score_matrix[i][j-1] + GAP_PENALTY;

            score_matrix[i][j] = max(match, delete, insert);
        }
    }

    // 找到最大得分
    int max_score = 0;
    int max_i = 0, max_j = 0;

    #pragma omp parallel for reduction(max:max_score)
    for (int i = 1; i <= len1; i++) {
        for (int j = 1; j <= len2; j++) {
            if (score_matrix[i][j] > max_score) {
                max_score = score_matrix[i][j];
                max_i = i;
                max_j = j;
            }
        }
    }

    printf("最大比对得分: %d\n", max_score);
    printf("位置: seq1[%d], seq2[%d]\n", max_i, max_j);

    // 清理内存
    for (int i = 0; i <= len1; i++) {
        free(score_matrix[i]);
    }
    free(score_matrix);
}

int main() {
    const char* seq1 = "ACGTACGTACGT";
    const char* seq2 = "ACGTAACGTAAC";

    parallel_smith_waterman(seq1, seq2, strlen(seq1), strlen(seq2));

    return 0;
}
```

### 11.8.2 基因表达数据分析

#### 并行相关性计算
```c
#include <omp.h>
#include <stdio.h>
#include <stdlib.h>
#include <math.h>

#define NUM_GENES 1000
#define NUM_SAMPLES 100

double** generate_expression_data() {
    double** data = (double**)malloc(NUM_GENES * sizeof(double*));
    for (int i = 0; i < NUM_GENES; i++) {
        data[i] = (double*)malloc(NUM_SAMPLES * sizeof(double));
        for (int j = 0; j < NUM_SAMPLES; j++) {
            data[i][j] = (double)rand() / RAND_MAX * 100.0;
        }
    }
    return data;
}

double calculate_correlation(double* gene1, double* gene2) {
    double mean1 = 0.0, mean2 = 0.0;

    // 计算均值
    for (int i = 0; i < NUM_SAMPLES; i++) {
        mean1 += gene1[i];
        mean2 += gene2[i];
    }
    mean1 /= NUM_SAMPLES;
    mean2 /= NUM_SAMPLES;

    // 计算相关系数
    double numerator = 0.0, denom1 = 0.0, denom2 = 0.0;
    for (int i = 0; i < NUM_SAMPLES; i++) {
        double diff1 = gene1[i] - mean1;
        double diff2 = gene2[i] - mean2;
        numerator += diff1 * diff2;
        denom1 += diff1 * diff1;
        denom2 += diff2 * diff2;
    }

    return numerator / (sqrt(denom1) * sqrt(denom2));
}

void parallel_correlation_analysis(double** expression_data) {
    double** correlation_matrix = (double**)malloc(NUM_GENES * sizeof(double*));
    for (int i = 0; i < NUM_GENES; i++) {
        correlation_matrix[i] = (double*)malloc(NUM_GENES * sizeof(double));
    }

    // 并行计算相关性矩阵
    printf("开始并行计算基因相关性...\n");

    #pragma omp parallel for collapse(2)
    for (int i = 0; i < NUM_GENES; i++) {
        for (int j = i; j < NUM_GENES; j++) {
            double corr = calculate_correlation(expression_data[i], expression_data[j]);
            correlation_matrix[i][j] = corr;
            correlation_matrix[j][i] = corr;  // 对称矩阵
        }
    }

    // 找到高度相关的基因对
    int highly_correlated = 0;
    #pragma omp parallel for reduction(+:highly_correlated) collapse(2)
    for (int i = 0; i < NUM_GENES; i++) {
        for (int j = i + 1; j < NUM_GENES; j++) {
            if (fabs(correlation_matrix[i][j]) > 0.8) {
                highly_correlated++;
            }
        }
    }

    printf("高度相关基因对数量 (|r| > 0.8): %d\n", highly_correlated);

    // 清理内存
    for (int i = 0; i < NUM_GENES; i++) {
        free(correlation_matrix[i]);
    }
    free(correlation_matrix);
}

int main() {
    srand(42);

    printf("生成基因表达数据...\n");
    double** expression_data = generate_expression_data();

    printf("进行并行相关性分析...\n");
    parallel_correlation_analysis(expression_data);

    // 清理内存
    for (int i = 0; i < NUM_GENES; i++) {
        free(expression_data[i]);
    }
    free(expression_data);

    return 0;
}
```

### 11.8.3 分子对接并行化

#### 并行构象搜索
```c
#include <omp.h>
#include <stdio.h>
#include <stdlib.h>
#include <math.h>

#define NUM_CONFORMATIONS 10000
#define NUM_ROTATIONS 360

typedef struct {
    double x, y, z;
} Vector3;

typedef struct {
    Vector3 position;
    double energy;
} Conformation;

// 简化的分子能量计算函数
double calculate_energy(Vector3 pos) {
    // 简化的势能函数
    return exp(-(pos.x*pos.x + pos.y*pos.y + pos.z*pos.z) / 100.0);
}

void parallel_conformation_search() {
    Conformation best_conformation = {{0, 0, 0}, INFINITY};
    Conformation* conformations = (Conformation*)malloc(NUM_CONFORMATIONS * sizeof(Conformation));

    printf("开始并行构象搜索...\n");

    // 并行生成和评估构象
    #pragma omp parallel for
    for (int i = 0; i < NUM_CONFORMATIONS; i++) {
        // 随机生成构象
        Vector3 pos;
        pos.x = (double)rand() / RAND_MAX * 20.0 - 10.0;
        pos.y = (double)rand() / RAND_MAX * 20.0 - 10.0;
        pos.z = (double)rand() / RAND_MAX * 20.0 - 10.0;

        // 计算能量
        double energy = calculate_energy(pos);

        conformations[i].position = pos;
        conformations[i].energy = energy;
    }

    // 找到最低能量构象
    #pragma omp parallel for reduction(min:best_conformation.energy)
    for (int i = 0; i < NUM_CONFORMATIONS; i++) {
        if (conformations[i].energy < best_conformation.energy) {
            best_conformation = conformations[i];
        }
    }

    printf("最佳构象:\n");
    printf("  位置: (%.2f, %.2f, %.2f)\n",
           best_conformation.position.x,
           best_conformation.position.y,
           best_conformation.position.z);
    printf("  能量: %.6f\n", best_conformation.energy);

    free(conformations);
}

int main() {
    srand(42);

    parallel_conformation_search();

    return 0;
}
```

## 11.9 调试和性能分析

### 11.8.1 OpenMP调试技巧

#### 环境变量调试
```bash
# 设置线程数量
export OMP_NUM_THREADS=4

# 设置调度策略
export OMP_SCHEDULE="dynamic,10"

# 启用嵌套并行
export OMP_NESTED=TRUE

# 设置堆栈大小
export OMP_STACKSIZE=4M

# 启用调试信息
export KMP_AFFINITY=verbose
export GOMP_DEBUG=1
```

#### 运行时检查
```c
#include <omp.h>
#include <stdio.h>

void check_openmp_environment() {
    printf("=== OpenMP环境信息 ===\n");
    printf("最大线程数: %d\n", omp_get_max_threads());
    printf("当前线程数: %d\n", omp_get_num_threads());
    printf("线程ID: %d\n", omp_get_thread_num());
    printf("是否在并行区域: %s\n", omp_in_parallel() ? "是" : "否");
    printf("嵌套并行支持: %s\n", omp_get_nested() ? "是" : "否");
    printf("动态线程支持: %s\n", omp_get_dynamic() ? "是" : "否");
}

int main() {
    check_openmp_environment();

    #pragma omp parallel
    {
        printf("线程 %d: ", omp_get_thread_num());
        check_openmp_environment();
    }

    return 0;
}
```

### 11.8.2 性能分析工具

#### 使用perf分析OpenMP程序
```bash
# 编译时添加调试信息
gcc -fopenmp -g -O2 program.c -o program

# 使用perf记录性能数据
perf record ./program

# 分析性能热点
perf report

# 分析缓存命中率
perf stat -e cache-misses,cache-references ./program

# 分析分支预测
perf stat -e branches,branch-misses ./program
```

#### Intel VTune Profiler使用
```bash
# 启用OpenMP分析
vtune -collect hotspots -result-dir=results ./program

# 分析线程和同步
vtune -collect threading -result-dir=results ./program

# 分析内存访问模式
vtune -collect memory-access -result-dir=results ./program

# 生成HTML报告
vtune -report hotspots -format=html -result-dir=results -report-output=report.html
```

### 11.8.3 性能基准测试

#### OpenMP性能测试框架
```c
#include <omp.h>
#include <stdio.h>
#include <stdlib.h>
#include <time.h>

#define TEST_SIZE 10000000
#define NUM_TESTS 5

double measure_performance(int num_threads) {
    double* array = (double*)malloc(TEST_SIZE * sizeof(double));
    double sum = 0.0;
    clock_t start, end;

    // 初始化数组
    for (int i = 0; i < TEST_SIZE; i++) {
        array[i] = (double)i;
    }

    // 设置线程数
    omp_set_num_threads(num_threads);

    // 执行测试
    start = clock();
    #pragma omp parallel for reduction(+:sum)
    for (int i = 0; i < TEST_SIZE; i++) {
        array[i] = sqrt(array[i]);
        sum += array[i];
    }
    end = clock();

    free(array);
    return ((double)(end - start)) / CLOCKS_PER_SEC;
}

void run_performance_test() {
    printf("OpenMP性能测试\n");
    printf("================\n");

    int max_threads = omp_get_max_threads();
    printf("最大线程数: %d\n\n", max_threads);

    printf("线程数\t时间(秒)\t加速比\t效率\n");
    printf("------\t--------\t------\t-----\n");

    double serial_time = measure_performance(1);
    printf("1\t%.4f\t1.00\t100.0%%\n", serial_time);

    for (int i = 2; i <= max_threads; i++) {
        double parallel_time = measure_performance(i);
        double speedup = serial_time / parallel_time;
        double efficiency = speedup / i * 100.0;

        printf("%d\t%.4f\t%.2f\t%.1f%%\n",
               i, parallel_time, speedup, efficiency);
    }
}

int main() {
    run_performance_test();
    return 0;
}
```

## 11.10 最佳实践和常见问题

### 11.9.1 最佳实践

#### 1. 适当的任务粒度
```c
// ❌ 粒度过细：每个迭代都很轻量
#pragma omp parallel for
for (int i = 0; i < 1000; i++) {
    result[i] = i * 2;  // 太简单的操作
}

// ✅ 适当的粒度：每个迭代有足够工作量
#pragma omp parallel for
for (int i = 0; i < 1000; i++) {
    // 复杂的计算
    for (int j = 0; j < 1000; j++) {
        result[i] += data[i][j] * weights[j];
    }
}
```

#### 2. 避免数据竞争
```c
// ❌ 数据竞争
#pragma omp parallel for
for (int i = 0; i < N; i++) {
    shared_array[i] = compute_value(i);
    global_counter++;  // 竞争条件
}

// ✅ 正确的同步
#pragma omp parallel for reduction(+:global_counter)
for (int i = 0; i < N; i++) {
    shared_array[i] = compute_value(i);
    global_counter++;
}
```

#### 3. 合理使用调度策略
```c
// 对于不均匀的工作负载，使用动态调度
#pragma omp parallel for schedule(dynamic, 10)

// 对于均匀的工作负载，使用静态调度
#pragma omp parallel for schedule(static)

// 对于递归算法，使用guided调度
#pragma omp parallel for schedule(guided)
```

### 11.9.2 常见问题和解决方案

#### 1. 死锁问题
```c
// ❌ 可能导致死锁
#pragma omp parallel
{
    #pragma omp critical(section1)
    {
        // 等待另一个临界区
        #pragma omp critical(section2)
        {
            // 代码
        }
    }
}

// ✅ 避免嵌套临界区
#pragma omp parallel
{
    #pragma omp critical(section1)
    {
        // 代码
    }
    #pragma omp critical(section2)
    {
        // 代码
    }
}
```

#### 2. 负载不均衡
```c
// ❌ 不均匀的工作负载
#pragma omp parallel for
for (int i = 0; i < N; i++) {
    // 某些迭代需要很长时间
    if (i % 100 == 0) {
        expensive_operation();
    }
}

// ✅ 使用动态调度
#pragma omp parallel for schedule(dynamic, 10)
for (int i = 0; i < N; i++) {
    if (i % 100 == 0) {
        expensive_operation();
    }
}
```

#### 3. 内存访问模式
```c
// ❌ 不缓存友好的访问模式
#pragma omp parallel for
for (int i = 0; i < N; i++) {
    for (int j = 0; j < M; j++) {
        result[j][i] = compute(i, j);  // 列优先访问
    }
}

// ✅ 缓存友好的访问模式
#pragma omp parallel for
for (int i = 0; i < N; i++) {
    for (int j = 0; j < M; j++) {
        result[i][j] = compute(i, j);  // 行优先访问
    }
}
```

### 11.9.3 编译器优化

#### 编译选项
```bash
# GCC编译选项
gcc -fopenmp -O3 -march=native -ffast-math program.c -o program

# Intel编译器选项
icc -qopenmp -O3 -xHost program.c -o program

# Clang编译选项
clang -fopenmp -O3 -march=native program.c -o program
```

#### 运行时优化
```c
// 启用NUMA感知
export KMP_AFFINITY=granularity=fine,compact,1,0

// 设置线程绑定
export GOMP_CPU_AFFINITY="0-3"

// 优化内存分配
export MALLOC_ARENA_MAX=1
```

## 11.11 总结

OpenMP是一个强大而灵活的并行编程工具，特别适合共享内存系统的并行化。通过本章的学习，你应该掌握：

### 核心概念
- **Fork-Join模型**：理解主线程和并行区域的关系
- **数据共享属性**：正确使用shared、private、firstprivate、lastprivate
- **同步机制**：critical、atomic、barrier、master、single等指令

### 实用技巧
- **循环并行化**：parallel for、schedule、reduction
- **任务并行**：task、taskwait、taskgroup
- **SIMD向量化**：simd指令提高向量计算性能

### 性能优化
- **负载均衡**：选择合适的调度策略
- **内存访问**：优化数据局部性和缓存使用
- **减少同步**：最小化临界区和同步点

### 生物信息学应用
- **序列比对**：并行Smith-Waterman算法
- **基因分析**：并行相关性计算
- **分子模拟**：并行构象搜索

### 最佳实践
- **适当的任务粒度**
- **避免数据竞争**
- **合理使用调度策略**
- **缓存友好的内存访问**

通过实践这些概念和技术，你可以在生物信息学和其他科学计算领域有效地利用多核处理器的并行计算能力，显著提高程序的性能。